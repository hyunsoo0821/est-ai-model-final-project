# AI_pipeline/core/pipeline.py

from AI_pipeline.core.timer_module import extract_frames, get_frame_paths
from AI_pipeline.core.ai_module import (
    upload_frames_to_gemini,
    wait_until_active,
    analyze_frames_with_llm,
    cleanup_gemini_files
)

VIDEO_PATH = "/workspace/AI_emotion_browser/AI_pipeline/video/ppangppangi2.mp4"


def run_llm_pipeline(start, end):
    """ì‹œì‘/ë ì´ˆ ì…ë ¥ë°›ê³  â†’ í”„ë ˆì„ ì¶”ì¶œ â†’ LLM ë¶„ì„"""
    extract_frames(VIDEO_PATH, start, end, fps=2)

    frames = get_frame_paths()
    if not frames:
        raise RuntimeError("âŒ í”„ë ˆì„ ì¶”ì¶œ ì‹¤íŒ¨ â€” íŒŒì¼ì´ ì—†ìŒ.")

    file_ids = upload_frames_to_gemini(frames)
    wait_until_active(file_ids)

    llm_result = analyze_frames_with_llm(file_ids)

    cleanup_gemini_files(file_ids)

    return llm_result


if __name__ == "__main__":
    print("ğŸ”¥ LLM íŒŒì´í”„ë¼ì¸ ë‹¨ë… ì‹¤í–‰ í…ŒìŠ¤íŠ¸!")
    result = run_llm_pipeline(12, 16)
    print("ğŸ‰ ê²°ê³¼:", result)
