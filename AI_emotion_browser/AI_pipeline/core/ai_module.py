# AI_pipeline/core/ai_module.py

import os
import time
import json
from google import genai
from dotenv import load_dotenv
from google.genai import types

# .env ë¡œë“œ
load_dotenv("/workspace/AI_emotion_browser/AI_pipeline/.env")

API_KEY = os.getenv("GOOGLE_API_KEY")

if not API_KEY:
    raise RuntimeError("âŒ GOOGLE_API_KEY is missing!")

client = genai.Client(api_key=API_KEY)


# ------------------------------------------------------------
# 1) Gemini Files Upload
# ------------------------------------------------------------
def upload_frames_to_gemini(frame_paths):
    uploaded_ids = []

    for path in frame_paths:
        uploaded = client.files.upload(
            file=path,
            #mime_type="image/jpeg"
        )
        uploaded_ids.append(uploaded.name)
        print("ğŸ“¤ ì—…ë¡œë“œë¨:", uploaded.name)

    return uploaded_ids


# ------------------------------------------------------------
# 2) Files ACTIVE ëŒ€ê¸°
# ------------------------------------------------------------
def wait_until_active(file_ids):
    print("â³ File ìƒíƒœ í™•ì¸ ì¤‘â€¦")

    for fid in file_ids:
        while True:
            f = client.files.get(name=fid)
            print(f" â¤ {fid} ìƒíƒœ: {f.state}")

            if f.state == "ACTIVE":
                break
            elif f.state == "FAILED":
                raise RuntimeError(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {fid}")

            time.sleep(0.3)

    print("ğŸ‰ ëª¨ë“  íŒŒì¼ ACTIVE!")


# ------------------------------------------------------------
# 3) LLM ë¶„ì„
# ------------------------------------------------------------
PROMPT = """
ë‹¤ìŒ ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ë¥¼ ë¶„ì„í•´ì„œ ì‚¬ìš©ìê°€ ì–´ë–¤ ì¥ë©´ì—ì„œ ì›ƒì—ˆëŠ”ì§€ JSON í˜•íƒœë¡œ ì •í™•íˆ ì¶œë ¥í•´ì¤˜.

ì¶œë ¥ í˜•ì‹ì€ ë°˜ë“œì‹œ ì•„ë˜ 3ê°œë§Œ í¬í•¨í•œë‹¤:

1) "tags": ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ì™€ ë¹„ìŠ·í•œ Youtube ì½˜í…ì¸  ê²€ìƒ‰ ì¶”ì²œìš© ëª…ì‚¬í˜• íƒœê·¸ ë°°ì—´ (ì˜ˆ: ["í¬ì¥ë§ˆì°¨", "ì»¤í”Œ", "ì›ƒê¸´ì˜ìƒ"])
2) "labels": ì•„ë˜ 5ê°€ì§€ ì¤‘ í•´ë‹¹ë˜ëŠ” ë¼ë²¨ë§Œ í¬í•¨í•˜ëŠ” ë°°ì—´  
   í—ˆìš©ëœ ë¼ë²¨:
   ['ë³‘ë§›','íŒ©íŠ¸í­ê²©','ê³µê°','ìŠ¬ë©ìŠ¤í‹±','ìƒí™©ê°œê·¸']

   âš ï¸ ê·œì¹™:
   - ì—¬ëŸ¬ ë¼ë²¨ì´ ë™ì‹œì— ê°€ëŠ¥í•˜ë‹¤.
   - 5ê°€ì§€ ë¼ë²¨ ëª©ë¡ì— ì—†ëŠ” ë¼ë²¨ì€ ì „ë¶€ ì œê±°í•œë‹¤.
   - ì í•©í•œ ë¼ë²¨ì´ ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ []ë¡œ ì¶œë ¥í•œë‹¤.

3) "summary": ì‚¬ìš©ìê°€ ì–´ë–¤ ì¥ë©´ì—ì„œ ì›ƒì—ˆëŠ”ì§€ í•œ ë¬¸ì¥ ìš”ì•½

ì¶œë ¥ ì˜ˆì‹œëŠ” ì•„ë˜ í˜•ì‹ì„ ë”°ë¼ì•¼ í•˜ë©° ì„¤ëª… ì—†ì´ JSONë§Œ ë°˜í™˜í•˜ë¼:

{
  "tags": ["ëª…ì‚¬1", "ëª…ì‚¬2","ëª…ì‚¬3"],
  "labels": ["ë³‘ë§›", "ìƒí™©ê°œê·¸"],
  "summary": "ì§§ì€ ì„¤ëª…"
}

ì„¤ëª… ì—†ì´ JSONë§Œ ì¶œë ¥í•˜ë¼.
"""



def analyze_frames_with_llm(file_ids):
    contents = [client.files.get(name=fid) for fid in file_ids]

    schema = types.Schema(
    type=types.Type.OBJECT,
    properties={
        "tags": types.Schema(
            type=types.Type.ARRAY, 
            items=types.Schema(type=types.Type.STRING)
        ),
        "labels": types.Schema(
            type=types.Type.ARRAY, 
            items=types.Schema(type=types.Type.STRING)
        ),
        "summary": types.Schema(type=types.Type.STRING)
    },
    required=["tags", "labels", "summary"]
)

    response = client.models.generate_content(
        model="models/gemini-2.5-pro",
        contents=contents + [PROMPT],
        config=types.GenerateContentConfig(
            response_mime_type="application/json",
            response_schema=schema
        ),
    )

    print("ğŸ¯ LLM Structured Output:", response)

    # âš ï¸ ì‹¤ì œ JSON string ì¶”ì¶œ
    json_text = response.candidates[0].content.parts[0].text

    # dictë¡œ íŒŒì‹±
    data = json.loads(json_text)

    return {
        "tags": data.get("tags", []),
        "labels": data.get("labels", []),
        "summary": data.get("summary", ""),
    }
# ------------------------------------------------------------
# 4) Files ì‚­ì œ
# ------------------------------------------------------------
def cleanup_gemini_files(file_ids):
    for fid in file_ids:
        client.files.delete(name=fid)
        print("ğŸ—‘ï¸ ì‚­ì œë¨:", fid)
