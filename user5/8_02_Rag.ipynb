{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osJRTFBXJbxO"
      },
      "source": [
        "**실습1 - 문서 요약**\n",
        " 1. 문서 업로드 (PDF or 텍스트)\n",
        " 2. 문서 로드 & chunk 분할\n",
        " 3. 벡터스토어 생성(Chroma)\n",
        " 4. Retriever + LLM 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqhBXZ9YvpQP"
      },
      "outputs": [],
      "source": [
        "# Chroma.from_documents : 임베딩 + 저장\n",
        "# vectordb.as_retriever() : 검색 함수 제공\n",
        "# RetrievalQA : 검색 + 프롬프트 생성 + LLM 호출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_EDqbntkBUkH"
      },
      "outputs": [],
      "source": [
        "# 필요한 라이브러리 설치\n",
        "# !pip install langchain langchain-community langchain-openai chromadb pypdf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPXdrItfBJ8b"
      },
      "outputs": [],
      "source": [
        "!pip install langchain langchain-community langchain-openai\n",
        "   # RAG 파이프라인을 구성하는 데 필요한 문서 로더, 텍스트 스플리터, 체인, 벡터 스토어 래퍼 등을 제공.\n",
        "!pip install chromadb\n",
        "   # 로컬 용 벡터 데이터베이스 (임베딩 저장 & 검색)\n",
        "!pip install faiss-cpu\n",
        "!pip install pypdf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9-NCyTcBVQD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "OPENAI_API_KEY = \"....\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "id": "vZc7Ml8ZBVNP",
        "outputId": "c5c1f529-18b5-4576-be6a-f6a10bfa1669"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a23ed8d5-338a-4737-9b86-f9c935d973cd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a23ed8d5-338a-4737-9b86-f9c935d973cd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving vit.paper.2010.11929v2.pdf to vit.paper.2010.11929v2 (1).pdf\n"
          ]
        }
      ],
      "source": [
        "### 문서 업로드 (PDF or 텍스트)\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8OaOfRhBVKH"
      },
      "outputs": [],
      "source": [
        "### 문서 로드 & chunk 분할\n",
        "\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "loader = PyPDFLoader(\"vit.paper.2010.11929v2.pdf\")  # <--- 업로드한 파일명으로 변경...\n",
        "   # PDF 파일을 읽어서 LangChain의 Document 객체 리스트로 바꿔주는 클래스.\n",
        "docs = loader.load()\n",
        "   # PDF를 읽어 Document 리스트 저장\n",
        "\n",
        "# 긴 텍스트를 잘게 쪼개서 검색 단위 만듦\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500, chunk_overlap=100\n",
        "      # 한 chunk의 최대 길이 : 500 (문자 수 기준)\n",
        "      # 너무 길면 LLM 컨텍스트를 많이 차지, 너무 짧으면 문맥이 끊겨 답변 품질 하락.\n",
        "\n",
        "      # chunk_overlap=100 : 앞 chunk의 마지막 100자와 다음 chunk의 처음 100자가 겹치게 잘라줌.\n",
        "      # 앞/뒤 chunk가 서로 맥락을 공유하도록 하기 위해\n",
        ")\n",
        "chunks = splitter.split_documents(docs)\n",
        "  # docs를 받아서 내부 텍스트를 합친 뒤,\n",
        "  # 설정한 chunk_size / overlap에 맞춰 여러 개의 작은 chunks(Document)로 나눔.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GM2fIcUlMZrM",
        "outputId": "90c2f784-f120-439b-dd46-954fc37dd86d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(docs)  # 페이지 수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "DaC9EIXxLrgQ",
        "outputId": "a1f8ec3a-1f5b-4f03-9866-2fa79bd913ff"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Published as a conference paper at ICLR 2021\\nAN IMAGE IS WORTH 16X16 W ORDS :\\nTRANSFORMERS FOR IMAGE RECOGNITION AT SCALE\\nAlexey Dosovitskiy∗,†, Lucas Beyer∗, Alexander Kolesnikov∗, Dirk Weissenborn∗,'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chunks[0].page_content[:200]  # 첫 chunk의 앞 200자 확인\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jCjJa0nMJs1",
        "outputId": "80985f6b-0bc0-4246-ad9f-db5f7ddf6d8d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'producer': 'pdfTeX-1.40.21',\n",
              " 'creator': 'LaTeX with hyperref',\n",
              " 'creationdate': '2021-06-04T00:19:58+00:00',\n",
              " 'author': '',\n",
              " 'keywords': '',\n",
              " 'moddate': '2021-06-04T00:19:58+00:00',\n",
              " 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
              " 'subject': '',\n",
              " 'title': '',\n",
              " 'trapped': '/False',\n",
              " 'source': 'vit.paper.2010.11929v2.pdf',\n",
              " 'total_pages': 22,\n",
              " 'page': 0,\n",
              " 'page_label': '1'}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chunks[0].metadata            # chunk metadata (document 정보 확인)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uiWejGFBVHS",
        "outputId": "b022131a-371a-485f-9317-2792ca88e9b7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2029611082.py:7: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
            "  emb = OpenAIEmbeddings()\n"
          ]
        }
      ],
      "source": [
        "### 벡터 DB 생성(Chroma)\n",
        "\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings # 텍스트를 OpenAI 임베딩 모델(text-embedding-3-small 등)로 벡터화\n",
        "                                                  # 각 chunk의 텍스트를 고차원 벡터로 변환\n",
        "\n",
        "emb = OpenAIEmbeddings()\n",
        "vectordb = Chroma.from_documents(chunks, emb)\n",
        "   # chunks 리스트를 순회 -> 각 chunk.page_content를 emb로 임베딩 생성\n",
        "   #   -> 생성된 벡터 + 원본 문서(Document)를 Chroma DB(로컬 폴더)에 저장\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vHEf350BVEd",
        "outputId": "f36dec9f-d8de-4f09-a5d6-060380530f43"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3019252939.py:6: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n"
          ]
        }
      ],
      "source": [
        "### Retriever + LLM 생성\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=vectordb.as_retriever(),\n",
        "        # 벡터 스토어를 retriever 인터페이스로 변환.\n",
        "    chain_type=\"stuff\"\n",
        "        # 가져온 Document들을 그냥 한 덩어리로(stuff) 붙여서 LLM 프롬프트에 넣음 <-- 가장 단순한 방식.\n",
        ")\n",
        "\n",
        "### \"stuff\" 방식으로 생성한  prompt 예시\n",
        "# 다음은 참고할 컨텍스트입니다:\n",
        "# {context}  <--- retriever가 가져온 chunks\n",
        "# 위 컨텍스트를 바탕으로 다음 질문에 답변해 주세요:\n",
        "# {question} <-- 사용자의 질문\n",
        "\n",
        "### langchain\n",
        "# 1. 검색 ... 임베딩 -> 코사인 유사도\n",
        "# 2. 컨텍스트를 프롬프트에 포함\n",
        "# 3. GPT에 질의\n",
        "# <---- LangChain wrapper 역활... 위  process를 자동으로 처리\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "zgaXtMrgBVBx",
        "outputId": "945f8d30-3090-4b91-efbd-eee9a71a4062"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'이 문서는 이미지 인식에서 변환기(Transformers)의 사용에 대해 다루고 있습니다. 주요 내용은 ViT-H/14 및 ViT-L/16과 같은 대형 모델을 기존의 CNN과 비교하고, 이 모델들이 어떻게 성능을 향상시키는지를 설명합니다. 또한, 주의(attention) 메커니즘과 다중 헤드 자기 주의(multihead self-attention) 개념을 소개하며, 이를 통해 입력 시퀀스의 요소 간의 관계를 효과적으로 학습할 수 있음을 강조합니다. 마지막으로, 이 연구는 이미지 인식 분야에서의 최신 기술 동향과 기여를 다루고 있습니다.'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### 질문하기\n",
        "\n",
        "query = \"이 문서의 핵심 내용을 요약해줘.\"\n",
        "answer = qa.run(query)\n",
        "answer\n",
        "\n",
        "### qa.run\n",
        "# retriever.get_relevant_documents(query) 실행\n",
        "#  → vectordb에서 query와 유사한 chunk 가져옴 (k개)\n",
        "# 가져온 chunk들을 합쳐서 context 문자열 생성\n",
        "# LLM 프롬프트에 {context}, {question}를 입력 -> llm 호출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4Qqx_GcBU_E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jI9YFYUWwdkV"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OD4VSWCEwj9y"
      },
      "source": [
        "ChromaDB : 로컬에서 동작하는 벡터 데이터베이스"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrR2VbqDBU8J"
      },
      "outputs": [],
      "source": [
        "# Chroma in LangChain\n",
        "# 텍스트 → 임베딩 벡터로 변환, 벡터 + 원본 문서 + 메타데이터 저장,\n",
        "# 문서 검색, 질문 벡터와의 유사도를 기준으로..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmVbGI36wm-4",
        "outputId": "bccebf42-2219-41ff-f8a7-756e6341f9af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "문서 개수: 180\n"
          ]
        }
      ],
      "source": [
        "# LangChain의 Chroma 래퍼 내부에 실제 chroma collection이 있습니다.\n",
        "collection = vectordb._collection\n",
        "\n",
        "print(\"문서 개수:\", collection.count()) ##  chunk 갯수\n",
        "   # chunk들을 벡터로 변환 -> 각 chunk마다 벡터 + metadata + text 정보 관리\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwcUnNIDwdCQ",
        "outputId": "ce83e49b-5aea-4baa-8ae0-09191e62c7a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['ids', 'embeddings', 'documents', 'uris', 'included', 'data', 'metadatas'])\n",
            "ids: ['a365f801-af75-4288-8f1a-1edc6295a2c8', '326d9a4e-b009-4582-9985-accfaabc8d3a', 'f17be90c-fe9f-4ade-9006-129d879149b9']\n",
            "\n",
            "=== 0번째 ===\n",
            "id: a365f801-af75-4288-8f1a-1edc6295a2c8\n",
            "document: Published as a conference paper at ICLR 2021\n",
            "AN IMAGE IS WORTH 16X16 W ORDS :\n",
            "TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE\n",
            "Alexey Dosovitskiy∗,†, Lucas Beyer∗, Alexander Kolesnikov∗, Dirk Weissenborn∗, ...\n",
            "metadata: {'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'title': '', 'producer': 'pdfTeX-1.40.21', 'keywords': '', 'subject': '', 'creator': 'LaTeX with hyperref', 'author': '', 'source': 'vit.paper.2010.11929v2.pdf', 'page': 0, 'creationdate': '2021-06-04T00:19:58+00:00', 'page_label': '1', 'trapped': '/False', 'moddate': '2021-06-04T00:19:58+00:00', 'total_pages': 22}\n",
            "embedding dim: 1536\n",
            "\n",
            "=== 1번째 ===\n",
            "id: 326d9a4e-b009-4582-9985-accfaabc8d3a\n",
            "document: Google Research, Brain Team\n",
            "{adosovitskiy, neilhoulsby}@google.com\n",
            "ABSTRACT\n",
            "While the Transformer architecture has become the de-facto standard for natural\n",
            "language processing tasks, its applications  ...\n",
            "metadata: {'page_label': '1', 'subject': '', 'title': '', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'total_pages': 22, 'creationdate': '2021-06-04T00:19:58+00:00', 'moddate': '2021-06-04T00:19:58+00:00', 'keywords': '', 'page': 0, 'trapped': '/False', 'author': '', 'producer': 'pdfTeX-1.40.21', 'source': 'vit.paper.2010.11929v2.pdf', 'creator': 'LaTeX with hyperref'}\n",
            "embedding dim: 1536\n",
            "\n",
            "=== 2번째 ===\n",
            "id: f17be90c-fe9f-4ade-9006-129d879149b9\n",
            "document: overall structure in place. We show that this reliance on CNNs is not necessary\n",
            "and a pure transformer applied directly to sequences of image patches can perform\n",
            "very well on image classiﬁcation tasks ...\n",
            "metadata: {'total_pages': 22, 'page': 0, 'moddate': '2021-06-04T00:19:58+00:00', 'subject': '', 'creationdate': '2021-06-04T00:19:58+00:00', 'producer': 'pdfTeX-1.40.21', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'page_label': '1', 'source': 'vit.paper.2010.11929v2.pdf', 'author': '', 'keywords': '', 'title': '', 'trapped': '/False', 'creator': 'LaTeX with hyperref'}\n",
            "embedding dim: 1536\n"
          ]
        }
      ],
      "source": [
        "### 저장된 문서/메타데이터/임베딩 확인\n",
        "\n",
        "res = collection.get(\n",
        "    limit=3,  # 앞 3개만 보기\n",
        "    include=[\"documents\", \"metadatas\", \"embeddings\"]\n",
        ")\n",
        "\n",
        "print(res.keys())   # dict의 키들: ids, embeddings, documents, metadatas\n",
        "print(\"ids:\", res[\"ids\"])\n",
        "\n",
        "for i in range(len(res[\"ids\"])):\n",
        "    print(f\"\\n=== {i}번째 ===\")\n",
        "    print(\"id:\", res[\"ids\"][i])\n",
        "    print(\"document:\", res[\"documents\"][i][:200], \"...\")\n",
        "    print(\"metadata:\", res[\"metadatas\"][i])\n",
        "    print(\"embedding dim:\", len(res[\"embeddings\"][i]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJGLewcXwc_M",
        "outputId": "4775d23a-3431-475d-a879-311b781b96cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Published as a conference paper at ICLR 2021\n",
            "AN IMAGE IS WORTH 16X16 W ORDS :\n",
            "TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE\n",
            "Alexey Dosovitskiy∗,†, Lucas Beyer∗, Alexander Kolesnikov∗, Dirk Weissenborn∗, ...\n",
            "{'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'page': 0, 'keywords': '', 'title': '', 'trapped': '/False', 'creator': 'LaTeX with hyperref', 'total_pages': 22, 'page_label': '1', 'producer': 'pdfTeX-1.40.21', 'creationdate': '2021-06-04T00:19:58+00:00', 'moddate': '2021-06-04T00:19:58+00:00', 'author': '', 'subject': '', 'source': 'vit.paper.2010.11929v2.pdf'}\n",
            "------------------------------------------------------------\n",
            "transformers. arXiv, 2019.\n",
            "Jean-Baptiste Cordonnier, Andreas Loukas, and Martin Jaggi. On the relationship between self-\n",
            "attention and convolutional layers. In ICLR, 2020.\n",
            "J. Deng, W. Dong, R. Socher, ...\n",
            "{'creator': 'LaTeX with hyperref', 'subject': '', 'page_label': '10', 'producer': 'pdfTeX-1.40.21', 'moddate': '2021-06-04T00:19:58+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'author': '', 'keywords': '', 'page': 9, 'trapped': '/False', 'total_pages': 22, 'creationdate': '2021-06-04T00:19:58+00:00', 'title': '', 'source': 'vit.paper.2010.11929v2.pdf'}\n",
            "------------------------------------------------------------\n",
            "Chen Sun, Abhinav Shrivastava, Saurabh Singh, and Abhinav Gupta. Revisiting unreasonable ef-\n",
            "fectiveness of data in deep learning era. In ICCV, 2017.\n",
            "Chen Sun, Austin Myers, Carl V ondrick, Kevin Murp ...\n",
            "{'moddate': '2021-06-04T00:19:58+00:00', 'author': '', 'total_pages': 22, 'subject': '', 'page': 10, 'page_label': '11', 'creationdate': '2021-06-04T00:19:58+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'source': 'vit.paper.2010.11929v2.pdf', 'title': '', 'keywords': '', 'producer': 'pdfTeX-1.40.21', 'trapped': '/False', 'creator': 'LaTeX with hyperref'}\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "### similarity search 결과 확인\n",
        "\n",
        "query = \"이 문서의 핵심 내용은 무엇인가?\"\n",
        "docs = vectordb.similarity_search(query, k=3)\n",
        "\n",
        "for d in docs:\n",
        "    print(d.page_content[:200], \"...\")\n",
        "    print(d.metadata)\n",
        "    print(\"-\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0FROSNuwc8A"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WM7mXwhyWE-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvMfOHpXJiRF"
      },
      "source": [
        "**실습2 - FAQ**\n",
        " 1. FAQ 문서 준비\n",
        " 2. 문서(FAQ) OpenAI 임베딩(벡터)로 변환, 저장\n",
        " 3. 질문 임베딩\n",
        " 4. 질문과 유사한 FAQ 검색 (코사인 유사도)\n",
        " 5. 검색된 FAQ를 프롬프트에 포함하여 LLM에 전달 -> LLM 답변 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYetsKtyJhYI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "client = OpenAI()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mC4DmF6wJhVU"
      },
      "outputs": [],
      "source": [
        "### 내 문서(지식) 예제\n",
        "### 학습 서비스 회사 FAQ\n",
        "### 실제 RAG 예시 PDF → chunk → 벡터 DB\n",
        "\n",
        "docs = [\n",
        "    {\n",
        "        \"id\": 1,\n",
        "        \"title\": \"환불 규정\",\n",
        "        \"text\": \"우리 회사의 유료 구독은 결제 후 7일 이내에는 전액 환불이 가능하고, 그 이후에는 사용 일수에 따라 부분 환불이 가능합니다.\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": 2,\n",
        "        \"title\": \"AI 튜터 기능\",\n",
        "        \"text\": \"AI 튜터는 학습자의 레벨 테스트 결과를 기반으로 맞춤형 영어 회화 연습 문제를 제공합니다.\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": 3,\n",
        "        \"title\": \"데이터 보관 정책\",\n",
        "        \"text\": \"학습 기록과 채팅 데이터는 서비스 품질 향상을 위해 최대 3년간 보관되며, 이용자가 요청할 경우 언제든지 삭제할 수 있습니다.\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": 4,\n",
        "        \"title\": \"수강 연장\",\n",
        "        \"text\": \"수강 기간은 마이페이지에서 1개월 단위로 연장할 수 있으며, 연장 시 기존 수강 기록은 그대로 유지됩니다.\"\n",
        "    }\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOOcqiknJhSg",
        "outputId": "891826c4-6bac-4c9a-ebbd-4c23328984b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4, 1536)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### 각 문서를 임베딩으로 변환 -> 벡터 저장\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# 1) 문서 텍스트 리스트\n",
        "doc_texts = [d[\"text\"] for d in docs]\n",
        "\n",
        "# 2) 임베딩 변환\n",
        "emb_res = client.embeddings.create(\n",
        "    model=\"text-embedding-3-small\",\n",
        "    input=doc_texts\n",
        ") # FAQ 4개 → 벡터 4개\n",
        "\n",
        "\n",
        "# 3) numpy 배열로 변환\n",
        "doc_embeddings = np.array([item.embedding for item in emb_res.data])\n",
        "doc_embeddings.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dj3V704rJhPW",
        "outputId": "3d8ba07d-7452-4435-fd6a-da941392bac0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'score': 0.3264114056920408,\n",
              "  'doc': {'id': 1,\n",
              "   'title': '환불 규정',\n",
              "   'text': '우리 회사의 유료 구독은 결제 후 7일 이내에는 전액 환불이 가능하고, 그 이후에는 사용 일수에 따라 부분 환불이 가능합니다.'}},\n",
              " {'score': 0.283685318387456,\n",
              "  'doc': {'id': 3,\n",
              "   'title': '데이터 보관 정책',\n",
              "   'text': '학습 기록과 채팅 데이터는 서비스 품질 향상을 위해 최대 3년간 보관되며, 이용자가 요청할 경우 언제든지 삭제할 수 있습니다.'}}]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### 질문 → 가장 관련 있는 문서들 검색 (간단 코사인 유사도)\n",
        "\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def embed_text(text: str):  # 사용자 질문을 벡터로 변환\n",
        "    res = client.embeddings.create(\n",
        "        model=\"text-embedding-3-small\",\n",
        "        input=[text]\n",
        "    )\n",
        "    return np.array(res.data[0].embedding)\n",
        "\n",
        "\n",
        "def search_docs(query: str, k: int = 3):  # 관련 있는 FAQ 검색 함수\n",
        "    \"\"\"\n",
        "    query를 임베딩하고, 모든 문서와 코사인 유사도를 계산해서\n",
        "    상위 k개 문서를 반환\n",
        "    \"\"\"\n",
        "    q_emb = embed_text(query)  # 질문을 임베딩 벡터로 변환\n",
        "    sim_scores = (doc_embeddings @ q_emb) / (norm(doc_embeddings, axis=1) * norm(q_emb) + 1e-10)\n",
        "           # 코사인 유사도 계산\n",
        "\n",
        "    # 유사도 순으로 정렬\n",
        "    top_idx = np.argsort(sim_scores)[::-1][:k]\n",
        "\n",
        "    results = []\n",
        "    for idx in top_idx:\n",
        "        results.append({\n",
        "            \"score\": float(sim_scores[idx]),\n",
        "            \"doc\": docs[idx]\n",
        "        })\n",
        "    return results\n",
        "\n",
        "# 테스트\n",
        "search_docs(\"환불 기간이 어떻게 되나요?\", k=2)  # 가장 유사한 문서 K개 선택\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09iJTUNoJhMj",
        "outputId": "41eba213-615e-4d93-82c3-5a07e6e65ccc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "결제 후 7일 이내에는 전액 환불이 가능합니다. 7일이 지난 후에는 사용 일수에 따라 부분 환불이 가능하니 참고해 주세요. 추가적인 환불 조건에 대해서는 문서에 없는 내용입니다.\n"
          ]
        }
      ],
      "source": [
        "### RAG 방식으로 프롬프트 구성 + GPT 호출\n",
        "\n",
        "def build_rag_prompt(query: str, retrieved_docs):\n",
        "    \"\"\"\n",
        "    RAG 스타일 프롬프트 문자열을 만들어 주는 함수\n",
        "    \"\"\"\n",
        "    context_blocks = []\n",
        "    for item in retrieved_docs:\n",
        "        d = item[\"doc\"]\n",
        "        block = f\"제목: {d['title']}\\n내용: {d['text']}\"\n",
        "        context_blocks.append(block)\n",
        "\n",
        "    context_text = \"\\n\\n---\\n\\n\".join(context_blocks)\n",
        "\n",
        "    user_message = f\"\"\"\n",
        "아래는 우리 회사의 내부 문서에서 발췌한 내용입니다. 이 컨텍스트를 우선적으로 참고해서 사용자 질문에 답변해 주세요.\n",
        "\n",
        "[컨텍스트 시작]\n",
        "{context_text}\n",
        "[컨텍스트 끝]\n",
        "\n",
        "사용자 질문: {query}\n",
        "\n",
        "답변 시:\n",
        "- 컨텍스트에 있는 정보 위주로 설명하고\n",
        "- 문서에 없는 내용은 추측하지 말고 \"문서에 없는 내용입니다\"라고 말해 주세요.\n",
        "\"\"\"\n",
        "    return user_message\n",
        "\n",
        "\n",
        "def ask_with_rag(query: str):\n",
        "    # 1) 관련 문서 검색\n",
        "    retrieved = search_docs(query, k=3)\n",
        "\n",
        "    # 2) 프롬프트 생성 (컨텍스트 + 질문)\n",
        "    user_content = build_rag_prompt(query, retrieved)\n",
        "\n",
        "    # 3) GPT 호출\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4.1-mini\",  # 또는 gpt-4.1, gpt-4o 등\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"너는 회사 내부 문서를 이용해서 고객 문의에 답변하는 헬프데스크 직원이야.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": user_content\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# 예시 질문\n",
        "print(ask_with_rag(\"이미 결제했는데, 환불은 언제까지 가능한가요?\"))\n",
        "\n",
        "########### RAG : 프롬프트에 지식(문서)을 넣어주는 기법\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ry8lLFYKfcJ",
        "outputId": "e922c9cb-a1cd-4544-a84c-9508697c7eec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "네, 수강 기간은 마이페이지에서 1개월 단위로 연장할 수 있습니다. 연장 시 기존 수강 기록은 그대로 유지됩니다. 추가적인 사항은 문서에 없는 내용입니다.\n"
          ]
        }
      ],
      "source": [
        "# 예시 질문2\n",
        "print(ask_with_rag(\"수강 연장 가능한가요?\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
