{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41d80484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (8.3.228)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from ultralytics) (2.2.6)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from ultralytics) (3.10.7)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from ultralytics) (4.12.0.88)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from ultralytics) (12.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from ultralytics) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.23.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from ultralytics) (2.32.5)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from ultralytics) (1.15.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from ultralytics) (2.7.1+cu118)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from ultralytics) (0.22.1+cu118)\n",
      "Requirement already satisfied: psutil in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from ultralytics) (7.0.0)\n",
      "Requirement already satisfied: polars in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from ultralytics) (1.35.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.18 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from ultralytics) (2.0.18)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
      "Requirement already satisfied: filelock in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: networkx in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.8.86)\n",
      "Requirement already satisfied: triton==3.3.1 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.3.1)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from triton==3.3.1->torch>=1.8.0->ultralytics) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
      "Requirement already satisfied: polars-runtime-32==1.35.2 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from polars->ultralytics) (1.35.2)\n",
      "Requirement already satisfied: ultralytics in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (8.3.228)\n",
      "Requirement already satisfied: Pillow in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (12.0.0)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from ultralytics) (2.2.6)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from ultralytics) (3.10.7)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from ultralytics) (4.12.0.88)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from ultralytics) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.23.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from ultralytics) (2.32.5)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from ultralytics) (1.15.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from ultralytics) (2.7.1+cu118)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from ultralytics) (0.22.1+cu118)\n",
      "Requirement already satisfied: psutil in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from ultralytics) (7.0.0)\n",
      "Requirement already satisfied: polars in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from ultralytics) (1.35.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.18 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from ultralytics) (2.0.18)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
      "Requirement already satisfied: filelock in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: networkx in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.8.86)\n",
      "Requirement already satisfied: triton==3.3.1 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.3.1)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from triton==3.3.1->torch>=1.8.0->ultralytics) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
      "Requirement already satisfied: polars-runtime-32==1.35.2 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from polars->ultralytics) (1.35.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics\n",
    "!pip install ultralytics Pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca90764",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adb7a39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (8.3.228)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from ultralytics) (2.2.6)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from ultralytics) (3.10.7)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from ultralytics) (4.12.0.88)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from ultralytics) (12.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from ultralytics) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.23.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from ultralytics) (2.32.5)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from ultralytics) (1.15.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from ultralytics) (2.7.1+cu118)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from ultralytics) (0.22.1+cu118)\n",
      "Requirement already satisfied: psutil in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from ultralytics) (7.0.0)\n",
      "Requirement already satisfied: polars in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from ultralytics) (1.35.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.18 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from ultralytics) (2.0.18)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
      "Requirement already satisfied: filelock in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: networkx in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.8.86)\n",
      "Requirement already satisfied: triton==3.3.1 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.3.1)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from triton==3.3.1->torch>=1.8.0->ultralytics) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
      "Requirement already satisfied: polars-runtime-32==1.35.2 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from polars->ultralytics) (1.35.2)\n",
      "Requirement already satisfied: opencv-python in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from opencv-python) (2.2.6)\n",
      "Requirement already satisfied: pillow in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (12.0.0)\n",
      "Requirement already satisfied: tqdm in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (4.67.1)\n",
      "Requirement already satisfied: pyyaml in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (6.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics\n",
    "!pip install opencv-python\n",
    "!pip install pillow\n",
    "!pip install tqdm\n",
    "!pip install pyyaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc830289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "from ultralytics import YOLO\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],   # ë˜ëŠ” ['http://localhost:4478']\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 1) YOLO ì–¼êµ´ ê²€ì¶œ ëª¨ë¸ ë¡œë“œ\n",
    "# ================================\n",
    "print(\"ğŸ“¥ YOLOv8 Face ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘...\")\n",
    "\n",
    "yolo_path = hf_hub_download(\n",
    "    repo_id=\"Reshma67/yolov8-face-detection\",\n",
    "    filename=\"model.pt\"\n",
    ")\n",
    "yolo_model = YOLO(yolo_path)\n",
    "\n",
    "# ================================\n",
    "# 2) ResNetCBAM ì •ì˜\n",
    "# ================================\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc(self.avg_pool(x))\n",
    "        max_out = self.fc(self.max_pool(x))\n",
    "        return self.sigmoid(avg_out + max_out)\n",
    "\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x_cat = torch.cat([avg_out, max_out], dim=1)\n",
    "        return self.sigmoid(self.conv1(x_cat))\n",
    "\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, in_planes):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.ca = ChannelAttention(in_planes)\n",
    "        self.sa = SpatialAttention()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x * self.ca(x)\n",
    "        x = x * self.sa(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNetCBAM(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(ResNetCBAM, self).__init__()\n",
    "\n",
    "        base = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "        self.conv1 = base.conv1\n",
    "        self.bn1 = base.bn1\n",
    "        self.relu = base.relu\n",
    "        self.maxpool = base.maxpool\n",
    "\n",
    "        self.layer1 = base.layer1\n",
    "        self.layer2 = base.layer2\n",
    "        self.cbam2 = CBAM(128)\n",
    "        self.layer3 = base.layer3\n",
    "        self.cbam3 = CBAM(256)\n",
    "        self.layer4 = base.layer4\n",
    "\n",
    "        self.avgpool = base.avgpool\n",
    "        self.fc = nn.Linear(base.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.cbam2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.cbam3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 3) ResNetCBAM ëª¨ë¸ ë¡œë“œ\n",
    "# ================================\n",
    "emotion_model = ResNetCBAM(num_classes=2)\n",
    "emotion_model.load_state_dict(torch.load(\"Res_CBAM_v3_epc50.pth\", map_location=\"cuda\"))\n",
    "emotion_model.eval()\n",
    "emotion_model.cuda()\n",
    "\n",
    "# ================================\n",
    "# 4) ì´ë¯¸ì§€ ë³€í™˜\n",
    "# ================================\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        [0.485, 0.456, 0.406],\n",
    "        [0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# ================================\n",
    "# 5) ìš”ì²­ body\n",
    "# ================================\n",
    "class Frame(BaseModel):\n",
    "    image: str  # base64\n",
    "\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "def predict(frame: Frame):\n",
    "    base64_data = frame.image.split(\",\")[-1]\n",
    "    img_bytes = base64.b64decode(base64_data)\n",
    "    img = Image.open(io.BytesIO(img_bytes)).convert(\"RGB\")\n",
    "    img_np = np.array(img)\n",
    "\n",
    "    # YOLO ì–¼êµ´ ê²€ì¶œ\n",
    "    results = yolo_model.predict(img_np, imgsz=320, device=0, verbose=False)\n",
    "    boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "\n",
    "    if len(boxes) == 0:\n",
    "        print(\"â›” No face detected â†’ OTHER(0.0)\")\n",
    "        return {\"emotion\": \"other\", \"prob\": 0.0}\n",
    "\n",
    "    x1, y1, x2, y2 = sorted(\n",
    "        boxes, key=lambda b: (b[2]-b[0])*(b[3]-b[1]), reverse=True\n",
    "    )[0]\n",
    "    x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "\n",
    "    crop = img_np[y1:y2, x1:x2]\n",
    "    if crop.size == 0:\n",
    "        print(\"â›” Crop empty â†’ OTHER(0.0)\")\n",
    "        return {\"emotion\": \"other\", \"prob\": 0.0}\n",
    "\n",
    "    # Transform + Predict\n",
    "    crop_tensor = transform(Image.fromarray(crop)).unsqueeze(0).cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = emotion_model(crop_tensor)\n",
    "        prob = torch.softmax(output, dim=1)[0][1].item()\n",
    "\n",
    "        label = \"laugh\" if prob > 0.5 else \"other\"\n",
    "        print(f\"PREDICT â†’ {label.upper()} ({prob:.4f})\")\n",
    "\n",
    "        return {\"emotion\": label, \"prob\": prob}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dfd949",
   "metadata": {},
   "source": [
    "ì „ì²´ì½”ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f2e199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ce0b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "\n",
    "# Ultralytics (YOLO) & HuggingFace\n",
    "from ultralytics import YOLO\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# ================================\n",
    "# 0) ì„¤ì • ë° ì•± ì´ˆê¸°í™”\n",
    "# ================================\n",
    "app = FastAPI()\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],  # ë³´ì•ˆìƒ í•„ìš”ì‹œ íŠ¹ì • ë„ë©”ì¸ìœ¼ë¡œ ì œí•œ ê¶Œì¥\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "# ë””ë°”ì´ìŠ¤ ì„¤ì • (GPU ìš°ì„ )\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"ğŸš€ Device set to: {device}\")\n",
    "\n",
    "# ================================\n",
    "# 1) YOLO ì–¼êµ´ ê²€ì¶œ ëª¨ë¸ ë¡œë“œ\n",
    "# ================================\n",
    "print(\"ğŸ“¥ [1/2] Loading Face Detection Model (YOLOv8-Face)...\")\n",
    "\n",
    "try:\n",
    "    # HuggingFaceì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ìµœì´ˆ 1íšŒë§Œ ë‹¤ìš´ë¡œë“œë¨)\n",
    "    face_model_path = hf_hub_download(\n",
    "        repo_id=\"Reshma67/yolov8-face-detection\",\n",
    "        filename=\"model.pt\"\n",
    "    )\n",
    "    face_model = YOLO(face_model_path)\n",
    "    print(\"âœ… Face Model Loaded.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Face Model Load Error: {e}\")\n",
    "    raise e\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 2) YOLO ê°ì • ë¶„ë¥˜ ëª¨ë¸ (Da4) ë¡œë“œ\n",
    "# ================================\n",
    "# [ì¤‘ìš”] í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ëª…ì´ 'Da4.pt' í˜¹ì€ 'best.pt'ë¼ê³  ê°€ì •í•©ë‹ˆë‹¤.\n",
    "# ì‹¤ì œ íŒŒì¼ ê²½ë¡œì— ë§ê²Œ ìˆ˜ì •í•´ì£¼ì„¸ìš”.\n",
    "EMOTION_MODEL_PATH = \"Da4.pt\" \n",
    "\n",
    "print(f\"ğŸ“¥ [2/2] Loading Emotion Classification Model ({EMOTION_MODEL_PATH})...\")\n",
    "\n",
    "try:\n",
    "    # ì‚¬ìš©ì ì§€ì • YOLO ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ\n",
    "    emotion_model = YOLO(EMOTION_MODEL_PATH)\n",
    "    emotion_model.to(device)\n",
    "    print(\"âœ… Emotion Model Loaded.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Emotion Model Load Error (ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”): {e}\")\n",
    "    # íŒŒì¼ì´ ì—†ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ì˜ˆì™¸ ì²˜ë¦¬ í•„ìš” (í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë¡œì§ ë“±)\n",
    "    emotion_model = None\n",
    "\n",
    "# ================================\n",
    "# 3) ìš”ì²­ ë°ì´í„° ëª¨ë¸ ì •ì˜\n",
    "# ================================\n",
    "class Frame(BaseModel):\n",
    "    image: str  # Base64 Encoded Image String\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 4) ì¶”ë¡  ì—”ë“œí¬ì¸íŠ¸\n",
    "# ================================\n",
    "@app.post(\"/predict\")\n",
    "def predict(frame: Frame):\n",
    "    \"\"\"\n",
    "    ì´ë¯¸ì§€ë¥¼ ë°›ì•„ ì–¼êµ´ì„ ê²€ì¶œí•˜ê³ , í•´ë‹¹ ì–¼êµ´ì˜ ê°ì •ì„ ë¶„ë¥˜í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    # 1. Base64 ë””ì½”ë”© -> ì´ë¯¸ì§€ ë³€í™˜\n",
    "    try:\n",
    "        base64_data = frame.image.split(\",\")[-1]\n",
    "        img_bytes = base64.b64decode(base64_data)\n",
    "        pil_img = Image.open(io.BytesIO(img_bytes)).convert(\"RGB\")\n",
    "        img_np = np.array(pil_img)\n",
    "    except Exception as e:\n",
    "        return {\"emotion\": \"error\", \"prob\": 0.0, \"msg\": \"Invalid Image Data\"}\n",
    "\n",
    "    # 2. ì–¼êµ´ ê²€ì¶œ (Face Detection)\n",
    "    # imgsz=320 ë“±ìœ¼ë¡œ ì†ë„ ìµœì í™” ê°€ëŠ¥\n",
    "    face_results = face_model.predict(img_np, imgsz=320, device=device, verbose=False, conf=0.5)\n",
    "    boxes = face_results[0].boxes.xyxy.cpu().numpy()\n",
    "\n",
    "    # ì–¼êµ´ì´ ì—†ìœ¼ë©´ 'other' ë°˜í™˜\n",
    "    if len(boxes) == 0:\n",
    "        print(\"â›” No face detected\")\n",
    "        return {\"emotion\": \"other\", \"prob\": 0.0}\n",
    "\n",
    "    # 3. ê°€ì¥ í° ì–¼êµ´ ì˜ì—­ ì„ íƒ (ì¤‘ì‹¬ í˜¹ì€ ë©´ì  ê¸°ì¤€)\n",
    "    # (x1, y1, x2, y2)\n",
    "    largest_face = sorted(boxes, key=lambda b: (b[2] - b[0]) * (b[3] - b[1]), reverse=True)[0]\n",
    "    x1, y1, x2, y2 = map(int, largest_face)\n",
    "\n",
    "    # ì¢Œí‘œê°€ ì´ë¯¸ì§€ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ì§€ ì•Šë„ë¡ í´ë¦½\n",
    "    h, w, _ = img_np.shape\n",
    "    x1, y1 = max(0, x1), max(0, y1)\n",
    "    x2, y2 = min(w, x2), min(h, y2)\n",
    "\n",
    "    # 4. ì–¼êµ´ ì˜ì—­ Crop\n",
    "    face_crop = img_np[y1:y2, x1:x2]\n",
    "    \n",
    "    # Crop ëœ ì´ë¯¸ì§€ê°€ ë„ˆë¬´ ì‘ê±°ë‚˜ ë¹„ì–´ìˆìœ¼ë©´ ì²˜ë¦¬\n",
    "    if face_crop.size == 0 or face_crop.shape[0] < 10 or face_crop.shape[1] < 10:\n",
    "        print(\"â›” Face crop too small\")\n",
    "        return {\"emotion\": \"other\", \"prob\": 0.0}\n",
    "\n",
    "    # 5. ê°ì • ë¶„ë¥˜ (Emotion Classification - Da4 Model)\n",
    "    if emotion_model:\n",
    "        # YOLO ë¶„ë¥˜ ëª¨ë¸ì€ ë‚´ë¶€ì ìœ¼ë¡œ ë¦¬ì‚¬ì´ì§• ë° ì •ê·œí™”ë¥¼ ìˆ˜í–‰í•˜ë¯€ë¡œ ì›ë³¸ Crop ì „ë‹¬ ê°€ëŠ¥\n",
    "        cls_results = emotion_model.predict(face_crop, device=device, verbose=False)\n",
    "        \n",
    "        # ê²°ê³¼ íŒŒì‹±\n",
    "        probs = cls_results[0].probs  # í™•ë¥  ê°ì²´\n",
    "        top1_index = probs.top1       # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ í´ë˜ìŠ¤ ì¸ë±ìŠ¤\n",
    "        top1_conf = probs.top1conf.item() # ê°€ì¥ ë†’ì€ í™•ë¥  ê°’ (tensor -> float)\n",
    "        \n",
    "        # í´ë˜ìŠ¤ ì´ë¦„ ë§¤í•‘ (ëª¨ë¸ ë‚´ë¶€ì— ì €ì¥ëœ names ì‚¬ìš©)\n",
    "        class_names = cls_results[0].names\n",
    "        pred_label = class_names[top1_index]\n",
    "\n",
    "        # í™•ë¥ ê°’ í¬ë§·íŒ…\n",
    "        prob_val = round(top1_conf, 4)\n",
    "\n",
    "        print(f\"ğŸ‘ï¸ Detect: {pred_label.upper()} ({prob_val})\")\n",
    "\n",
    "        return {\n",
    "            \"emotion\": pred_label,  # ì˜ˆ: 'happy', 'anger', 'neutral' ë“±\n",
    "            \"prob\": prob_val\n",
    "        }\n",
    "    else:\n",
    "        # ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œ\n",
    "        return {\"emotion\": \"error\", \"prob\": 0.0, \"msg\": \"Model not loaded\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a79cb4",
   "metadata": {},
   "source": [
    "crop+yoloëª¨ë¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3533e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "import random\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# ==============================================================\n",
    "# 1. ì„¤ì • ë° ë°ì´í„° ê²½ë¡œ (ìš”ì²­í•˜ì‹  ì£¼ì†Œë¡œ ì—…ë°ì´íŠ¸ë¨)\n",
    "# ==============================================================\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "NUM_EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-4\n",
    "IMG_SIZE = 224\n",
    "MODEL_SAVE_PATH = \"best_emotion_model.pt\"\n",
    "CSV_PATH = \"training_log.csv\"\n",
    "IMG_SAVE_DIR = Path(\"epoch_previews\")\n",
    "IMG_SAVE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# í´ë˜ìŠ¤ ì •ì˜\n",
    "CLASSES = [\"happy\", \"average\", \"other\"]\n",
    "CLASS_TO_ID = {cls: i for i, cls in enumerate(CLASSES)}\n",
    "ID_TO_CLASS = {i: cls for i, cls in enumerate(CLASSES)}\n",
    "\n",
    "# [ìš”ì²­] ì—…ë°ì´íŠ¸ëœ í•™ìŠµ ë°ì´í„° ê²½ë¡œ\n",
    "TRAIN_SOURCES = {\n",
    "    \"happy\": {\n",
    "        \"happy\": {\n",
    "            \"img_dir\": \"/workspace/user4/segmented_output_bisenet/train/happy\",\n",
    "            \"json_path\": \"/workspace/merge_data/new_data/label/happy_half.json\"\n",
    "        }\n",
    "    },\n",
    "    \"average\": {\n",
    "        \"anger\": {\n",
    "            \"img_dir\": \"/workspace/user4/segmented_output_bisenet/train/anger\",\n",
    "            \"json_path\": \"/workspace/merge_data/data/label/train/train_anger.json\"\n",
    "        }\n",
    "    },\n",
    "    \"other\": {\n",
    "        \"panic\": {\n",
    "            \"img_dir\": \"/workspace/user4/segmented_output_bisenet/train/panic\",\n",
    "            \"json_path\": \"/workspace/merge_data/data/label/train/train_panic.json\"\n",
    "        },\n",
    "        \"sadness\": {\n",
    "            \"img_dir\": \"/workspace/user4/segmented_output_bisenet/train/sadness\",\n",
    "            \"json_path\": \"/workspace/merge_data/data/label/train/train_sadness.json\"\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "# [ìš”ì²­] ì—…ë°ì´íŠ¸ëœ ê²€ì¦ ë°ì´í„° ê²½ë¡œ\n",
    "human = {\n",
    "    \"happy\": {\n",
    "        \"happy\": {\n",
    "            \"img_dir\": \"/workspace/user4/segmented_output_bisenet/val/happy\",\n",
    "           \n",
    "        }\n",
    "    }\n",
    "   \n",
    "}\n",
    "\n",
    "# ==============================================================\n",
    "# 2. ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ë° ìœ í‹¸ë¦¬í‹°\n",
    "# ==============================================================\n",
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, sources, transform=None):\n",
    "        self.transform = transform\n",
    "        self.samples = []  # (img_path, label_id, confidence)\n",
    "\n",
    "        for label_str, sub_dict in sources.items():\n",
    "            label_id = CLASS_TO_ID[label_str]\n",
    "            \n",
    "            for sub_emotion, paths in sub_dict.items():\n",
    "                img_dir = Path(paths[\"img_dir\"])\n",
    "                json_path = paths[\"json_path\"]\n",
    "                \n",
    "                # JSON ë¡œë“œ (íŒŒì¼ êµ¬ì¡°ì— ë”°ë¼ ìˆ˜ì • í•„ìš”í•  ìˆ˜ ìˆìŒ)\n",
    "                try:\n",
    "                    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "                        data = json.load(f)\n",
    "                        \n",
    "                    # JSON êµ¬ì¡°ê°€ ë¦¬ìŠ¤íŠ¸ì¸ì§€ ë”•ì…”ë„ˆë¦¬ì¸ì§€ì— ë”°ë¼ ì²˜ë¦¬\n",
    "                    # ê°€ì •: [{\"filename\": \"a.jpg\", \"confidence\": 1.0}, ...] í˜•íƒœë¼ê³  ê°€ì •\n",
    "                    # ì‹¤ì œ ë°ì´í„° í¬ë§·ì— ë§ê²Œ íŒŒì‹± ë¡œì§ì„ ì¡°ì •í•˜ì„¸ìš”.\n",
    "                    items = data if isinstance(data, list) else data.get('images', [])\n",
    "                    \n",
    "                    for item in items:\n",
    "                        # íŒŒì¼ëª… í‚¤ ì°¾ê¸° (filename, file_name ë“±)\n",
    "                        fname = item.get('filename') or item.get('file_name')\n",
    "                        if not fname: continue\n",
    "                        \n",
    "                        # confidence í‚¤ (ì—†ìœ¼ë©´ 1.0)\n",
    "                        conf = float(item.get('confidence', 1.0))\n",
    "                        \n",
    "                        full_path = img_dir / fname\n",
    "                        if full_path.exists():\n",
    "                            self.samples.append((str(full_path), label_id, conf))\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    print(f\"âš ï¸ Warning: Failed to load {json_path} or parse data: {e}\")\n",
    "\n",
    "        print(f\"âœ… Loaded {len(self.samples)} samples.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label_id, conf = self.samples[idx]\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "        except Exception:\n",
    "            # ì—ëŸ¬ ë°œìƒ ì‹œ ê²€ì€ìƒ‰ ì´ë¯¸ì§€ ë°˜í™˜\n",
    "            image = torch.zeros((3, IMG_SIZE, IMG_SIZE))\n",
    "        \n",
    "        return image, torch.tensor(label_id, dtype=torch.long), torch.tensor(conf, dtype=torch.float)\n",
    "\n",
    "\n",
    "def get_transforms(is_train=True):\n",
    "    if is_train:\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            # ImageNet Norm\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    else:\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "# ==============================================================\n",
    "# 3. [ìš”ì²­ ê¸°ëŠ¥] ì‹œê°í™” í•¨ìˆ˜ (íŒŒë€ìƒ‰ ë°•ìŠ¤ ìŠ¤íƒ€ì¼)\n",
    "# ==============================================================\n",
    "def save_epoch_preview(model, val_loader, epoch, device, save_dir):\n",
    "    \"\"\"\n",
    "    ê²€ì¦ ë°°ì¹˜ë¥¼ í•˜ë‚˜ ê°€ì ¸ì™€ì„œ ì‹œê°í™” ì´ë¯¸ì§€ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "    ìš”ì²­í•˜ì‹  íŒŒë€ìƒ‰ ë°°ê²½ í…ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ì„ ì ìš©í–ˆìŠµë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    try:\n",
    "        # ë°°ì¹˜ í•˜ë‚˜ ê°€ì ¸ì˜¤ê¸°\n",
    "        imgs, lbls, confs = next(iter(val_loader))\n",
    "    except StopIteration:\n",
    "        return\n",
    "\n",
    "    imgs, lbls = imgs.to(device), lbls.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(imgs)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        preds = torch.argmax(probs, dim=1)\n",
    "        conf_values, _ = torch.max(probs, dim=1) # ëª¨ë¸ì´ ì˜ˆì¸¡í•œ í™•ë¥ \n",
    "\n",
    "    # ì—­ì •ê·œí™” (ì‹œê°í™”ë¥¼ ìœ„í•´)\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1).to(device)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1).to(device)\n",
    "    imgs_vis = imgs * std + mean\n",
    "    imgs_vis = torch.clamp(imgs_vis, 0, 1)\n",
    "\n",
    "    # [ìš”ì²­í•˜ì‹  Matplotlib ì½”ë“œ ì ìš©]\n",
    "    cols = 4\n",
    "    rows = 4\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    \n",
    "    batch_limit = min(cols * rows, len(imgs))\n",
    "    \n",
    "    for i in range(batch_limit):\n",
    "        ax = plt.subplot(rows, cols, i+1)\n",
    "        # Tensor -> Numpy (H, W, C)\n",
    "        img_np = imgs_vis[i].cpu().permute(1, 2, 0).numpy()\n",
    "        plt.imshow(img_np)\n",
    "        \n",
    "        pred_cls = ID_TO_CLASS[preds[i].item()]\n",
    "        true_cls = ID_TO_CLASS[lbls[i].item()]\n",
    "        model_conf = conf_values[i].item()\n",
    "        \n",
    "        # í…ìŠ¤íŠ¸: P(ì˜ˆì¸¡), T(ì •ë‹µ), í™•ë¥ \n",
    "        label_text = f\"P:{pred_cls}\\nT:{true_cls}\\n{model_conf:.2f}\"\n",
    "        \n",
    "        # [ìŠ¤íƒ€ì¼] íŒŒë€ìƒ‰ ë°°ê²½, í°ìƒ‰ ê¸€ì”¨, ì¢Œì¸¡ ìƒë‹¨ (ìš”ì²­ì‚¬í•­)\n",
    "        plt.text(\n",
    "            x=5, y=5,\n",
    "            s=label_text,\n",
    "            color='white',\n",
    "            fontsize=9,\n",
    "            fontweight='bold',\n",
    "            verticalalignment='top',\n",
    "            bbox=dict(facecolor='blue', alpha=0.8, edgecolor='none', pad=2)\n",
    "        )\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = save_dir / f\"epoch_{epoch:03d}_preview.png\"\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\" ğŸ–¼ï¸ Preview saved: {save_path}\")\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# 4. ë©”ì¸ í•™ìŠµ ë£¨í”„\n",
    "# ==============================================================\n",
    "def main():\n",
    "    print(f\"ğŸš€ Device: {DEVICE}\")\n",
    "    \n",
    "    # ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "    print(\"Loading Train Data...\")\n",
    "    train_dataset = EmotionDataset(TRAIN_SOURCES, transform=get_transforms(is_train=True))\n",
    "    print(\"Loading Val Data...\")\n",
    "    val_dataset = EmotionDataset(human, transform=get_transforms(is_train=False))\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "    # ëª¨ë¸ ì •ì˜ (ResNet18 ì˜ˆì‹œ)\n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "    model.fc = nn.Linear(model.fc.in_features, len(CLASSES))\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(reduction='none') # Weak supervisionì„ ìœ„í•´ none ì„¤ì •\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    # CSV í—¤ë” ì‘ì„±\n",
    "    with open(CSV_PATH, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Epoch', 'Train_Loss', 'Val_Loss', 'Val_Acc', 'F1_Macro', 'F1_Happy', 'F1_Avg', 'F1_Other'])\n",
    "\n",
    "    # [ìš”ì²­] best_f1 ì´ˆê¸°í™”\n",
    "    best_f1 = 0.0\n",
    "\n",
    "    print(\"ğŸ Start Training...\")\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        # --- Train ---\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        loop = tqdm(train_loader, desc=f\"Ep {epoch+1}/{NUM_EPOCHS}\")\n",
    "        for imgs, lbls, confs in loop:\n",
    "            imgs, lbls, confs = imgs.to(DEVICE), lbls.to(DEVICE), confs.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            logits = model(imgs)\n",
    "            \n",
    "            # Loss ê³„ì‚°\n",
    "            raw_loss = criterion(logits, lbls)\n",
    "            # [ìš”ì²­] Weak Supervision: Loss * Confidence\n",
    "            loss = (raw_loss * confs).mean()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        # --- Validation ---\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        preds_list, trues_list = [], []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for imgs, lbls, confs in val_loader:\n",
    "                imgs, lbls, confs = imgs.to(DEVICE), lbls.to(DEVICE), confs.to(DEVICE)\n",
    "                \n",
    "                logits = model(imgs)\n",
    "                raw_loss = criterion(logits, lbls)\n",
    "                loss = (raw_loss * confs).mean()\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                probs = F.softmax(logits, dim=1)\n",
    "                preds = torch.argmax(probs, dim=1)\n",
    "                \n",
    "                preds_list.extend(preds.cpu().numpy())\n",
    "                trues_list.extend(lbls.cpu().numpy())\n",
    "\n",
    "        # --- Metrics ---\n",
    "        val_acc = (np.array(preds_list) == np.array(trues_list)).mean()\n",
    "        f1_macro = f1_score(trues_list, preds_list, average='macro', zero_division=0)\n",
    "        f1_per_class = f1_score(trues_list, preds_list, average=None, zero_division=0)\n",
    "        \n",
    "        # í´ë˜ìŠ¤ë³„ F1 Score (ì¸ë±ìŠ¤ ìˆœì„œì— ì£¼ì˜)\n",
    "        happy_f1 = f1_per_class[CLASS_TO_ID[\"happy\"]] if len(f1_per_class) > CLASS_TO_ID[\"happy\"] else 0.0\n",
    "        avg_f1 = f1_per_class[CLASS_TO_ID[\"average\"]] if len(f1_per_class) > CLASS_TO_ID[\"average\"] else 0.0\n",
    "        other_f1 = f1_per_class[CLASS_TO_ID[\"other\"]] if len(f1_per_class) > CLASS_TO_ID[\"other\"] else 0.0\n",
    "\n",
    "        print(f\" -> Val Acc: {val_acc:.4f} | F1 Macro: {f1_macro:.4f}\")\n",
    "        print(f\" -> [Happy]: {happy_f1:.4f} | [Avg]: {avg_f1:.4f} | [Other]: {other_f1:.4f}\")\n",
    "\n",
    "        # --- Logging ---\n",
    "        with open(CSV_PATH, 'a', newline='') as f:\n",
    "            csv.writer(f).writerow([\n",
    "                epoch+1, \n",
    "                train_loss/len(train_loader), \n",
    "                val_loss/len(val_loader), \n",
    "                val_acc, \n",
    "                f1_macro, \n",
    "                happy_f1, \n",
    "                avg_f1, \n",
    "                other_f1\n",
    "            ])\n",
    "        \n",
    "        # [ìš”ì²­] ì‹œê°í™” ì €ì¥ (íŒŒë€ ë°•ìŠ¤ ìŠ¤íƒ€ì¼ ì ìš©ë¨)\n",
    "        save_epoch_preview(model, val_loader, epoch+1, DEVICE, IMG_SAVE_DIR)\n",
    "\n",
    "        # [ìš”ì²­] ëª¨ë¸ ì €ì¥ (Best F1 ê¸°ì¤€)\n",
    "        if f1_macro > best_f1:\n",
    "            best_f1 = f1_macro\n",
    "            torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "            print(f\" -> â­ Best Model Saved! (New F1: {best_f1:.4f})\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tomas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
