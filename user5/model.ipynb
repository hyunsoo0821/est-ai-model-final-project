{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b85a2b1",
   "metadata": {},
   "source": [
    "1Ï∞®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2317a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 0. Í∏∞Î≥∏ ÌôòÍ≤Ω ÏÑ§Ï†ï\n",
    "# ============================================================\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def safe_load_image(path):\n",
    "    \"\"\"Í≥†ÏÜç Î°úÎî© + Íπ®ÏßÑ JPEG ÏûêÎèô Ï≤òÎ¶¨\"\"\"\n",
    "    try:\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "            img = np.array(img)\n",
    "        else:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        return img\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "class FastHappyDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.paths = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "\n",
    "        for emo in os.listdir(root_dir):\n",
    "            emo_dir = os.path.join(root_dir, emo)\n",
    "            if not os.path.isdir(emo_dir):\n",
    "                continue\n",
    "\n",
    "            label = 1 if emo == \"happy\" else 0\n",
    "\n",
    "            for f in os.listdir(emo_dir):\n",
    "                if f.lower().endswith((\"jpg\", \"jpeg\", \"png\")):\n",
    "                    self.paths.append(os.path.join(emo_dir, f))\n",
    "                    self.labels.append(label)\n",
    "\n",
    "        print(f\"Loaded {len(self.paths)} images from {root_dir}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        img = safe_load_image(path)\n",
    "        if img is None:\n",
    "            return self.__getitem__((idx + 1) % len(self.paths))\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)[\"image\"]\n",
    "\n",
    "        return img, torch.tensor(label).long()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. Albumentations Transform\n",
    "# ============================================================\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. Dataset & DataLoader\n",
    "# ============================================================\n",
    "train_root = \"/workspace/merge_data/data/img/train\"\n",
    "val_root   = \"/workspace/merge_data/data/img/val\"\n",
    "\n",
    "train_dataset = FastHappyDataset(train_root, transform=transform)\n",
    "val_dataset   = FastHappyDataset(val_root, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=4,\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=4,\n",
    ")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. MobileViT-S Î™®Îç∏ Î∂àÎü¨Ïò§Í∏∞\n",
    "# ============================================================\n",
    "from torchvision.models import mobilevit_s\n",
    "\n",
    "model = mobilevit_s(weights=\"IMAGENET1K_V1\")  # pretrained\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(640, 2)   # MobileViT-S output dim = 640\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "print(\"Model loaded on:\", next(model.parameters()).device)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. Optimizer & Loss\n",
    "# ============================================================\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-5, weight_decay=1e-5)\n",
    "\n",
    "scaler = torch.amp.GradScaler(\"cuda\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. ÌïôÏäµ Ìï®Ïàò\n",
    "# ============================================================\n",
    "def train_one_epoch():\n",
    "    model.train()\n",
    "    total_loss, total_correct, total_samples = 0, 0, 0\n",
    "\n",
    "    for imgs, labels in tqdm(train_loader, desc=\"Train\"):\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.amp.autocast(\"cuda\"):\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        total_correct += (preds == labels).sum().item()\n",
    "        total_loss += loss.item() * labels.size(0)\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    return total_loss / total_samples, total_correct / total_samples\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6. Í≤ÄÏ¶ù Ìï®Ïàò\n",
    "# ============================================================\n",
    "def validate():\n",
    "    model.eval()\n",
    "    total_loss, total_correct, total_samples = 0, 0, 0\n",
    "\n",
    "    with torch.inference_mode(), torch.amp.autocast(\"cuda\"):\n",
    "        for imgs, labels in tqdm(val_loader, desc=\"Validation\"):\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            preds = outputs.argmax(dim=1)\n",
    "\n",
    "            total_correct += (preds == labels).sum().item()\n",
    "            total_loss += loss.item() * labels.size(0)\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    return total_loss / total_samples, total_correct / total_samples\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 7. Ï†ÑÏ≤¥ ÌïôÏäµ Î£®ÌîÑ\n",
    "# ============================================================\n",
    "num_epochs = 10\n",
    "best_acc = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\n===== Epoch {epoch+1}/{num_epochs} =====\")\n",
    "\n",
    "    train_loss, train_acc = train_one_epoch()\n",
    "    val_loss, val_acc     = validate()\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val   Loss: {val_loss:.4f} | Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"mobilevit_s_fastloader_best.pth\")\n",
    "        print(\"üíæ Best model saved!\")\n",
    "\n",
    "print(f\"\\nüéâ Training Completed ‚Äî Best Val Acc: {best_acc:.4f}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 8. ÌèâÍ∞Ä ÏÑ±Îä• Ï∂úÎ†•\n",
    "# ============================================================\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.inference_mode(), torch.amp.autocast(\"cuda\"):\n",
    "    for imgs, labels in tqdm(val_loader, desc=\"Final Evaluation\"):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        outputs = model(imgs)\n",
    "        preds = outputs.argmax(1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().tolist())\n",
    "        all_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "acc  = accuracy_score(all_labels, all_preds)\n",
    "prec = precision_score(all_labels, all_preds, zero_division=0)\n",
    "rec  = recall_score(all_labels, all_preds, zero_division=0)\n",
    "f1   = f1_score(all_labels, all_preds, zero_division=0)\n",
    "\n",
    "print(\"\\n===== Final Metrics =====\")\n",
    "print(f\"Accuracy:  {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, digits=4))\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[\"Not Happy (0)\", \"Happy (1)\"],\n",
    "            yticklabels=[\"Not Happy (0)\", \"Happy (1)\"])\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc65471",
   "metadata": {},
   "source": [
    "2Ï∞®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341f1f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    MobileViTImageProcessor,\n",
    "    MobileViTForImageClassification,\n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# 1. SEED Í≥†Ï†ï\n",
    "# =====================================================\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 2. DATASET\n",
    "# =====================================================\n",
    "class HappyDataset(Dataset):\n",
    "    def __init__(self, root_dir, processor):\n",
    "        self.root_dir = root_dir\n",
    "        self.processor = processor\n",
    "        self.samples = []\n",
    "\n",
    "        classes = sorted(os.listdir(root_dir))  # [\"happy\", \"other\"]\n",
    "        self.class_to_idx = {c: i for i, c in enumerate(classes)}\n",
    "\n",
    "        for cls in classes:\n",
    "            folder = os.path.join(root_dir, cls)\n",
    "            for file in os.listdir(folder):\n",
    "                if file.lower().endswith((\"jpg\", \"jpeg\", \"png\")):\n",
    "                    self.samples.append(\n",
    "                        (os.path.join(folder, file), self.class_to_idx[cls])\n",
    "                    )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "\n",
    "        processed = self.processor(images=img, return_tensors=\"pt\")\n",
    "        pixel_values = processed[\"pixel_values\"].squeeze(0)\n",
    "\n",
    "        return pixel_values, torch.tensor(label)\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 3. LOAD Processor & Model  ‚Üê MobileViT\n",
    "# =====================================================\n",
    "processor = MobileViTImageProcessor.from_pretrained(\n",
    "    \"apple/mobilevit-small\"\n",
    ")\n",
    "\n",
    "model = MobileViTForImageClassification.from_pretrained(\n",
    "    \"apple/mobilevit-small\",\n",
    "    num_labels=2,\n",
    "    ignore_mismatched_sizes=True\n",
    ").to(device)\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 4. PATHS\n",
    "# =====================================================\n",
    "train_root = \"/workspace/merge_data_binary/new_data/img_binary\"\n",
    "val_root   = \"/workspace/merge_data_binary/new_data_val/img_binary\"\n",
    "\n",
    "train_dataset = HappyDataset(train_root, processor)\n",
    "val_dataset   = HappyDataset(val_root, processor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=8)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=8)\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 5. Optimizer\n",
    "# =====================================================\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-5)\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 6. TRAINING LOOP\n",
    "# =====================================================\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    pbar = tqdm(train_loader, desc=f\"[Epoch {epoch+1}] Training\")\n",
    "    for pixel_values, labels in pbar:\n",
    "        pixel_values = pixel_values.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({\"loss\": loss.item()})\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"\\n[Epoch {epoch+1}] Train Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # -------------------------\n",
    "    # Validation\n",
    "    # -------------------------\n",
    "    model.eval()\n",
    "    preds, gts = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for pixel_values, labels in tqdm(val_loader, desc=\"Validating\"):\n",
    "            pixel_values = pixel_values.to(device)\n",
    "            outputs = model(pixel_values=pixel_values)\n",
    "\n",
    "            pred = outputs.logits.argmax(dim=1).cpu()\n",
    "            preds.extend(pred.tolist())\n",
    "            gts.extend(labels.tolist())\n",
    "\n",
    "    # ============================\n",
    "    # METRICS\n",
    "    # ============================\n",
    "    acc = accuracy_score(gts, preds)\n",
    "    prec = precision_score(gts, preds, average=\"binary\")\n",
    "    rec = recall_score(gts, preds, average=\"binary\")\n",
    "    f1 = f1_score(gts, preds, average=\"binary\")\n",
    "    cm = confusion_matrix(gts, preds)\n",
    "\n",
    "    print(\"\\n========== METRICS ==========\")\n",
    "    print(f\"Accuracy  : {acc:.4f}\")\n",
    "    print(f\"Precision : {prec:.4f}\")\n",
    "    print(f\"Recall    : {rec:.4f}\")\n",
    "    print(f\"F1-Score  : {f1:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(\"============================\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79aae3ac",
   "metadata": {},
   "source": [
    "3Ï∞®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9acb2006",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MobileViTForImageClassification were not initialized from the model checkpoint at apple/mobilevit-small and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 640]) in the checkpoint and torch.Size([4, 640]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[Epoch 1] Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 183/183 [01:43<00:00,  1.76it/s, loss=1.33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 1] Train Loss: 1.3666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:22<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== METRICS ==========\n",
      "Accuracy  : 0.4796\n",
      "Precision : 0.4881\n",
      "Recall    : 0.4796\n",
      "F1-Score  : 0.4403\n",
      "Confusion Matrix:\n",
      "[[203  22  46  28]\n",
      " [ 59  43 161  28]\n",
      " [ 38  12 222   8]\n",
      " [ 87  23  87  84]]\n",
      "============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 183/183 [01:33<00:00,  1.96it/s, loss=0.876]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 2] Train Loss: 1.1272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:21<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== METRICS ==========\n",
      "Accuracy  : 0.6394\n",
      "Precision : 0.6415\n",
      "Recall    : 0.6390\n",
      "F1-Score  : 0.6070\n",
      "Confusion Matrix:\n",
      "[[270   5  10  14]\n",
      " [ 58  65  94  74]\n",
      " [ 21  18 206  35]\n",
      " [ 48  10  28 195]]\n",
      "============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 183/183 [01:34<00:00,  1.94it/s, loss=0.573]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 3] Train Loss: 0.8047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:21<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== METRICS ==========\n",
      "Accuracy  : 0.7133\n",
      "Precision : 0.7129\n",
      "Recall    : 0.7125\n",
      "F1-Score  : 0.7098\n",
      "Confusion Matrix:\n",
      "[[255  13   7  24]\n",
      " [ 20 160  45  66]\n",
      " [ 13  62 181  24]\n",
      " [ 17  30   9 225]]\n",
      "============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 183/183 [01:35<00:00,  1.92it/s, loss=0.417]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 4] Train Loss: 0.6242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:21<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== METRICS ==========\n",
      "Accuracy  : 0.7202\n",
      "Precision : 0.7198\n",
      "Recall    : 0.7194\n",
      "F1-Score  : 0.7185\n",
      "Confusion Matrix:\n",
      "[[254  18   8  19]\n",
      " [ 16 168  48  59]\n",
      " [ 10  66 186  18]\n",
      " [ 14  32  14 221]]\n",
      "============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 183/183 [01:34<00:00,  1.94it/s, loss=0.745]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 5] Train Loss: 0.5138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:21<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== METRICS ==========\n",
      "Accuracy  : 0.7307\n",
      "Precision : 0.7385\n",
      "Recall    : 0.7298\n",
      "F1-Score  : 0.7288\n",
      "Confusion Matrix:\n",
      "[[253  14   8  24]\n",
      " [ 14 176  31  70]\n",
      " [ 11  73 173  23]\n",
      " [  7  28   7 239]]\n",
      "============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 6] Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 183/183 [01:35<00:00,  1.92it/s, loss=0.464]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 6] Train Loss: 0.4461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:21<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== METRICS ==========\n",
      "Accuracy  : 0.7411\n",
      "Precision : 0.7531\n",
      "Recall    : 0.7395\n",
      "F1-Score  : 0.7401\n",
      "Confusion Matrix:\n",
      "[[260  19   7  13]\n",
      " [ 15 197  22  57]\n",
      " [  9  86 166  19]\n",
      " [ 11  33   7 230]]\n",
      "============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 7] Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 183/183 [01:36<00:00,  1.89it/s, loss=0.3]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 7] Train Loss: 0.3877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:21<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== METRICS ==========\n",
      "Accuracy  : 0.7489\n",
      "Precision : 0.7555\n",
      "Recall    : 0.7478\n",
      "F1-Score  : 0.7488\n",
      "Confusion Matrix:\n",
      "[[256  17   9  17]\n",
      " [ 16 194  31  50]\n",
      " [  8  72 182  18]\n",
      " [  8  36   7 230]]\n",
      "============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 8] Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 183/183 [01:35<00:00,  1.92it/s, loss=0.133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 8] Train Loss: 0.3444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:21<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== METRICS ==========\n",
      "Accuracy  : 0.7463\n",
      "Precision : 0.7513\n",
      "Recall    : 0.7446\n",
      "F1-Score  : 0.7437\n",
      "Confusion Matrix:\n",
      "[[268  13   8  10]\n",
      " [ 20 191  25  55]\n",
      " [ 13  76 173  18]\n",
      " [ 17  31   6 227]]\n",
      "============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 9] Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 183/183 [01:38<00:00,  1.85it/s, loss=0.526] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 9] Train Loss: 0.3082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:21<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== METRICS ==========\n",
      "Accuracy  : 0.7524\n",
      "Precision : 0.7595\n",
      "Recall    : 0.7510\n",
      "F1-Score  : 0.7512\n",
      "Confusion Matrix:\n",
      "[[264  15   9  11]\n",
      " [ 13 194  25  59]\n",
      " [  8  78 176  18]\n",
      " [ 11  31   7 232]]\n",
      "============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 10] Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 183/183 [01:36<00:00,  1.90it/s, loss=0.651] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 10] Train Loss: 0.2617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:21<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== METRICS ==========\n",
      "Accuracy  : 0.7541\n",
      "Precision : 0.7581\n",
      "Recall    : 0.7526\n",
      "F1-Score  : 0.7537\n",
      "Confusion Matrix:\n",
      "[[264  14   9  12]\n",
      " [ 15 200  33  43]\n",
      " [ 11  67 187  15]\n",
      " [ 13  42   9 217]]\n",
      "============================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    MobileViTImageProcessor,\n",
    "    MobileViTForImageClassification,\n",
    ")\n",
    "from torch import amp\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 1. SEED\n",
    "# =====================================================\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "\n",
    "set_seed(42)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 2. DATASET (4-class)\n",
    "# =====================================================\n",
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, root_dir, processor):\n",
    "        self.root_dir = root_dir\n",
    "        self.processor = processor\n",
    "        self.samples = []\n",
    "\n",
    "        self.valid_folders = [\"happy\", \"anger\", \"panic\", \"sadness\"]\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.valid_folders)}\n",
    "\n",
    "        for cls in self.valid_folders:\n",
    "            folder_path = os.path.join(root_dir, cls)\n",
    "            if not os.path.exists(folder_path):\n",
    "                continue\n",
    "\n",
    "            label = self.class_to_idx[cls]\n",
    "\n",
    "            for file in os.listdir(folder_path):\n",
    "                if file.lower().endswith((\"jpg\", \"jpeg\", \"png\")):\n",
    "                    self.samples.append((os.path.join(folder_path, file), label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "\n",
    "        processed = self.processor(images=img, return_tensors=\"pt\")\n",
    "        pixel_values = processed[\"pixel_values\"].squeeze(0)\n",
    "        return pixel_values, torch.tensor(label)\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 3. LOAD Model  ‚Üê ‚òÖ MobileViT Small\n",
    "# =====================================================\n",
    "processor = MobileViTImageProcessor.from_pretrained(\n",
    "    \"apple/mobilevit-small\"\n",
    ")\n",
    "\n",
    "model = MobileViTForImageClassification.from_pretrained(\n",
    "    \"apple/mobilevit-small\",\n",
    "    num_labels=4,\n",
    "    ignore_mismatched_sizes=True\n",
    ").to(device)\n",
    "\n",
    "scaler = amp.GradScaler(device=\"cuda\")\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 4. PATHS\n",
    "# =====================================================\n",
    "train_root = \"/workspace/merge_data/data/img/train\"\n",
    "val_root   = \"/workspace/merge_data/data/img/val\"\n",
    "\n",
    "train_dataset = EmotionDataset(train_root, processor)\n",
    "val_dataset   = EmotionDataset(val_root, processor)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=32, shuffle=True,\n",
    "    num_workers=8, pin_memory=True, persistent_workers=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=32, shuffle=False,\n",
    "    num_workers=8, pin_memory=True, persistent_workers=True\n",
    ")\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 5. Optimizer\n",
    "# =====================================================\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-5)\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 6. TRAINING LOOP\n",
    "# =====================================================\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    pbar = tqdm(train_loader, desc=f\"[Epoch {epoch+1}] Training\")\n",
    "\n",
    "    for pixel_values, labels in pbar:\n",
    "        pixel_values = pixel_values.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # AMP\n",
    "        with amp.autocast(\"cuda\"):\n",
    "            outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "            loss = outputs.loss\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({\"loss\": loss.item()})\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"\\n[Epoch {epoch+1}] Train Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # -------------------------\n",
    "    # Validation\n",
    "    # -------------------------\n",
    "    model.eval()\n",
    "    preds, gts = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for pixel_values, labels in tqdm(val_loader, desc=\"Validating\"):\n",
    "            pixel_values = pixel_values.to(device, non_blocking=True)\n",
    "\n",
    "            with amp.autocast(\"cuda\"):\n",
    "                outputs = model(pixel_values=pixel_values)\n",
    "                pred = outputs.logits.argmax(dim=1).cpu()\n",
    "\n",
    "            preds.extend(pred.tolist())\n",
    "            gts.extend(labels.tolist())\n",
    "\n",
    "    # ‚òÖ 4-class ÏßÄÌëú\n",
    "    acc = accuracy_score(gts, preds)\n",
    "    prec = precision_score(gts, preds, average='macro')\n",
    "    rec  = recall_score(gts, preds, average='macro')\n",
    "    f1   = f1_score(gts, preds, average='macro')\n",
    "    cm   = confusion_matrix(gts, preds)\n",
    "\n",
    "    print(\"\\n========== METRICS ==========\")\n",
    "    print(f\"Accuracy  : {acc:.4f}\")\n",
    "    print(f\"Precision : {prec:.4f}\")\n",
    "    print(f\"Recall    : {rec:.4f}\")\n",
    "    print(f\"F1-Score  : {f1:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(\"============================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4078824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (2.0.8)\n",
      "Requirement already satisfied: opencv-python in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (4.12.0.88)\n",
      "Requirement already satisfied: scikit-learn in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (1.7.2)\n",
      "Requirement already satisfied: tqdm in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from albumentations) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from albumentations) (1.15.3)\n",
      "Requirement already satisfied: PyYAML in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from albumentations) (6.0.3)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from albumentations) (2.12.4)\n",
      "Requirement already satisfied: albucore==0.0.24 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from albumentations) (0.0.24)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from albumentations) (4.12.0.88)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from albucore==0.0.24->albumentations) (4.3.0)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from albucore==0.0.24->albumentations) (6.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations) (0.4.2)\n",
      "Requirement already satisfied: timm in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (1.0.22)\n",
      "Requirement already satisfied: torch in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from timm) (2.7.1+cu118)\n",
      "Requirement already satisfied: torchvision in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from timm) (0.22.1+cu118)\n",
      "Requirement already satisfied: pyyaml in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from timm) (6.0.3)\n",
      "Requirement already satisfied: huggingface_hub in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from timm) (0.36.0)\n",
      "Requirement already satisfied: safetensors in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from timm) (0.6.2)\n",
      "Requirement already satisfied: filelock in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from huggingface_hub->timm) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from huggingface_hub->timm) (2025.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from huggingface_hub->timm) (25.0)\n",
      "Requirement already satisfied: requests in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from huggingface_hub->timm) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from huggingface_hub->timm) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from huggingface_hub->timm) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from huggingface_hub->timm) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (2025.11.12)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch->timm) (1.14.0)\n",
      "Requirement already satisfied: networkx in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch->timm) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch->timm) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch->timm) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch->timm) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch->timm) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch->timm) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch->timm) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch->timm) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch->timm) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch->timm) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch->timm) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch->timm) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch->timm) (11.8.86)\n",
      "Requirement already satisfied: triton==3.3.1 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torch->timm) (3.3.1)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from triton==3.3.1->torch->timm) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from jinja2->torch->timm) (3.0.3)\n",
      "Requirement already satisfied: numpy in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torchvision->timm) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from torchvision->timm) (12.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install albumentations opencv-python scikit-learn tqdm\n",
    "!pip install timm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3a6924",
   "metadata": {},
   "source": [
    "4Îã®Í≥Ñ seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3326438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "Original 9535 -> 9535 samples.\n",
      "Original 1149 -> 1149 samples.\n",
      "\n",
      "‚úÖ Ï†ÑÏ≤òÎ¶¨ Î∞è Îç∞Ïù¥ÌÑ∞ Î°úÎìú ÏôÑÎ£å.\n",
      "\n",
      "Loading MobileViT Small model using timm...\n",
      "\n",
      "Epoch 1/10\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 298/298 [02:36<00:00,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2514 Acc: 0.9181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   Loss: 0.1219 Acc: 0.9626\n",
      ">> best model updated\n",
      "\n",
      "Epoch 2/10\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 298/298 [01:30<00:00,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0844 Acc: 0.9712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   Loss: 0.1165 Acc: 0.9626\n",
      "\n",
      "Epoch 3/10\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 298/298 [01:18<00:00,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0547 Acc: 0.9825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   Loss: 0.0994 Acc: 0.9713\n",
      ">> best model updated\n",
      "\n",
      "Epoch 4/10\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 298/298 [01:18<00:00,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0339 Acc: 0.9884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   Loss: 0.1305 Acc: 0.9617\n",
      "\n",
      "Epoch 5/10\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 298/298 [01:16<00:00,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0262 Acc: 0.9917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   Loss: 0.1397 Acc: 0.9608\n",
      "\n",
      "Epoch 6/10\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 298/298 [01:16<00:00,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0174 Acc: 0.9940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   Loss: 0.1930 Acc: 0.9478\n",
      "\n",
      "Epoch 7/10\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 298/298 [01:18<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0196 Acc: 0.9941\n",
      "Val   Loss: 0.0984 Acc: 0.9782\n",
      ">> best model updated\n",
      "\n",
      "Epoch 8/10\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 298/298 [01:18<00:00,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0158 Acc: 0.9943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   Loss: 0.1766 Acc: 0.9556\n",
      "\n",
      "Epoch 9/10\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 298/298 [01:17<00:00,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0114 Acc: 0.9961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   Loss: 0.1267 Acc: 0.9704\n",
      "\n",
      "Epoch 10/10\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 298/298 [01:18<00:00,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0124 Acc: 0.9959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   Loss: 0.1263 Acc: 0.9695\n",
      "\n",
      "Best val Acc: 0.9782\n",
      "\n",
      "=== Val Metrics (1=HAPPY, 0=OTHERS) ===\n",
      "Accuracy : 0.9782\n",
      "Precision: 0.9477\n",
      "Recall   : 0.9699\n",
      "F1-score : 0.9587\n",
      "\n",
      "Confusion Matrix:\n",
      " [[834  16]\n",
      " [  9 290]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      OTHERS       0.99      0.98      0.99       850\n",
      "       HAPPY       0.95      0.97      0.96       299\n",
      "\n",
      "    accuracy                           0.98      1149\n",
      "   macro avg       0.97      0.98      0.97      1149\n",
      "weighted avg       0.98      0.98      0.98      1149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2 \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models, datasets\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2 \n",
    "\n",
    "# ‚òÖ timm ÏûÑÌè¨Ìä∏ Ï∂îÍ∞Ä ‚òÖ\n",
    "import timm\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "# ================================\n",
    "# 3. Transform / Dataset / DataLoader\n",
    "# ================================\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(224, 224), # MobileViTÎäî 256x256Ïù¥ ÏõêÎûò Ïä§ÌéôÏù¥ÏßÄÎßå 224ÎèÑ Í∞ÄÎä•\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "data_root = \"/workspace/user4/segmented_output_bisenet\"\n",
    "\n",
    "train_full_dataset = datasets.ImageFolder(os.path.join(data_root, \"train\"), transform=None) \n",
    "val_full_dataset = datasets.ImageFolder(os.path.join(data_root, \"val\"), transform=None) \n",
    "\n",
    "target_classes = [\"anger\", \"happy\", \"panic\", \"sadness\"]\n",
    "\n",
    "def filter_and_remap_dataset(full_dataset, transform, target_classes): \n",
    "    new_samples = []\n",
    "    for path, class_idx in full_dataset.samples:\n",
    "        class_name = full_dataset.classes[class_idx]\n",
    "        if class_name not in target_classes:\n",
    "            continue\n",
    "        # 0: OTHERS, 1: HAPPY\n",
    "        binary_label = 1 if class_name == \"happy\" else 0\n",
    "        new_samples.append((path, binary_label))\n",
    "        \n",
    "    class CustomBinaryDataset(Dataset):\n",
    "        def __init__(self, samples, transform):\n",
    "            self.samples = samples\n",
    "            self.transform = transform\n",
    "        def __len__(self):\n",
    "            return len(self.samples)\n",
    "        def __getitem__(self, idx):\n",
    "            path, label = self.samples[idx]\n",
    "            image = cv2.imread(path)\n",
    "            if image is None: raise FileNotFoundError(f\"Image not found: {path}\")\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            if self.transform:\n",
    "                augmented = self.transform(image=image)\n",
    "                image = augmented['image']\n",
    "            return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "    print(f\"Original {len(full_dataset)} -> {len(new_samples)} samples.\")\n",
    "    return CustomBinaryDataset(new_samples, transform) \n",
    "\n",
    "train_dataset = filter_and_remap_dataset(train_full_dataset, train_transform, target_classes) \n",
    "val_dataset = filter_and_remap_dataset(val_full_dataset, val_transform, target_classes) \n",
    "\n",
    "batch_size = 32\n",
    "num_workers = 4 \n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "print(\"\\n‚úÖ Ï†ÑÏ≤òÎ¶¨ Î∞è Îç∞Ïù¥ÌÑ∞ Î°úÎìú ÏôÑÎ£å.\")\n",
    "\n",
    "# ================================\n",
    "# 4. Î™®Îç∏ Ï†ïÏùò (timm ÏÇ¨Ïö©: MobileViT)\n",
    "# ================================\n",
    "print(\"\\nLoading MobileViT Small model using timm...\")\n",
    "\n",
    "# ‚òÖ timmÏùÑ ÏÇ¨Ïö©ÌïòÎ©¥ Î≤ÑÏ†Ñ ÏóêÎü¨ ÏóÜÏù¥ ÏïàÏ†ÑÌïòÍ≤å Î°úÎìú Í∞ÄÎä•Ìï©ÎãàÎã§ ‚òÖ\n",
    "# num_classes=2Î•º ÎÑ£ÏúºÎ©¥ ÎßàÏßÄÎßâ Î†àÏù¥Ïñ¥ÎèÑ ÏûêÎèôÏúºÎ°ú ÎßûÏ∂∞Ï§çÎãàÎã§.\n",
    "model = timm.create_model('mobilevit_s', pretrained=True, num_classes=2)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "# ================================\n",
    "# 5. ÌïôÏäµ Ìï®Ïàò\n",
    "# ================================\n",
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=20):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_val_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "        # Train\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in tqdm(train_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            total += labels.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / total\n",
    "        epoch_acc = running_corrects.double() / total\n",
    "        print(f\"Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "        # Val\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                val_corrects += torch.sum(preds == labels.data)\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_loss /= val_total\n",
    "        val_acc = val_corrects.double() / val_total\n",
    "        print(f\"Val   Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            torch.save(best_model_wts, \"best_mobilevit_timm.pth\")\n",
    "            print(\">> best model updated\")\n",
    "\n",
    "    print(f\"\\nBest val Acc: {best_val_acc:.4f}\")\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "# ================================\n",
    "# 6. ÌïôÏäµ Ïã§Ìñâ\n",
    "# ================================\n",
    "num_epochs = 10\n",
    "model = train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs)\n",
    "\n",
    "# ================================\n",
    "# 7. ÏÑ±Îä• ÏßÄÌëú\n",
    "# ================================\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "all_preds = np.array(all_preds)\n",
    "\n",
    "print(\"\\n=== Val Metrics (1=HAPPY, 0=OTHERS) ===\")\n",
    "print(f\"Accuracy : {accuracy_score(all_labels, all_preds):.4f}\")\n",
    "print(f\"Precision: {precision_score(all_labels, all_preds, pos_label=1):.4f}\")\n",
    "print(f\"Recall   : {recall_score(all_labels, all_preds, pos_label=1):.4f}\")\n",
    "print(f\"F1-score : {f1_score(all_labels, all_preds, pos_label=1):.4f}\")\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(all_labels, all_preds))\n",
    "print(\"\\nReport:\\n\", classification_report(all_labels, all_preds, target_names=[\"OTHERS\", \"HAPPY\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd179b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in /workspace/miniconda3/lib/python3.13/site-packages (1.0.22)\n",
      "Requirement already satisfied: torch in /workspace/miniconda3/lib/python3.13/site-packages (from timm) (2.9.1)\n",
      "Requirement already satisfied: torchvision in /workspace/miniconda3/lib/python3.13/site-packages (from timm) (0.24.1)\n",
      "Requirement already satisfied: pyyaml in /workspace/miniconda3/lib/python3.13/site-packages (from timm) (6.0.3)\n",
      "Requirement already satisfied: huggingface_hub in /workspace/miniconda3/lib/python3.13/site-packages (from timm) (0.36.0)\n",
      "Requirement already satisfied: safetensors in /workspace/miniconda3/lib/python3.13/site-packages (from timm) (0.7.0)\n",
      "Requirement already satisfied: filelock in /workspace/miniconda3/lib/python3.13/site-packages (from huggingface_hub->timm) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /workspace/miniconda3/lib/python3.13/site-packages (from huggingface_hub->timm) (2025.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /workspace/miniconda3/lib/python3.13/site-packages (from huggingface_hub->timm) (25.0)\n",
      "Requirement already satisfied: requests in /workspace/miniconda3/lib/python3.13/site-packages (from huggingface_hub->timm) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /workspace/miniconda3/lib/python3.13/site-packages (from huggingface_hub->timm) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /workspace/miniconda3/lib/python3.13/site-packages (from huggingface_hub->timm) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /workspace/miniconda3/lib/python3.13/site-packages (from huggingface_hub->timm) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /workspace/miniconda3/lib/python3.13/site-packages (from requests->huggingface_hub->timm) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /workspace/miniconda3/lib/python3.13/site-packages (from requests->huggingface_hub->timm) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /workspace/miniconda3/lib/python3.13/site-packages (from requests->huggingface_hub->timm) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /workspace/miniconda3/lib/python3.13/site-packages (from requests->huggingface_hub->timm) (2025.11.12)\n",
      "Requirement already satisfied: setuptools in /workspace/miniconda3/lib/python3.13/site-packages (from torch->timm) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->timm) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->timm) (3.5)\n",
      "Requirement already satisfied: jinja2 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->timm) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->timm) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->timm) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->timm) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->timm) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->timm) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->timm) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->timm) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->timm) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->timm) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->timm) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->timm) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->timm) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->timm) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->timm) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->timm) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->timm) (3.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /workspace/miniconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /workspace/miniconda3/lib/python3.13/site-packages (from jinja2->torch->timm) (3.0.3)\n",
      "Requirement already satisfied: numpy in /workspace/miniconda3/lib/python3.13/site-packages (from torchvision->timm) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /workspace/miniconda3/lib/python3.13/site-packages (from torchvision->timm) (12.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f565f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MobileViT Small Model via timm...\n",
      "‚úÖ MobileViT loaded via timm\n"
     ]
    }
   ],
   "source": [
    "import timm # ‚òÖ timm ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏûÑÌè¨Ìä∏\n",
    "\n",
    "# ================================\n",
    "# 4. Î™®Îç∏ Ï†ïÏùò (timmÏùÑ ÏÇ¨Ïö©Ìïú MobileViT Small)\n",
    "# ================================\n",
    "print(\"Loading MobileViT Small Model via timm...\")\n",
    "\n",
    "# timmÏùÑ ÏÇ¨Ïö©ÌïòÎ©¥ Î≥µÏû°Ìïú Î†àÏù¥Ïñ¥ ÍµêÏ≤¥ ÏóÜÏù¥ num_classes Ïù∏ÏûêÎßåÏúºÎ°ú Ï≤òÎ¶¨ Í∞ÄÎä•Ìï©ÎãàÎã§.\n",
    "# 'mobilevit_s': MobileViT Small Î™®Îç∏\n",
    "# pretrained=True: ImageNet Í∞ÄÏ§ëÏπò ÏÇ¨Ïö©\n",
    "# num_classes=2: Happy vs Others (2ÏßÑ Î∂ÑÎ•ò)\n",
    "try:\n",
    "    model = timm.create_model('mobilevit_s', pretrained=True, num_classes=2)\n",
    "    print(\"‚úÖ MobileViT loaded via timm\")\n",
    "except ImportError:\n",
    "    print(\"üö® timm ÎùºÏù¥Î∏åÎü¨Î¶¨Í∞Ä ÏÑ§ÏπòÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§. '!pip install timm'ÏùÑ Ïã§ÌñâÌï¥Ï£ºÏÑ∏Ïöî.\")\n",
    "    # ÎπÑÏÉÅÏãú ResNetÏúºÎ°ú ÎåÄÏ≤¥ (ÏΩîÎìú Ïã§ÌñâÏù¥ Î©àÏ∂îÏßÄ ÏïäÍ≤å)\n",
    "    print(\">> Fallback to ResNet18\")\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# timm Î™®Îç∏ÏùÄ ÎÇ¥Î∂Ä Íµ¨Ï°∞Í∞Ä Ï°∞Í∏à Îã§Î•º Ïàò ÏûàÏúºÎÇò, \n",
    "# ÌïôÏäµ Ïãú optimizerÎÇò loss functionÏùÄ ÎèôÏùºÌïòÍ≤å ÏÇ¨Ïö© Í∞ÄÎä•Ìï©ÎãàÎã§.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac197bb",
   "metadata": {},
   "source": [
    "mobilevit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aba6daa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /workspace/miniconda3/lib/python3.13/site-packages (2.9.1)\n",
      "Requirement already satisfied: torchvision in /workspace/miniconda3/lib/python3.13/site-packages (0.24.1)\n",
      "Requirement already satisfied: filelock in /workspace/miniconda3/lib/python3.13/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /workspace/miniconda3/lib/python3.13/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /workspace/miniconda3/lib/python3.13/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /workspace/miniconda3/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /workspace/miniconda3/lib/python3.13/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /workspace/miniconda3/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /workspace/miniconda3/lib/python3.13/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /workspace/miniconda3/lib/python3.13/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /workspace/miniconda3/lib/python3.13/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /workspace/miniconda3/lib/python3.13/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /workspace/miniconda3/lib/python3.13/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /workspace/miniconda3/lib/python3.13/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /workspace/miniconda3/lib/python3.13/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /workspace/miniconda3/lib/python3.13/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /workspace/miniconda3/lib/python3.13/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /workspace/miniconda3/lib/python3.13/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /workspace/miniconda3/lib/python3.13/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /workspace/miniconda3/lib/python3.13/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /workspace/miniconda3/lib/python3.13/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /workspace/miniconda3/lib/python3.13/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /workspace/miniconda3/lib/python3.13/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /workspace/miniconda3/lib/python3.13/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /workspace/miniconda3/lib/python3.13/site-packages (from torch) (3.5.1)\n",
      "Requirement already satisfied: numpy in /workspace/miniconda3/lib/python3.13/site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /workspace/miniconda3/lib/python3.13/site-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /workspace/miniconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /workspace/miniconda3/lib/python3.13/site-packages (from jinja2->torch) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "# Ï£ºÌîºÌÑ∞ ÎÖ∏Ìä∏Î∂Å ÏÖÄÏóêÏÑú Ïã§Ìñâ Ïãú ÏïûÏóê !Î•º Î∂ôÏù¥ÏÑ∏Ïöî\n",
    "!pip install --upgrade torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19815010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (25.3)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27975c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MobileViT Small Model using timm...\n",
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import timm # Ï∂îÍ∞Ä\n",
    "\n",
    "# ================================\n",
    "# 4. Î™®Îç∏ Ï†ïÏùò (MobileViT Small via timm)\n",
    "# ================================\n",
    "print(\"Loading MobileViT Small Model using timm...\")\n",
    "\n",
    "# timmÏùÑ ÏÇ¨Ïö©ÌïòÎ©¥ num_classesÎ•º ÏßÅÏ†ë ÏßÄÏ†ïÌïòÏó¨ ÎßàÏßÄÎßâ Î†àÏù¥Ïñ¥Î•º ÏûêÎèôÏúºÎ°ú ÎßûÏ∂∞Ï§çÎãàÎã§.\n",
    "# pretrained=TrueÎ°ú ÏÑ§Ï†ïÌïòÎ©¥ ImageNet Í∞ÄÏ§ëÏπòÎ•º Í∞ÄÏ†∏ÏòµÎãàÎã§.\n",
    "model = timm.create_model('mobilevit_s', pretrained=True, num_classes=2)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# timm Î™®Îç∏ÎèÑ ÌååÎùºÎØ∏ÌÑ∞ Íµ¨Ï°∞Îäî ÌëúÏ§Ä PyTorch Î™®Îç∏Í≥º Í∞ôÏäµÎãàÎã§.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fc7a26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21.0\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "print(torchvision.__version__) \n",
    "# 0.13.0 Ïù¥ÏÉÅÏù¥Ïñ¥Ïïº Ìï®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9deab81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8efc2b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MobileViT Small Model (via timm)...\n",
      "‚úÖ MobileViT Small Model successfully loaded via timm.\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 4. Î™®Îç∏ Ï†ïÏùò (timmÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ MobileViT Î°úÎìú) ‚òÖ ÏàòÏ†ïÎêú Î∂ÄÎ∂Ñ ‚òÖ\n",
    "# ================================\n",
    "print(\"Loading MobileViT Small Model (via timm)...\")\n",
    "\n",
    "# timmÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ MobileViT Î™®Îç∏ÏùÑ Î∂àÎü¨ÏòµÎãàÎã§.\n",
    "# num_classes=2Î°ú ÏÑ§Ï†ïÌïòÎ©¥ ÎßàÏßÄÎßâ Î∂ÑÎ•ò Î†àÏù¥Ïñ¥Í∞Ä ÏûêÎèôÏúºÎ°ú Ïù¥ÏßÑ Î∂ÑÎ•òÏóê ÎßûÍ≤å Î≥ÄÍ≤ΩÎê©ÎãàÎã§.\n",
    "try:\n",
    "    # timmÏù¥ ÏÑ§ÏπòÎêòÏñ¥ ÏûàÎã§Î©¥ Ïù¥ Î∂ÄÎ∂ÑÏù¥ Ïã§ÌñâÎê©ÎãàÎã§.\n",
    "    model = timm.create_model('mobilevit_s', pretrained=True, num_classes=2)\n",
    "    print(\"‚úÖ MobileViT Small Model successfully loaded via timm.\")\n",
    "except Exception as e:\n",
    "    # ÌòπÏãú timm ÏÑ§ÏπòÍ∞Ä Ïã§Ìå®ÌñàÍ±∞ÎÇò Î™®Îç∏ Ïù¥Î¶ÑÏù¥ ÏûòÎ™ªÎêú Í≤ΩÏö∞Ïùò ÎåÄÏ≤¥ Î™®Îç∏ (ResNet18)\n",
    "    print(f\"timm Î°úÎìú Ïã§Ìå®: {e}\")\n",
    "    print(\"ResNet18Î°ú ÎåÄÏ≤¥ Î°úÎìúÌï©ÎãàÎã§. (Í∂åÏû•: timm ÏÑ§Ïπò ÌõÑ Ïû¨ÏãúÎèÑ)\")\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "# Ï∞∏Í≥†: Î™®Îç∏ Ï†ÄÏû• Í≤ΩÎ°úÎäî Ïù¥ÎØ∏ Ïù¥Ï†Ñ ÏΩîÎìúÏóêÏÑú `/workspace/user5`Î°ú ÏÑ§Ï†ïÎêòÏóàÏäµÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73dea92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "Original 9550 samples reduced to 9535.\n",
      "Original 1151 samples reduced to 1149.\n",
      "\n",
      "‚úÖ Ï†ÑÏ≤òÎ¶¨ Î∞è Îç∞Ïù¥ÌÑ∞ Î°úÎìú ÏôÑÎ£å.\n",
      "Loading MobileViT Small Model (via timm)...\n",
      "Model will be saved to: /workspace/user5/best_mobilevit_happy_vs_others.pth\n",
      "\n",
      "Epoch 1/10\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 298/298 [00:45<00:00,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2507 Acc: 0.9183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   Loss: 0.1172 Acc: 0.9634\n",
      ">> best model updated and saved to /workspace/user5/best_mobilevit_happy_vs_others.pth\n",
      "\n",
      "Epoch 2/10\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 298/298 [00:36<00:00,  8.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0824 Acc: 0.9726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   Loss: 0.1724 Acc: 0.9469\n",
      "\n",
      "Epoch 3/10\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 298/298 [00:37<00:00,  7.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0514 Acc: 0.9828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   Loss: 0.1338 Acc: 0.9661\n",
      ">> best model updated and saved to /workspace/user5/best_mobilevit_happy_vs_others.pth\n",
      "\n",
      "Epoch 4/10\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 298/298 [00:37<00:00,  8.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0358 Acc: 0.9895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   Loss: 0.1550 Acc: 0.9617\n",
      "\n",
      "Epoch 5/10\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 298/298 [00:36<00:00,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0261 Acc: 0.9911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   Loss: 0.1697 Acc: 0.9547\n",
      "\n",
      "Epoch 6/10\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 298/298 [00:34<00:00,  8.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0189 Acc: 0.9943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   Loss: 0.2245 Acc: 0.9487\n",
      "\n",
      "Epoch 7/10\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 298/298 [00:35<00:00,  8.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0200 Acc: 0.9935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   Loss: 0.1540 Acc: 0.9634\n",
      "\n",
      "Epoch 8/10\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 298/298 [00:34<00:00,  8.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0129 Acc: 0.9961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   Loss: 0.1280 Acc: 0.9730\n",
      ">> best model updated and saved to /workspace/user5/best_mobilevit_happy_vs_others.pth\n",
      "\n",
      "Epoch 9/10\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 298/298 [00:35<00:00,  8.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0123 Acc: 0.9962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   Loss: 0.1632 Acc: 0.9678\n",
      "\n",
      "Epoch 10/10\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 298/298 [00:36<00:00,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0089 Acc: 0.9974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   Loss: 0.2580 Acc: 0.9547\n",
      "\n",
      "Best val Acc: 0.9730\n",
      "\n",
      "=== Val Metrics (binary: 1=HAPPY, 0=OTHERS) ===\n",
      "Model: MobileViT Small\n",
      "Accuracy : 0.9730\n",
      "Precision: 0.9268\n",
      "Recall    : 0.9732\n",
      "F1-score : 0.9494\n",
      "\n",
      "Confusion Matrix (rows: true, cols: pred)\n",
      "[[827  23]\n",
      " [  8 291]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      OTHERS       0.99      0.97      0.98       850\n",
      "       HAPPY       0.93      0.97      0.95       299\n",
      "\n",
      "    accuracy                           0.97      1149\n",
      "   macro avg       0.96      0.97      0.97      1149\n",
      "weighted avg       0.97      0.97      0.97      1149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2 \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models, datasets\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2 \n",
    "\n",
    "# ‚òÖ timm ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏûÑÌè¨Ìä∏ (Î≤ÑÏ†Ñ Ïò§Î•ò Ìï¥Í≤∞Ïö©) ‚òÖ\n",
    "import timm \n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "# ================================\n",
    "# 3. Transform / Dataset / DataLoader\n",
    "# ================================\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "data_root = \"/workspace/user4/cropped\"\n",
    "\n",
    "train_full_dataset = datasets.ImageFolder(os.path.join(data_root, \"train\"), transform=None) \n",
    "val_full_dataset = datasets.ImageFolder(os.path.join(data_root, \"val\"), transform=None) \n",
    "\n",
    "target_classes = [\"anger\", \"happy\", \"panic\", \"sadness\"]\n",
    "\n",
    "def filter_and_remap_dataset(full_dataset, transform, target_classes): \n",
    "    new_samples = []\n",
    "    \n",
    "    for path, class_idx in full_dataset.samples:\n",
    "        class_name = full_dataset.classes[class_idx]\n",
    "        \n",
    "        if class_name not in target_classes:\n",
    "            continue\n",
    "            \n",
    "        # 2ÏßÑ Î∂ÑÎ•ò ÎùºÎ≤® Ìï†Îãπ (Happy: 1, Others: 0)\n",
    "        if class_name == \"happy\":\n",
    "            binary_label = 1 \n",
    "        else:\n",
    "            binary_label = 0 \n",
    "            \n",
    "        new_samples.append((path, binary_label))\n",
    "        \n",
    "    class CustomBinaryDataset(Dataset):\n",
    "        def __init__(self, samples, transform):\n",
    "            self.samples = samples\n",
    "            self.transform = transform\n",
    "            \n",
    "        def __len__(self):\n",
    "            return len(self.samples)\n",
    "            \n",
    "        def __getitem__(self, idx):\n",
    "            path, label = self.samples[idx]\n",
    "            \n",
    "            image = cv2.imread(path)\n",
    "            if image is None:\n",
    "                 raise FileNotFoundError(f\"Image not found or invalid: {path}\")\n",
    "\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            if self.transform is not None:\n",
    "                augmented = self.transform(image=image)\n",
    "                image = augmented['image'] \n",
    "            \n",
    "            return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "    print(f\"Original {len(full_dataset)} samples reduced to {len(new_samples)}.\")\n",
    "    return CustomBinaryDataset(new_samples, transform) \n",
    "\n",
    "\n",
    "train_dataset = filter_and_remap_dataset(train_full_dataset, train_transform, target_classes) \n",
    "val_dataset = filter_and_remap_dataset(val_full_dataset, val_transform, target_classes) \n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "num_workers = 2 \n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "print(\"\\n‚úÖ Ï†ÑÏ≤òÎ¶¨ Î∞è Îç∞Ïù¥ÌÑ∞ Î°úÎìú ÏôÑÎ£å.\")\n",
    "\n",
    "# ================================\n",
    "# 4. Î™®Îç∏ Ï†ïÏùò (timm ÏÇ¨Ïö©ÏúºÎ°ú Ïò§Î•ò Ìï¥Í≤∞)\n",
    "# ================================\n",
    "print(\"Loading MobileViT Small Model (via timm)...\")\n",
    "\n",
    "# ‚òÖ Ïó¨Í∏∞ÏÑú timmÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ Î™®Îç∏ÏùÑ Î∂àÎü¨ÏòµÎãàÎã§. (Í∏∞Ï°¥ ÏΩîÎìú ÎåÄÏ≤¥) ‚òÖ\n",
    "# num_classes=2Î°ú ÏÑ§Ï†ïÌïòÎ©¥ ÎßàÏßÄÎßâ Î†àÏù¥Ïñ¥Î•º ÏûêÎèôÏúºÎ°ú ÎßûÏ∂∞Ï§çÎãàÎã§.\n",
    "try:\n",
    "    model = timm.create_model('mobilevit_s', pretrained=True, num_classes=2)\n",
    "except Exception as e:\n",
    "    print(f\"timm Î°úÎìú Ïã§Ìå®. ÎùºÏù¥Î∏åÎü¨Î¶¨Í∞Ä ÏÑ§ÏπòÎêòÏóàÎäîÏßÄ ÌôïÏù∏ÌïòÏÑ∏Ïöî. ÏóêÎü¨: {e}\")\n",
    "    # ÌòπÏãú Î™®Î•º ÏÉÅÌô©ÏùÑ ÎåÄÎπÑÌïú ÏòàÎπÑÏ±Ö (ResNet18)\n",
    "    print(\"ResNet18Î°ú ÎåÄÏ≤¥ Î°úÎìúÌï©ÎãàÎã§.\")\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 5. ÌïôÏäµ Ìï®Ïàò (Ï†ÄÏû• Í≤ΩÎ°ú ÏàòÏ†ïÎê®)\n",
    "# ================================\n",
    "# ‚òÖ Ï†ÄÏû• Í≤ΩÎ°ú Î≥ÄÏàò ÏÑ§Ï†ï ‚òÖ\n",
    "SAVE_DIR = \"/workspace/user5\"\n",
    "SAVE_PATH = os.path.join(SAVE_DIR, \"best_mobilevit_happy_vs_others.pth\")\n",
    "\n",
    "# Ìè¥ÎçîÍ∞Ä ÏóÜÏúºÎ©¥ ÏÉùÏÑ±\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "print(f\"Model will be saved to: {SAVE_PATH}\")\n",
    "\n",
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=20):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_val_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "        # ---- Train ----\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in tqdm(train_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            total += labels.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / total\n",
    "        epoch_acc = running_corrects.double() / total\n",
    "        print(f\"Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "        # ---- Validation ----\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                val_corrects += torch.sum(preds == labels.data)\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_loss /= val_total\n",
    "        val_acc = val_corrects.double() / val_total\n",
    "        print(f\"Val   Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
    "\n",
    "        # best model Ï†ÄÏû• (Í≤ΩÎ°ú ÏàòÏ†ïÎê®)\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "            # ‚òÖ Ïó¨Í∏∞ÏÑú ÏßÄÏ†ïÌïú Í≤ΩÎ°úÏóê Ï†ÄÏû•Ìï©ÎãàÎã§ ‚òÖ\n",
    "            torch.save(best_model_wts, SAVE_PATH)\n",
    "            print(f\">> best model updated and saved to {SAVE_PATH}\")\n",
    "\n",
    "    print(f\"\\nBest val Acc: {best_val_acc:.4f}\")\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 6. ÌïôÏäµ Ïã§Ìñâ\n",
    "# ================================\n",
    "num_epochs = 10\n",
    "model = train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs)\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 7. ÏÑ±Îä• ÏßÄÌëú\n",
    "# ================================\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "all_preds = np.array(all_preds)\n",
    "\n",
    "acc  = accuracy_score(all_labels, all_preds)\n",
    "prec = precision_score(all_labels, all_preds, pos_label=1)\n",
    "rec  = recall_score(all_labels, all_preds, pos_label=1)\n",
    "f1   = f1_score(all_labels, all_preds, pos_label=1)\n",
    "cm   = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "print(\"\\n=== Val Metrics (binary: 1=HAPPY, 0=OTHERS) ===\")\n",
    "print(f\"Model: MobileViT Small\")\n",
    "print(f\"Accuracy : {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall    : {rec:.4f}\")\n",
    "print(f\"F1-score : {f1:.4f}\")\n",
    "print(\"\\nConfusion Matrix (rows: true, cols: pred)\")\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=[\"OTHERS\", \"HAPPY\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15353551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: tabulate\n",
      "Successfully installed tabulate-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4531539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting thop\n",
      "  Using cached thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: torch in /workspace/miniconda3/lib/python3.13/site-packages (from thop) (2.9.1)\n",
      "Requirement already satisfied: filelock in /workspace/miniconda3/lib/python3.13/site-packages (from torch->thop) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->thop) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /workspace/miniconda3/lib/python3.13/site-packages (from torch->thop) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->thop) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->thop) (3.5)\n",
      "Requirement already satisfied: jinja2 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->thop) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->thop) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->thop) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->thop) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->thop) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->thop) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->thop) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->thop) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->thop) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->thop) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->thop) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->thop) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->thop) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->thop) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->thop) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->thop) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->thop) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /workspace/miniconda3/lib/python3.13/site-packages (from torch->thop) (3.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /workspace/miniconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch->thop) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /workspace/miniconda3/lib/python3.13/site-packages (from jinja2->torch->thop) (3.0.3)\n",
      "Using cached thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: thop\n",
      "Successfully installed thop\n"
     ]
    }
   ],
   "source": [
    "!pip install thop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c23db6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ÏÇ¨Ïö© Ïû•Ïπò: cuda\n",
      "------------------------------\n",
      "‚è≥ Î™®Îç∏ Î°úÎî© Ï§ë...\n",
      "‚úÖ timm: MobileViT-S Î°úÎìú ÏôÑÎ£å (pretrained)\n",
      "‚úÖ ÏµúÏ†Å Í∞ÄÏ§ëÏπò Î°úÎìú ÏôÑÎ£å: best_mobilevit_happy_vs_others.pth\n",
      "‚úÖ Î™®Îç∏ Î∞è Dummy Input Ï§ÄÎπÑ ÏôÑÎ£å.\n",
      "ÏûÖÎ†• Îç∞Ïù¥ÌÑ∞ ÌòïÌÉú: torch.Size([1, 3, 256, 256])\n",
      "------------------------------\n",
      "=== Î™®Îç∏ Î≥µÏû°ÎèÑ Ï∏°Ï†ï (thop) ===\n",
      "ÌååÎùºÎØ∏ÌÑ∞ Ïàò (Params): 4.93 M\n",
      "Ïó∞ÏÇ∞Îüâ (FLOPs): 3.66 G\n",
      "------------------------------\n",
      "=== Ï∂îÎ°† ÏÜçÎèÑ Ï∏°Ï†ï ÏãúÏûë (Warm-up 10Ìöå, Ï∏°Ï†ï 100Ìöå) ===\n",
      "\n",
      "=====================================================================================\n",
      "=== ÏÑ±Îä• ÏöîÏïΩ ===\n",
      "+------------------+--------+--------------------------------------------+--------------+---------+----------+\n",
      "| Î∞±ÏóîÎìú/Î™®Îç∏           | ÌÅ¨Í∏∞(px) | Ï†ïÌôïÎèÑ(Ï∞∏Í≥†)                                    | ÏÜçÎèÑ CUDA (ms) | ÌååÎùºÎØ∏ÌÑ∞(M) | FLOPs(G) |\n",
      "+------------------+--------+--------------------------------------------+--------------+---------+----------+\n",
      "| timm-MobileViT-S | 256    | MobileViT-S: ~78.4% (ImageNet Top-1, ref.) | 6.61 ¬± 0.40  | 4.93    | 3.66     |\n",
      "+------------------+--------+--------------------------------------------+--------------+---------+----------+\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import statistics\n",
    "\n",
    "# --- ÏÑ†ÌÉùÏ†Å Î™®Îìà Ï°¥Ïû¨ Ïó¨Î∂Ä ÌôïÏù∏ ---\n",
    "has_timm = False\n",
    "has_thop = False\n",
    "try:\n",
    "    import timm\n",
    "    has_timm = True\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    from thop import profile\n",
    "    has_thop = True\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# torchvisionÏùÄ Ìè¥Î∞±Ïö©ÏúºÎ°úÎßå ÌïÑÏöî\n",
    "try:\n",
    "    import torchvision.models as tv_models\n",
    "except Exception:\n",
    "    tv_models = None\n",
    "\n",
    "# 1. Ïû•Ïπò ÏÑ§Ï†ï\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"‚úÖ ÏÇ¨Ïö© Ïû•Ïπò: {device}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 2. Î™®Îç∏ Î°úÎìú: Ïö∞ÏÑ† timmÏùò MobileViT-S ÏãúÎèÑ, ÏóÜÏúºÎ©¥ torchvision MobileNetV3-Small\n",
    "MODEL_NAME = \"MobileViT-S\"\n",
    "NUM_CLASSES = 2\n",
    "print(\"‚è≥ Î™®Îç∏ Î°úÎî© Ï§ë...\")\n",
    "\n",
    "model = None\n",
    "used_backend = None\n",
    "\n",
    "if has_timm:\n",
    "    try:\n",
    "        # timmÏúºÎ°ú MobileViT-S\n",
    "        model = timm.create_model('mobilevit_s', pretrained=True, num_classes=NUM_CLASSES)\n",
    "        used_backend = \"timm-MobileViT-S\"\n",
    "        print(\"‚úÖ timm: MobileViT-S Î°úÎìú ÏôÑÎ£å (pretrained)\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è timm MobileViT-S Î°úÎìú Ïã§Ìå®: {e}\")\n",
    "\n",
    "if model is None and tv_models is not None:\n",
    "    try:\n",
    "        # torchvision Ìè¥Î∞±: MobileNetV3-Small\n",
    "        tv_model = tv_models.mobilenet_v3_small(weights=None)\n",
    "        # Î∂ÑÎ•òÍ∏∞ Ìó§Îìú ÍµêÏ≤¥\n",
    "        in_features = tv_model.classifier[-1].in_features\n",
    "        tv_model.classifier[-1] = nn.Linear(in_features, NUM_CLASSES)\n",
    "        model = tv_model\n",
    "        used_backend = \"torchvision-MobileNetV3-Small\"\n",
    "        print(\"‚úÖ torchvision: MobileNetV3-Small Ìè¥Î∞± Î°úÎìú (pretrained ÏóÜÏùå)\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è torchvision MobileNetV3 Î°úÎìú Ïã§Ìå®: {e}\")\n",
    "\n",
    "if model is None:\n",
    "    raise RuntimeError(\"Î™®Îç∏ Î°úÎìúÏóê Ïã§Ìå®ÌñàÏäµÎãàÎã§. timm ÏÑ§Ïπò ÎòêÎäî torchvision ÏóÖÎç∞Ïù¥Ìä∏Í∞Ä ÌïÑÏöîÌï©ÎãàÎã§.\")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# 3. ÏÇ¨Ïö©Ïûê ÌïôÏäµ Í∞ÄÏ§ëÏπò Î°úÎìú (ÏÑ†ÌÉù)\n",
    "save_path = \"best_mobilevit_happy_vs_others.pth\"\n",
    "try:\n",
    "    state_dict = torch.load(save_path, map_location=device)\n",
    "    missing, unexpected = model.load_state_dict(state_dict, strict=False)\n",
    "    print(f\"‚úÖ ÏµúÏ†Å Í∞ÄÏ§ëÏπò Î°úÎìú ÏôÑÎ£å: {save_path}\")\n",
    "    if missing:\n",
    "        print(f\"‚ÑπÔ∏è ÎàÑÎùΩÎêú ÌÇ§: {missing}\")\n",
    "    if unexpected:\n",
    "        print(f\"‚ÑπÔ∏è ÏòàÏÉÅÏπò Î™ªÌïú ÌÇ§: {unexpected}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"üö® Í≤ΩÍ≥†: '{save_path}' ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§. (ÌÖåÏä§Ìä∏Î•º ÏúÑÌï¥ Í∏∞Î≥∏/ÏÇ¨Ï†ÑÌïôÏäµ Í∞ÄÏ§ëÏπòÎ°ú ÏßÑÌñâ)\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# 4. Dummy Input (MobileViT Í∂åÏû• 256, Ìè¥Î∞±ÎèÑ ÎèôÏùº Ï≤òÎ¶¨)\n",
    "input_size = 256\n",
    "dummy_input = torch.randn(1, 3, input_size, input_size).to(device)\n",
    "print(\"‚úÖ Î™®Îç∏ Î∞è Dummy Input Ï§ÄÎπÑ ÏôÑÎ£å.\")\n",
    "print(f\"ÏûÖÎ†• Îç∞Ïù¥ÌÑ∞ ÌòïÌÉú: {dummy_input.shape}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 5. ÌååÎùºÎØ∏ÌÑ∞ Ïàò & FLOPs\n",
    "params_m = sum(p.numel() for p in model.parameters()) / 1e6\n",
    "flops_g = 0.0\n",
    "\n",
    "if has_thop:\n",
    "    try:\n",
    "        macs, params = profile(model, inputs=(dummy_input,), verbose=False)\n",
    "        flops_g = macs / 1e9 * 2  # FLOPs ‚âà MACs * 2\n",
    "        params_m = params / 1e6\n",
    "        print(f\"=== Î™®Îç∏ Î≥µÏû°ÎèÑ Ï∏°Ï†ï (thop) ===\")\n",
    "        print(f\"ÌååÎùºÎØ∏ÌÑ∞ Ïàò (Params): {params_m:.2f} M\")\n",
    "        print(f\"Ïó∞ÏÇ∞Îüâ (FLOPs): {flops_g:.2f} G\")\n",
    "        print(\"-\" * 30)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è thop/FLOPs Í≥ÑÏÇ∞ Ï§ë Ïò§Î•ò: {e}\")\n",
    "        print(f\"‚û°Ô∏è ÌååÎùºÎØ∏ÌÑ∞Îßå Í≥ÑÏÇ∞: {params_m:.2f} M\")\n",
    "        print(\"-\" * 30)\n",
    "else:\n",
    "    print(f\"‚û°Ô∏è thop ÎØ∏ÏÑ§Ïπò: ÌååÎùºÎØ∏ÌÑ∞Îßå Í≥ÑÏÇ∞ {params_m:.2f} M, FLOPs=0.00 G\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# 6. Ï∂îÎ°† ÏÜçÎèÑ Ï∏°Ï†ï\n",
    "ITERATIONS = 100\n",
    "print(f\"=== Ï∂îÎ°† ÏÜçÎèÑ Ï∏°Ï†ï ÏãúÏûë (Warm-up 10Ìöå, Ï∏°Ï†ï {ITERATIONS}Ìöå) ===\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in range(10):\n",
    "        _ = model(dummy_input)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "timings = []\n",
    "if device.type == 'cuda':\n",
    "    starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "    with torch.no_grad():\n",
    "        for _ in range(ITERATIONS):\n",
    "            starter.record()\n",
    "            _ = model(dummy_input)\n",
    "            ender.record()\n",
    "            torch.cuda.synchronize()\n",
    "            timings.append(starter.elapsed_time(ender))  # ms\n",
    "else:\n",
    "    with torch.no_grad():\n",
    "        for _ in range(ITERATIONS):\n",
    "            t0 = time.time()\n",
    "            _ = model(dummy_input)\n",
    "            t1 = time.time()\n",
    "            timings.append((t1 - t0) * 1000.0)\n",
    "\n",
    "mean_ms = statistics.mean(timings)\n",
    "std_ms = statistics.stdev(timings) if len(timings) > 1 else 0.0\n",
    "\n",
    "# 7. Ï∂úÎ†• (ASCII ÌÖåÏù¥Î∏î)\n",
    "ACCURACY_REF = \"MobileViT-S: ~78.4% (ImageNet Top-1, ref.)\"  # Ï∞∏Í≥†Ïπò\n",
    "\n",
    "headers = [\"Î∞±ÏóîÎìú/Î™®Îç∏\", \"ÌÅ¨Í∏∞(px)\", \"Ï†ïÌôïÎèÑ(Ï∞∏Í≥†)\", f\"ÏÜçÎèÑ {device.type.upper()} (ms)\", \"ÌååÎùºÎØ∏ÌÑ∞(M)\", \"FLOPs(G)\"]\n",
    "row = [used_backend, str(input_size), ACCURACY_REF, f\"{mean_ms:.2f} ¬± {std_ms:.2f}\", f\"{params_m:.2f}\", f\"{flops_g:.2f}\"]\n",
    "\n",
    "def render_table(headers, row):\n",
    "    widths = [max(len(h), len(r)) for h, r in zip(headers, row)]\n",
    "    def fmt(vals): return \"| \" + \" | \".join(v.ljust(w) for v, w in zip(vals, widths)) + \" |\"\n",
    "    sep = \"+\" + \"+\".join(\"-\" * (w + 2) for w in widths) + \"+\"\n",
    "    return \"\\n\".join([sep, fmt(headers), sep, fmt(row), sep])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 85)\n",
    "print(\"=== ÏÑ±Îä• ÏöîÏïΩ ===\")\n",
    "print(render_table(headers, row))\n",
    "print(\"=\" * 85)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9b5eeb",
   "metadata": {},
   "source": [
    "segÏΩîÎìú"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ce23a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Full train classes: ['anger', 'happy', 'panic', 'sadness']\n",
      "Full val   classes: ['anger', 'happy', 'panic', 'sadness']\n",
      "[BinaryFilteredDataset] Total: 9535 | HAPPY(1): 5245 | OTHERS(0): 4290\n",
      "[BinaryFilteredDataset] Total: 1149 | HAPPY(1): 299 | OTHERS(0): 850\n",
      "Model will be saved to: /workspace/user5/best_mobilevit_happy_vs_others.pth\n",
      "\n",
      "Epoch 1/10\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a339c1cc17a241d5942707848bc9cd9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1677 Acc: 0.9399\n",
      "Val   Loss: 0.1219 Acc: 0.9652\n",
      ">> best model updated and saved to /workspace/user5/best_mobilevit_happy_vs_others.pth\n",
      "\n",
      "Epoch 2/10\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbfd494aabd542d6bd4da135d1e5fd7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0723 Acc: 0.9751\n",
      "Val   Loss: 0.1965 Acc: 0.9373\n",
      "\n",
      "Epoch 3/10\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fae9507a3e34d899e3ea5b77cbb39b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0461 Acc: 0.9842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()Exception ignored in: \n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>Exception ignored in: Exception ignored in:     \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50><function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>if w.is_alive():\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "    AssertionErrorself._shutdown_workers():     \n",
      "can only test a child process  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "\n",
      "self._shutdown_workers()\n",
      "Exception ignored in:   File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "        if w.is_alive():self._shutdown_workers()\n",
      "\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "        if w.is_alive():        self._shutdown_workers()assert self._parent_pid == os.getpid(), 'can only test a child process'if w.is_alive():\n",
      "\n",
      "AssertionError\n",
      "\n",
      ":   File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "can only test a child process  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'Exception ignored in:     \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>AssertionError    \n",
      ": assert self._parent_pid == os.getpid(), 'can only test a child process'Traceback (most recent call last):\n",
      "can only test a child processif w.is_alive():  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "\n",
      "\n",
      "\n",
      "AssertionError      File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "self._shutdown_workers(): \n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    can only test a child processassert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "    if w.is_alive():\n",
      "\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "AssertionError    : assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "can only test a child processException ignored in: AssertionError: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>can only test a child process\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "    Traceback (most recent call last):\n",
      "self._shutdown_workers()  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "        self._shutdown_workers()if w.is_alive():\n",
      "\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "        assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "if w.is_alive():AssertionError\n",
      ":   File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "can only test a child process\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   Loss: 0.1056 Acc: 0.9765\n",
      ">> best model updated and saved to /workspace/user5/best_mobilevit_happy_vs_others.pth\n",
      "\n",
      "Epoch 4/10\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35488a9b1f3d4c8ebba2870269fdb3f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0367 Acc: 0.9868\n",
      "Val   Loss: 0.0931 Acc: 0.9730\n",
      "\n",
      "Epoch 5/10\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f485fd20ee4347e0981bd198550a0e89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0328 Acc: 0.9893\n",
      "Val   Loss: 0.1435 Acc: 0.9669\n",
      "\n",
      "Epoch 6/10\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69039f9502f6482e806973e5abc2c489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0208 Acc: 0.9927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>Exception ignored in: \n",
      "Traceback (most recent call last):\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>Exception ignored in:   File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "Traceback (most recent call last):\n",
      "    Exception ignored in:   File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "self._shutdown_workers()<function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>    \n",
      "\n",
      "self._shutdown_workers()  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "Traceback (most recent call last):\n",
      "    \n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "self._shutdown_workers()  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "        if w.is_alive():    self._shutdown_workers()\n",
      "if w.is_alive():    \n",
      "\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "if w.is_alive():  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "            assert self._parent_pid == os.getpid(), 'can only test a child process'    assert self._parent_pid == os.getpid(), 'can only test a child process'if w.is_alive():\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "AssertionError\n",
      "AssertionError  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      ": AssertionError: can only test a child process: can only test a child process\n",
      "can only test a child process\n",
      "    \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "Exception ignored in: AssertionError<function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>Exception ignored in: Exception ignored in: : <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50><function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "can only test a child process\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "                self._shutdown_workers()self._shutdown_workers()self._shutdown_workers()self._shutdown_workers()\n",
      "\n",
      "\n",
      "\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "                if w.is_alive():if w.is_alive():if w.is_alive():\n",
      "if w.is_alive():\n",
      "\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "                assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "\n",
      "\n",
      "AssertionErrorAssertionError: AssertionErrorAssertionErrorcan only test a child process: : can only test a child process: \n",
      "can only test a child processcan only test a child process\n",
      "\n",
      "\n",
      "Exception ignored in: Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50><function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50><function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "        self._shutdown_workers()    self._shutdown_workers()self._shutdown_workers()\n",
      "\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "            if w.is_alive():if w.is_alive():    \n",
      "self._shutdown_workers()\n",
      "if w.is_alive():  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "            assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "\n",
      "AssertionErrorAssertionError    AssertionError: : : if w.is_alive():can only test a child processcan only test a child process\n",
      "can only test a child process\n",
      "\n",
      "\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   Loss: 0.1530 Acc: 0.9730\n",
      "\n",
      "Epoch 7/10\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b889db09cd4f43a9fa0fc21e192d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50><function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50><function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "            self._shutdown_workers()  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "self._shutdown_workers()\n",
      "self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "      File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():        \n",
      "if w.is_alive():if w.is_alive():  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    \n",
      "if w.is_alive():  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "\n",
      "      File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "    AssertionError        assert self._parent_pid == os.getpid(), 'can only test a child process': can only test a child process\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: \n",
      "can only test a child process\n",
      "AssertionErrorException ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>: AssertionError\n",
      "Traceback (most recent call last):\n",
      "can only test a child process  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "Exception ignored in: : \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "can only test a child process    Traceback (most recent call last):\n",
      "self._shutdown_workers()  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "\n",
      "\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "Exception ignored in:     self._shutdown_workers()\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>      File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "if w.is_alive():\n",
      "\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in:     if w.is_alive():  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "\n",
      "AssertionError: Traceback (most recent call last):\n",
      "can only test a child process    \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "\n",
      "    AssertionErrorException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>self._shutdown_workers(): \n",
      "can only test a child processTraceback (most recent call last):\n",
      "\n",
      "\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "        Exception ignored in: self._shutdown_workers()self._shutdown_workers()<function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "\n",
      "\n",
      "      File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "Traceback (most recent call last):\n",
      "if w.is_alive():  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    if w.is_alive():\n",
      "      File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'self._shutdown_workers()\n",
      "    \n",
      "AssertionError    assert self._parent_pid == os.getpid(), 'can only test a child process':   File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "if w.is_alive():\n",
      "can only test a child processAssertionError\n",
      "\n",
      ": can only test a child process    \n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "if w.is_alive():Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "Traceback (most recent call last):\n",
      "      File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
      "self._shutdown_workers()\n",
      "AssertionError\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      ": AssertionErrorcan only test a child process\n",
      ":     can only test a child processif w.is_alive():\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child processException ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0211 Acc: 0.9922\n",
      "Val   Loss: 0.1906 Acc: 0.9608\n",
      "\n",
      "Epoch 8/10\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ac61cf7e4f4f74aa6b0355e63bcea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0170 Acc: 0.9943\n",
      "Val   Loss: 0.1506 Acc: 0.9713\n",
      "\n",
      "Epoch 9/10\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1abc2fbcda0f4331ad6aab8c188f30c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0186 Acc: 0.9932\n",
      "Val   Loss: 0.1900 Acc: 0.9634\n",
      "\n",
      "Epoch 10/10\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c141a35014f845fbad47d594362f9134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0164 Acc: 0.9933\n",
      "Val   Loss: 0.1605 Acc: 0.9687\n",
      "\n",
      "Best val Acc: 0.9765\n",
      "\n",
      "=== Val Metrics (binary: 1=HAPPY, 0=OTHERS) ===\n",
      "Model: MobileViT Small\n",
      "Accuracy : 0.9765\n",
      "Precision: 0.9359\n",
      "Recall   : 0.9766\n",
      "F1-score : 0.9558\n",
      "\n",
      "Confusion Matrix (rows: true, cols: pred)\n",
      "[[830  20]\n",
      " [  7 292]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      OTHERS       0.99      0.98      0.98       850\n",
      "       HAPPY       0.94      0.98      0.96       299\n",
      "\n",
      "    accuracy                           0.98      1149\n",
      "   macro avg       0.96      0.98      0.97      1149\n",
      "weighted avg       0.98      0.98      0.98      1149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# scikit-learn metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# MobileViT from timm\n",
    "try:\n",
    "    import timm\n",
    "except ImportError as e:\n",
    "    raise ImportError(\"timmÍ∞Ä ÏÑ§ÏπòÎêòÏñ¥ ÏûàÏßÄ ÏïäÏäµÎãàÎã§. Î®ºÏ†Ä `pip install timm`ÏùÑ Ïã§ÌñâÌïòÏÑ∏Ïöî.\") from e\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Ïû¨ÌòÑÏÑ± ÏÑ§Ï†ï(ÏÑ†ÌÉù)\n",
    "# -----------------------------\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    # ÏïÑÎûò Îëê Ï§ÑÏùÄ ÏïΩÍ∞ÑÏùò ÏÑ±Îä• Ï†ÄÌïòÍ∞Ä ÏûàÏùÑ Ïàò ÏûàÏäµÎãàÎã§.\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Í≤ΩÎ°ú Î∞è ÌÉÄÍπÉ ÌÅ¥ÎûòÏä§ ÏÑ§Ï†ï\n",
    "# -----------------------------\n",
    "train_dir = \"/workspace/user4/segmented_output_bisenet/train\"\n",
    "val_dir   = \"/workspace/user4/segmented_output_bisenet/val\"\n",
    "\n",
    "target_classes = [\"anger\", \"happy\", \"panic\", \"sadness\"]  # ÏöîÏ≤≠ÌïòÏã† ÌÉÄÍπÉ ÌÅ¥ÎûòÏä§\n",
    "\n",
    "# -----------------------------\n",
    "# 2) ÎîîÎ∞îÏù¥Ïä§ ÏÑ§Ï†ï\n",
    "# -----------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Î≥ÄÌôò Ï†ïÏùò\n",
    "#    MobileViTÎäî Í∏∞Î≥∏Ï†ÅÏúºÎ°ú 256x256 ÏûÖÎ†•ÏùÑ ÎßéÏù¥ ÏÇ¨Ïö©Ìï©ÎãàÎã§.\n",
    "#    ImageNet ÌèâÍ∑†/ÌëúÏ§ÄÌé∏Ï∞®Î°ú Ï†ïÍ∑úÌôîÌï©ÎãàÎã§.\n",
    "# -----------------------------\n",
    "IMG_SIZE = 256\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.05, hue=0.02),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ Î°úÎìú (ImageFolder)\n",
    "# -----------------------------\n",
    "full_train = datasets.ImageFolder(train_dir)\n",
    "full_val   = datasets.ImageFolder(val_dir)\n",
    "\n",
    "print(f\"Full train classes: {full_train.classes}\")\n",
    "print(f\"Full val   classes: {full_val.classes}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5) ÏöîÏ≤≠ÌïòÏã† ÌïÑÌÑ∞ + Ïù¥ÏßÑ ÎùºÎ≤® Î¶¨ÎßµÌïë Dataset\n",
    "#    (happy: 1, others: 0)\n",
    "# -----------------------------\n",
    "class BinaryFilteredDataset(Dataset):\n",
    "    def __init__(self, full_dataset, transform, target_classes):\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        # full_dataset.samples: [(path, class_idx), ...]\n",
    "        for path, class_idx in full_dataset.samples:\n",
    "            class_name = full_dataset.classes[class_idx]\n",
    "            if class_name not in target_classes:\n",
    "                continue\n",
    "            # Ïù¥ÏßÑ ÎùºÎ≤® Îß§Ìïë\n",
    "            binary_label = 1 if class_name == \"happy\" else 0\n",
    "            self.samples.append((path, binary_label))\n",
    "        # ÌÜµÍ≥Ñ Ï∂úÎ†•\n",
    "        total = len(self.samples)\n",
    "        num_happy = sum(1 for _, y in self.samples if y == 1)\n",
    "        num_others = total - num_happy\n",
    "        print(f\"[{type(self).__name__}] Total: {total} | HAPPY(1): {num_happy} | OTHERS(0): {num_others}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "\n",
    "# ÌïÑÌÑ∞ÎßÅÎêú Îç∞Ïù¥ÌÑ∞ÏÖã ÏÉùÏÑ±\n",
    "train_dataset = BinaryFilteredDataset(full_train, transform=train_transform, target_classes=target_classes)\n",
    "val_dataset   = BinaryFilteredDataset(full_val,   transform=val_transform,   target_classes=target_classes)\n",
    "\n",
    "# -----------------------------\n",
    "# 6) DataLoader Ï§ÄÎπÑ\n",
    "# -----------------------------\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 7) MobileViT Î™®Îç∏ Ï†ïÏùò\n",
    "#    num_classes=2 (binary)\n",
    "# -----------------------------\n",
    "# Ïòà: 'mobilevit_s', 'mobilevit_xs' Îì± ÏÇ¨Ïö© Í∞ÄÎä•. Ïó¨Í∏∞ÏÑ† small ÏÇ¨Ïö©.\n",
    "model_name = \"mobilevit_s\"\n",
    "model = timm.create_model(model_name, pretrained=True, num_classes=2)\n",
    "model.to(device)\n",
    "\n",
    "# -----------------------------\n",
    "# 8) ÏÜêÏã§Ìï®Ïàò/ÏòµÌã∞ÎßàÏù¥Ï†Ä Ï†ïÏùò\n",
    "# -----------------------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "\n",
    "# -----------------------------\n",
    "# 9) Ï†ÄÏû• Í≤ΩÎ°ú ÏÑ§Ï†ï (ÏöîÏ≤≠ÏÇ¨Ìï≠ Î∞òÏòÅ)\n",
    "# -----------------------------\n",
    "SAVE_DIR = \"/workspace/user5\"\n",
    "SAVE_PATH = os.path.join(SAVE_DIR, \"best_mobilevit_happy_vs_others.pth\")\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "print(f\"Model will be saved to: {SAVE_PATH}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 10) ÌïôÏäµ Î£®ÌîÑ (ÏöîÏ≤≠ÌïòÏã† ÌòïÌÉú + epoch=10)\n",
    "# -----------------------------\n",
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_val_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "        # ---- Train ----\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in tqdm(train_loader, leave=False):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            total += labels.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / total if total > 0 else 0.0\n",
    "        epoch_acc = (running_corrects.double() / total) if total > 0 else torch.tensor(0.0)\n",
    "        print(f\"Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "        # ---- Validation ----\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                val_corrects += torch.sum(preds == labels.data)\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_loss = val_loss / val_total if val_total > 0 else 0.0\n",
    "        val_acc = (val_corrects.double() / val_total) if val_total > 0 else torch.tensor(0.0)\n",
    "        print(f\"Val   Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
    "\n",
    "        # best model Ï†ÄÏû•\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            torch.save(best_model_wts, SAVE_PATH)\n",
    "            print(f\">> best model updated and saved to {SAVE_PATH}\")\n",
    "\n",
    "    print(f\"\\nBest val Acc: {best_val_acc:.4f}\")\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "# -----------------------------\n",
    "# 11) ÌïôÏäµ Ïã§Ìñâ (epoch=10)\n",
    "# -----------------------------\n",
    "model = train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10)\n",
    "\n",
    "# -----------------------------\n",
    "# 12) ÏÑ±Îä• ÌèâÍ∞Ä (ÏöîÏ≤≠ÌïòÏã† Ìè¨Îß∑)\n",
    "# -----------------------------\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "all_preds  = np.array(all_preds)\n",
    "\n",
    "acc  = accuracy_score(all_labels, all_preds)\n",
    "prec = precision_score(all_labels, all_preds, pos_label=1)\n",
    "rec  = recall_score(all_labels, all_preds, pos_label=1)\n",
    "f1   = f1_score(all_labels, all_preds, pos_label=1)\n",
    "cm   = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "print(\"\\n=== Val Metrics (binary: 1=HAPPY, 0=OTHERS) ===\")\n",
    "print(f\"Model: MobileViT Small\")\n",
    "print(f\"Accuracy : {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall   : {rec:.4f}\")\n",
    "print(f\"F1-score : {f1:.4f}\")\n",
    "print(\"\\nConfusion Matrix (rows: true, cols: pred)\")\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=[\"OTHERS\", \"HAPPY\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7588073c",
   "metadata": {},
   "source": [
    "efficientformer Î™®Îç∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33f3bc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Full train classes: ['anger', 'happy', 'panic', 'sadness']\n",
      "Full val   classes: ['anger', 'happy', 'panic', 'sadness']\n",
      "[BinaryFilteredDataset] Total: 9535 | HAPPY(1): 5245 | OTHERS(0): 4290\n",
      "[BinaryFilteredDataset] Total: 1149 | HAPPY(1): 299 | OTHERS(0): 850\n",
      "Using Model: efficientformerv2_l with num_classes=2\n",
      "Model will be saved to: /workspace/user5/best_efficientformerv2_happy_vs_others.pth\n",
      "\n",
      "Epoch 1/10\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc119170bfd64c6cadc25ac794ba0f01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 1:   0%|          | 0/298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1508 Acc: 0.9400\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ce376ab43d465c94c04b149d858fa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val   Epoch 1:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   Loss: 0.4159 Acc: 0.9286\n",
      ">> best model updated and saved to /workspace/user5/best_efficientformerv2_happy_vs_others.pth\n",
      "\n",
      "Epoch 2/10\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554b81890d474242b269b24da6954600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 2:   0%|          | 0/298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0643 Acc: 0.9782\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03bfcfc1a880446ca3671d686411ffca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val   Epoch 2:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   Loss: 0.2858 Acc: 0.9008\n",
      "\n",
      "Epoch 3/10\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1905b0b929f947c39ae2dcb4a1deabd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 3:   0%|          | 0/298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0393 Acc: 0.9881\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9baeb8a608724546bac71fd1aa2b30f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val   Epoch 3:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   Loss: 0.1073 Acc: 0.9721\n",
      ">> best model updated and saved to /workspace/user5/best_efficientformerv2_happy_vs_others.pth\n",
      "\n",
      "Epoch 4/10\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef2da91dc29c435e99469f96693a4c90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 4:   0%|          | 0/298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0302 Acc: 0.9902\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c57f5c634994b3fa3acf1ef6f32d4bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val   Epoch 4:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   Loss: 0.2014 Acc: 0.9513\n",
      "\n",
      "Epoch 5/10\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0cbea472e5d42c4bfe9040c7ad5c479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 5:   0%|          | 0/298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0286 Acc: 0.9894\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb351d312deb4b4bb4edfa43d334ec20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val   Epoch 5:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   Loss: 0.1355 Acc: 0.9582\n",
      "\n",
      "Epoch 6/10\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37bbb9e80d584d86b49bfcb9790bf6d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 6:   0%|          | 0/298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0225 Acc: 0.9923\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "071424122f6847cda116e41d9cb6e492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val   Epoch 6:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   Loss: 0.1108 Acc: 0.9739\n",
      ">> best model updated and saved to /workspace/user5/best_efficientformerv2_happy_vs_others.pth\n",
      "\n",
      "Epoch 7/10\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b59b455c28d44ee999c1244839aa5bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 7:   0%|          | 0/298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0175 Acc: 0.9931\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74325de1d9e34d8da6348584ff8da4df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val   Epoch 7:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   Loss: 0.2901 Acc: 0.9243\n",
      "\n",
      "Epoch 8/10\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a1349434ff64aea94a161ee9e1b755b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 8:   0%|          | 0/298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0153 Acc: 0.9939\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d49f6146b054cb384c30a2ae3ea392e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val   Epoch 8:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   Loss: 0.1297 Acc: 0.9687\n",
      "\n",
      "Epoch 9/10\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c44003ca80204023b6c0cb0f1875d2aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 9:   0%|          | 0/298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: Exception ignored in: Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50><function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50><function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50><function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "        self._shutdown_workers()self._shutdown_workers()\n",
      "\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "                if w.is_alive():self._shutdown_workers()if w.is_alive():self._shutdown_workers()\n",
      "\n",
      "\n",
      "\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "        assert self._parent_pid == os.getpid(), 'can only test a child process'    assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
      "if w.is_alive():if w.is_alive():\n",
      "AssertionError\n",
      "AssertionError\n",
      ":   File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      ": can only test a child processcan only test a child process\n",
      "\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
      "AssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process': \n",
      "can only test a child processAssertionError\n",
      ": can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()    \n",
      "self._shutdown_workers()  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():    \n",
      "if w.is_alive():  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'AssertionError\n",
      ": AssertionErrorcan only test a child process: \n",
      "can only test a child process\n",
      "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50><function _MultiProcessingDataLoaderIter.__del__ at 0x7fb9c4894e50>\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()    \n",
      "self._shutdown_workers()  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
      "    if w.is_alive():    \n",
      "if w.is_alive():  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "  File \"/home/user5/miniconda3/envs/tomas/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'AssertionError\n",
      ": AssertionErrorcan only test a child process: \n",
      "can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0132 Acc: 0.9956\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04366dd42854616af46f2eeed73f1cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val   Epoch 9:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   Loss: 0.1372 Acc: 0.9713\n",
      "\n",
      "Epoch 10/10\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7236def807814276be63bcf36e9aad7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 10:   0%|          | 0/298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0119 Acc: 0.9961\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7abf9c05c2764547a735458395e70ff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val   Epoch 10:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   Loss: 0.1254 Acc: 0.9756\n",
      ">> best model updated and saved to /workspace/user5/best_efficientformerv2_happy_vs_others.pth\n",
      "\n",
      "Best val Acc: 0.9756\n",
      "\n",
      "=== Val Metrics (binary: 1=HAPPY, 0=OTHERS) ===\n",
      "Model: EFFICIENTFORMERV2_L\n",
      "Accuracy : 0.9756\n",
      "Precision: 0.9302\n",
      "Recall   : 0.9799\n",
      "F1-score : 0.9544\n",
      "\n",
      "Confusion Matrix (rows: true, cols: pred)\n",
      "[[828  22]\n",
      " [  6 293]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      OTHERS       0.99      0.97      0.98       850\n",
      "       HAPPY       0.93      0.98      0.95       299\n",
      "\n",
      "    accuracy                           0.98      1149\n",
      "   macro avg       0.96      0.98      0.97      1149\n",
      "weighted avg       0.98      0.98      0.98      1149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# scikit-learn metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# EfficientFormerV2 from timm\n",
    "try:\n",
    "    import timm\n",
    "except ImportError as e:\n",
    "    raise ImportError(\"timmÏù¥ ÏÑ§ÏπòÎêòÏñ¥ ÏûàÏßÄ ÏïäÏäµÎãàÎã§. Î®ºÏ†Ä `pip install timm`ÏùÑ Ïã§ÌñâÌïòÏÑ∏Ïöî.\") from e\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Ïû¨ÌòÑÏÑ± ÏÑ§Ï†ï(ÏÑ†ÌÉù)\n",
    "# -----------------------------\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        # ÏïÑÎûò Îëê Ï§ÑÏùÄ ÏïΩÍ∞ÑÏùò ÏÑ±Îä• Ï†ÄÌïòÍ∞Ä ÏûàÏùÑ Ïàò ÏûàÏäµÎãàÎã§.\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Í≤ΩÎ°ú Î∞è ÌÉÄÍπÉ ÌÅ¥ÎûòÏä§ ÏÑ§Ï†ï\n",
    "# -----------------------------\n",
    "# Í≤ΩÎ°ú ÏÑ§Ï†ïÏùÄ ÏÇ¨Ïö©Ïûê ÌôòÍ≤ΩÏóê ÎßûÍ≤å Ïú†ÏßÄÌï©ÎãàÎã§.\n",
    "train_dir = \"/workspace/user4/segmented_output_bisenet/train\"\n",
    "val_dir   = \"/workspace/user4/segmented_output_bisenet/val\"\n",
    "\n",
    "target_classes = [\"anger\", \"happy\", \"panic\", \"sadness\"]  # ÏöîÏ≤≠ÌïòÏã† ÌÉÄÍπÉ ÌÅ¥ÎûòÏä§\n",
    "\n",
    "# -----------------------------\n",
    "# 2) ÎîîÎ∞îÏù¥Ïä§ ÏÑ§Ï†ï\n",
    "# -----------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Î≥ÄÌôò Ï†ïÏùò (IMG_SIZEÎ•º 224Î°ú ÏàòÏ†ï)\n",
    "#    EfficientFormerV2Ïùò ÏïàÏ†ïÏ†ÅÏù∏ ÎèôÏûëÏùÑ ÏúÑÌï¥ 224x224Î°ú ÏÑ§Ï†ïÌï©ÎãàÎã§.\n",
    "# -----------------------------\n",
    "# üö® ÏàòÏ†ï: IMG_SIZEÎ•º 256 -> 224Î°ú Î≥ÄÍ≤ΩÌïòÏó¨ Attention Î∏îÎ°ùÏùò Shape Ïò§Î•ò Î∞©ÏßÄ\n",
    "IMG_SIZE = 224\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.05, hue=0.02),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ Î°úÎìú (ImageFolder)\n",
    "# -----------------------------\n",
    "full_train = datasets.ImageFolder(train_dir)\n",
    "full_val   = datasets.ImageFolder(val_dir)\n",
    "\n",
    "print(f\"Full train classes: {full_train.classes}\")\n",
    "print(f\"Full val   classes: {full_val.classes}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5) ÏöîÏ≤≠ÌïòÏã† ÌïÑÌÑ∞ + Ïù¥ÏßÑ ÎùºÎ≤® Î¶¨ÎßµÌïë Dataset (happy: 1, others: 0)\n",
    "# -----------------------------\n",
    "class BinaryFilteredDataset(Dataset):\n",
    "    def __init__(self, full_dataset, transform, target_classes):\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        # full_dataset.samples: [(path, class_idx), ...]\n",
    "        for path, class_idx in full_dataset.samples:\n",
    "            class_name = full_dataset.classes[class_idx]\n",
    "            if class_name not in target_classes:\n",
    "                continue\n",
    "            # Ïù¥ÏßÑ ÎùºÎ≤® Îß§Ìïë\n",
    "            binary_label = 1 if class_name == \"happy\" else 0\n",
    "            self.samples.append((path, binary_label))\n",
    "        # ÌÜµÍ≥Ñ Ï∂úÎ†•\n",
    "        total = len(self.samples)\n",
    "        num_happy = sum(1 for _, y in self.samples if y == 1)\n",
    "        num_others = total - num_happy\n",
    "        print(f\"[{type(self).__name__}] Total: {total} | HAPPY(1): {num_happy} | OTHERS(0): {num_others}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "\n",
    "# ÌïÑÌÑ∞ÎßÅÎêú Îç∞Ïù¥ÌÑ∞ÏÖã ÏÉùÏÑ±\n",
    "train_dataset = BinaryFilteredDataset(full_train, transform=train_transform, target_classes=target_classes)\n",
    "val_dataset   = BinaryFilteredDataset(full_val,   transform=val_transform,   target_classes=target_classes)\n",
    "\n",
    "# -----------------------------\n",
    "# 6) DataLoader Ï§ÄÎπÑ\n",
    "# -----------------------------\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4 # ÌôòÍ≤ΩÏóê Îî∞Îùº Ï†ÅÏ†àÌûà ÏÑ§Ï†ï (1-4 Í∂åÏû•)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 7) EfficientFormerV2 Î™®Îç∏ Ï†ïÏùò\n",
    "#    num_classes=2 (binary)\n",
    "# -----------------------------\n",
    "model_name = \"efficientformerv2_l\"\n",
    "# pretrained=TrueÎ°ú ImageNet Í∞ÄÏ§ëÏπò Î°úÎìú\n",
    "model = timm.create_model(model_name, pretrained=True, num_classes=2)\n",
    "model.to(device)\n",
    "print(f\"Using Model: {model_name} with num_classes=2\") # Î™®Îç∏ ÏÇ¨Ïö© Ï†ïÎ≥¥ Ï∂úÎ†•\n",
    "\n",
    "# -----------------------------\n",
    "# 8) ÏÜêÏã§Ìï®Ïàò/ÏòµÌã∞ÎßàÏù¥Ï†Ä Ï†ïÏùò\n",
    "# -----------------------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "\n",
    "# -----------------------------\n",
    "# 9) Ï†ÄÏû• Í≤ΩÎ°ú ÏÑ§Ï†ï (ÏöîÏ≤≠ÏÇ¨Ìï≠ Î∞òÏòÅ)\n",
    "# -----------------------------\n",
    "SAVE_DIR = \"/workspace/user5\"\n",
    "SAVE_PATH = os.path.join(SAVE_DIR, \"best_efficientformerv2_happy_vs_others.pth\")\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "print(f\"Model will be saved to: {SAVE_PATH}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 10) ÌïôÏäµ Î£®ÌîÑ (epoch=10)\n",
    "# -----------------------------\n",
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_val_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "        # ---- Train ----\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        total = 0\n",
    "\n",
    "        # tqdm.auto.tqdmÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ ÏßÑÌñâ ÏÉÅÌô© ÌëúÏãú\n",
    "        for inputs, labels in tqdm(train_loader, desc=f\"Train Epoch {epoch+1}\"):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            total += labels.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / total if total > 0 else 0.0\n",
    "        # .item()ÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ ÌÖêÏÑúÏóêÏÑú Python Ïà´ÏûêÎ°ú Î≥ÄÌôò\n",
    "        epoch_acc = (running_corrects.double() / total).item() if total > 0 else 0.0\n",
    "        print(f\"Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "        # ---- Validation ----\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            # tqdm.auto.tqdmÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ ÏßÑÌñâ ÏÉÅÌô© ÌëúÏãú\n",
    "            for inputs, labels in tqdm(val_loader, desc=f\"Val   Epoch {epoch+1}\"):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                val_corrects += torch.sum(preds == labels.data)\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_loss = val_loss / val_total if val_total > 0 else 0.0\n",
    "        # .item()ÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ ÌÖêÏÑúÏóêÏÑú Python Ïà´ÏûêÎ°ú Î≥ÄÌôò\n",
    "        val_acc = (val_corrects.double() / val_total).item() if val_total > 0 else 0.0\n",
    "        print(f\"Val   Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
    "\n",
    "        # best model Ï†ÄÏû•\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            torch.save(best_model_wts, SAVE_PATH)\n",
    "            print(f\">> best model updated and saved to {SAVE_PATH}\")\n",
    "\n",
    "    print(f\"\\nBest val Acc: {best_val_acc:.4f}\")\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "# -----------------------------\n",
    "# 11) ÌïôÏäµ Ïã§Ìñâ (epoch=10)\n",
    "# -----------------------------\n",
    "model = train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10)\n",
    "\n",
    "# -----------------------------\n",
    "# 12) ÏÑ±Îä• ÌèâÍ∞Ä (ÏöîÏ≤≠ÌïòÏã† Ìè¨Îß∑)\n",
    "# -----------------------------\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "all_preds  = np.array(all_preds)\n",
    "\n",
    "acc  = accuracy_score(all_labels, all_preds)\n",
    "# pos_label=1: \"happy\" ÌÅ¥ÎûòÏä§Î•º Í∏çÏ†ï(Positive)ÏúºÎ°ú Í∞ÑÏ£º\n",
    "prec = precision_score(all_labels, all_preds, pos_label=1, zero_division=0)\n",
    "rec  = recall_score(all_labels, all_preds, pos_label=1, zero_division=0)\n",
    "f1   = f1_score(all_labels, all_preds, pos_label=1, zero_division=0)\n",
    "cm   = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "print(\"\\n=== Val Metrics (binary: 1=HAPPY, 0=OTHERS) ===\")\n",
    "print(f\"Model: {model_name.upper()}\")\n",
    "print(f\"Accuracy : {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall   : {rec:.4f}\")\n",
    "print(f\"F1-score : {f1:.4f}\")\n",
    "print(\"\\nConfusion Matrix (rows: true, cols: pred)\")\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "# target_names: 0 -> OTHERS, 1 -> HAPPY\n",
    "print(classification_report(all_labels, all_preds, target_names=[\"OTHERS\", \"HAPPY\"], zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tomas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
