{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e67bccb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.7-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.60.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (112 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-12.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m295.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.10.7-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m240.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m401.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.60.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m273.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m297.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-12.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m355.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pyparsing, pillow, numpy, kiwisolver, fonttools, cycler, pandas, contourpy, matplotlib\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m10/11\u001b[0m [matplotlib]^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m10/11\u001b[0m [matplotlib]\n",
      "\u001b[1A\u001b[2K"
     ]
    }
   ],
   "source": [
    "!pip install pandas matplotlib numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a1b6bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (2.3.3)\n",
      "Requirement already satisfied: matplotlib in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (3.10.7)\n",
      "Requirement already satisfied: numpy in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: pandas in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (2.3.3)\n",
      "Requirement already satisfied: matplotlib in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (3.10.7)\n",
      "Requirement already satisfied: numpy in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: pandas in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (2.3.3)\n",
      "Requirement already satisfied: matplotlib in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (3.10.7)\n",
      "Requirement already satisfied: numpy in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: pip in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (25.2)\n",
      "Collecting pip\n",
      "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 25.2\n",
      "    Uninstalling pip-25.2:\n",
      "      Successfully uninstalled pip-25.2\n",
      "Successfully installed pip-25.3\n",
      "Requirement already satisfied: pandas in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (2.3.3)\n",
      "Requirement already satisfied: matplotlib in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (3.10.7)\n",
      "Requirement already satisfied: numpy in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# 기본 재시도\n",
    "!pip install pandas matplotlib numpy\n",
    "\n",
    "# 네트워크가 불안정할 때 (다운로드 재시도 횟수 & 타임아웃 늘리기)\n",
    "!pip install pandas matplotlib numpy --retries 5 --timeout 120\n",
    "\n",
    "# 캐시 문제 회피\n",
    "!pip install pandas matplotlib numpy --no-cache-dir\n",
    "\n",
    "# 권한 이슈가 있을 때(Windows 관리자 권한 터미널 또는 가상환경 내에서)\n",
    "!python -m pip install --upgrade pip\n",
    "!python -m pip install pandas matplotlib numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e155b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sudo] password for user5: \n",
      "sudo: a password is required\n",
      "^C\n",
      "[sudo] password for user5: "
     ]
    }
   ],
   "source": [
    "!sudo apt-get install -y fonts-nanum\n",
    "!sudo fc-cache -fv\n",
    "!rm ~/.cache/matplotlib -rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08add64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 폴더에서 파일명 읽는 중: /workspace/new_data/img (recursive=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== 결과 요약 =====\n",
      "총 레코드: 7499\n",
      "유지(기쁨+파일매칭): 7499\n",
      "제외 - filename 없음: 0\n",
      "제외 - 기쁨 아님: 0\n",
      "제외 - 기쁨 폴더에 파일 없음: 0\n",
      "출력 파일: metadata_filtered_joy.json\n"
     ]
    }
   ],
   "source": [
    "# filter_joy_json.py\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# === 설정값 ===\n",
    "INPUT_JSON   = r\"/workspace/new_data/json/unicode_decoded_happy_data.json\"      # 원본 JSON (배열 JSON 또는 NDJSON 모두 지원)\n",
    "IMAGE_SOURCE = r\"/workspace/new_data/img\"  # '기쁨' 폴더 경로 또는 파일명 목록 txt 경로\n",
    "OUTPUT_JSON  = \"metadata_filtered_joy.json\"\n",
    "\n",
    "# 폴더 탐색 옵션\n",
    "RECURSIVE_SCAN = False   # True로 바꾸면 하위 폴더까지 모두 포함\n",
    "ALLOW_EXTENSIONS = None  # 예: {\"jpg\", \"jpeg\", \"png\"} 로 제한하려면 지정 (None이면 모든 확장자 포함)\n",
    "\n",
    "def load_json_safely(path):\n",
    "    \"\"\"JSON이 배열인지, NDJSON(줄 단위)인지 자동 감지하여 리스트로 반환\"\"\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read().strip()\n",
    "    if not text:\n",
    "        return []\n",
    "    try:\n",
    "        data = json.loads(text)\n",
    "        if isinstance(data, list):\n",
    "            return data\n",
    "        return [data]  # 단일 오브젝트면 리스트로 감싸기\n",
    "    except json.JSONDecodeError:\n",
    "        # NDJSON 파싱\n",
    "        records = []\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f2:\n",
    "            for line in f2:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                try:\n",
    "                    obj = json.loads(line)\n",
    "                    records.append(obj)\n",
    "                except json.JSONDecodeError:\n",
    "                    # 깨진 라인은 건너뜀\n",
    "                    pass\n",
    "        return records\n",
    "\n",
    "def normalize_filename(name):\n",
    "    \"\"\"경로 제거 + 트림 + 소문자 변환\"\"\"\n",
    "    if not isinstance(name, str):\n",
    "        return \"\"\n",
    "    base = os.path.basename(name.strip())\n",
    "    return base.lower()\n",
    "\n",
    "def list_filenames_from_dir(dir_path, recursive=False, allow_exts=None):\n",
    "    \"\"\"폴더에서 파일명 목록 생성 (basename만, 소문자)\"\"\"\n",
    "    result = set()\n",
    "    if recursive:\n",
    "        for root, dirs, files in os.walk(dir_path):\n",
    "            for fn in files:\n",
    "                if allow_exts:\n",
    "                    ext = os.path.splitext(fn)[1].lower().lstrip(\".\")\n",
    "                    if ext not in allow_exts:\n",
    "                        continue\n",
    "                result.add(normalize_filename(fn))\n",
    "    else:\n",
    "        # 상위 폴더만\n",
    "        for fn in os.listdir(dir_path):\n",
    "            full = os.path.join(dir_path, fn)\n",
    "            if os.path.isfile(full):\n",
    "                if allow_exts:\n",
    "                    ext = os.path.splitext(fn)[1].lower().lstrip(\".\")\n",
    "                    if ext not in allow_exts:\n",
    "                        continue\n",
    "                result.add(normalize_filename(fn))\n",
    "    return result\n",
    "\n",
    "def load_image_names(source_path):\n",
    "    \"\"\"\n",
    "    source_path가 디렉터리면 폴더 스캔,\n",
    "    파일이면 줄단위로 읽어서 집합 반환\n",
    "    \"\"\"\n",
    "    if not os.path.exists(source_path):\n",
    "        print(f\"[ERROR] 존재하지 않는 경로: {source_path}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # 디렉터리 처리\n",
    "    if os.path.isdir(source_path):\n",
    "        print(f\"[INFO] 폴더에서 파일명 읽는 중: {source_path} (recursive={RECURSIVE_SCAN})\")\n",
    "        names = list_filenames_from_dir(\n",
    "            source_path,\n",
    "            recursive=RECURSIVE_SCAN,\n",
    "            allow_exts=ALLOW_EXTENSIONS\n",
    "        )\n",
    "        if not names:\n",
    "            print(\"[WARN] 폴더에서 발견된 파일이 없습니다.\")\n",
    "        return names\n",
    "\n",
    "    # 텍스트 파일 처리\n",
    "    joy_names = set()\n",
    "    with open(source_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            name = line.strip()\n",
    "            if not name:\n",
    "                continue\n",
    "            joy_names.add(normalize_filename(name))\n",
    "    if not joy_names:\n",
    "        print(\"[WARN] 텍스트 파일에서 읽은 파일명이 없습니다.\")\n",
    "    return joy_names\n",
    "\n",
    "def main():\n",
    "    # 1) 이미지 파일명 집합 로드 (폴더 or 텍스트 파일)\n",
    "    joy_names = load_image_names(IMAGE_SOURCE)\n",
    "\n",
    "    # 2) 원본 JSON 로드\n",
    "    if not os.path.exists(INPUT_JSON):\n",
    "        print(f\"[ERROR] JSON 파일이 없습니다: {INPUT_JSON}\")\n",
    "        sys.exit(1)\n",
    "    records = load_json_safely(INPUT_JSON)\n",
    "    total = len(records)\n",
    "\n",
    "    # 3) 필터링: faceExp_uploader == \"기쁨\" AND filename ∈ joy_names\n",
    "    kept = []\n",
    "    dropped_missing_filename = 0\n",
    "    dropped_not_joy_label = 0\n",
    "    dropped_not_in_folder = 0\n",
    "\n",
    "    for rec in records:\n",
    "        fn = normalize_filename(rec.get(\"filename\", \"\"))\n",
    "        label = str(rec.get(\"faceExp_uploader\", \"\")).strip()\n",
    "        if not fn:\n",
    "            dropped_missing_filename += 1\n",
    "            continue\n",
    "        if label != \"기쁨\":\n",
    "            dropped_not_joy_label += 1\n",
    "            continue\n",
    "        if fn not in joy_names:\n",
    "            dropped_not_in_folder += 1\n",
    "            continue\n",
    "        kept.append(rec)\n",
    "\n",
    "    # 4) 저장\n",
    "    with open(OUTPUT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(kept, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    # 5) 통계 출력\n",
    "    print(\"===== 결과 요약 =====\")\n",
    "    print(f\"총 레코드: {total}\")\n",
    "    print(f\"유지(기쁨+파일매칭): {len(kept)}\")\n",
    "    print(f\"제외 - filename 없음: {dropped_missing_filename}\")\n",
    "    print(f\"제외 - 기쁨 아님: {dropped_not_joy_label}\")\n",
    "    print(f\"제외 - 기쁨 폴더에 파일 없음: {dropped_not_in_folder}\")\n",
    "    print(f\"출력 파일: {OUTPUT_JSON}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be505a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [openpyxl]1/2\u001b[0m [openpyxl]\n",
      "\u001b[1A\u001b[2KSuccessfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b660fad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xlrd\n",
      "  Downloading xlrd-2.0.2-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Downloading xlrd-2.0.2-py2.py3-none-any.whl (96 kB)\n",
      "Installing collected packages: xlrd\n",
      "Successfully installed xlrd-2.0.2\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56275153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (25.3)\n",
      "Requirement already satisfied: openpyxl in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in /workspace/miniconda3/envs/tomas/lib/python3.10/site-packages (from openpyxl) (2.0.0)\n"
     ]
    }
   ],
   "source": [
    "# 가상환경이 활성화된 터미널에서\n",
    "!python -m pip install --upgrade pip\n",
    "!python -m pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b1da2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 44592 (\\N{HANGUL SYLLABLE GI}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 49256 (\\N{HANGUL SYLLABLE BBEUM}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 51473 (\\N{HANGUL SYLLABLE JUNG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 47549 (\\N{HANGUL SYLLABLE RIB}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 45817 (\\N{HANGUL SYLLABLE DANG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 54889 (\\N{HANGUL SYLLABLE HWANG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 48520 (\\N{HANGUL SYLLABLE BUL}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 50504 (\\N{HANGUL SYLLABLE AN}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 49836 (\\N{HANGUL SYLLABLE SEUL}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 54548 (\\N{HANGUL SYLLABLE PEUM}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 49345 (\\N{HANGUL SYLLABLE SANG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 52376 (\\N{HANGUL SYLLABLE CEO}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 48516 (\\N{HANGUL SYLLABLE BUN}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 45432 (\\N{HANGUL SYLLABLE NO}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 50508 (\\N{HANGUL SYLLABLE AL}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 49688 (\\N{HANGUL SYLLABLE SU}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 50630 (\\N{HANGUL SYLLABLE EOBS}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 51020 (\\N{HANGUL SYLLABLE EUM}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 54252 (\\N{HANGUL SYLLABLE PO}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 48708 (\\N{HANGUL SYLLABLE BI}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 44368 (\\N{HANGUL SYLLABLE GYO}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 51221 (\\N{HANGUL SYLLABLE JEONG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 51204 (\\N{HANGUL SYLLABLE JEON}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 54980 (\\N{HANGUL SYLLABLE HU}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 52404 (\\N{HANGUL SYLLABLE CE}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 48516 (\\N{HANGUL SYLLABLE BUN}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 54252 (\\N{HANGUL SYLLABLE PO}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 48708 (\\N{HANGUL SYLLABLE BI}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 44368 (\\N{HANGUL SYLLABLE GYO}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 49688 (\\N{HANGUL SYLLABLE SU}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 51221 (\\N{HANGUL SYLLABLE JEONG}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 51204 (\\N{HANGUL SYLLABLE JEON}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 54980 (\\N{HANGUL SYLLABLE HU}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 52404 (\\N{HANGUL SYLLABLE CE}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 44592 (\\N{HANGUL SYLLABLE GI}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 49256 (\\N{HANGUL SYLLABLE BBEUM}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 51473 (\\N{HANGUL SYLLABLE JUNG}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 47549 (\\N{HANGUL SYLLABLE RIB}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 45817 (\\N{HANGUL SYLLABLE DANG}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 54889 (\\N{HANGUL SYLLABLE HWANG}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 48520 (\\N{HANGUL SYLLABLE BUL}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 50504 (\\N{HANGUL SYLLABLE AN}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 49836 (\\N{HANGUL SYLLABLE SEUL}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 54548 (\\N{HANGUL SYLLABLE PEUM}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 49345 (\\N{HANGUL SYLLABLE SANG}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 52376 (\\N{HANGUL SYLLABLE CEO}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 45432 (\\N{HANGUL SYLLABLE NO}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 50508 (\\N{HANGUL SYLLABLE AL}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 50630 (\\N{HANGUL SYLLABLE EOBS}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 51020 (\\N{HANGUL SYLLABLE EUM}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 44592 (\\N{HANGUL SYLLABLE GI}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 49256 (\\N{HANGUL SYLLABLE BBEUM}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 51473 (\\N{HANGUL SYLLABLE JUNG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 47549 (\\N{HANGUL SYLLABLE RIB}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 45817 (\\N{HANGUL SYLLABLE DANG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 54889 (\\N{HANGUL SYLLABLE HWANG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 48520 (\\N{HANGUL SYLLABLE BUL}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 50504 (\\N{HANGUL SYLLABLE AN}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 49836 (\\N{HANGUL SYLLABLE SEUL}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 54548 (\\N{HANGUL SYLLABLE PEUM}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 49345 (\\N{HANGUL SYLLABLE SANG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 52376 (\\N{HANGUL SYLLABLE CEO}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 48516 (\\N{HANGUL SYLLABLE BUN}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 45432 (\\N{HANGUL SYLLABLE NO}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 50508 (\\N{HANGUL SYLLABLE AL}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 49688 (\\N{HANGUL SYLLABLE SU}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 50630 (\\N{HANGUL SYLLABLE EOBS}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 51020 (\\N{HANGUL SYLLABLE EUM}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 54252 (\\N{HANGUL SYLLABLE PO}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 48708 (\\N{HANGUL SYLLABLE BI}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 44368 (\\N{HANGUL SYLLABLE GYO}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 51221 (\\N{HANGUL SYLLABLE JEONG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 51204 (\\N{HANGUL SYLLABLE JEON}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 54980 (\\N{HANGUL SYLLABLE HU}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 47588 (\\N{HANGUL SYLLABLE MAE}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:277: UserWarning: Glyph 52845 (\\N{HANGUL SYLLABLE CING}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 48516 (\\N{HANGUL SYLLABLE BUN}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 54252 (\\N{HANGUL SYLLABLE PO}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 48708 (\\N{HANGUL SYLLABLE BI}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 44368 (\\N{HANGUL SYLLABLE GYO}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 49688 (\\N{HANGUL SYLLABLE SU}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 51221 (\\N{HANGUL SYLLABLE JEONG}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 51204 (\\N{HANGUL SYLLABLE JEON}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 54980 (\\N{HANGUL SYLLABLE HU}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 47588 (\\N{HANGUL SYLLABLE MAE}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 52845 (\\N{HANGUL SYLLABLE CING}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 44592 (\\N{HANGUL SYLLABLE GI}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 49256 (\\N{HANGUL SYLLABLE BBEUM}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 51473 (\\N{HANGUL SYLLABLE JUNG}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 47549 (\\N{HANGUL SYLLABLE RIB}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 45817 (\\N{HANGUL SYLLABLE DANG}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 54889 (\\N{HANGUL SYLLABLE HWANG}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 48520 (\\N{HANGUL SYLLABLE BUL}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 50504 (\\N{HANGUL SYLLABLE AN}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 49836 (\\N{HANGUL SYLLABLE SEUL}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 54548 (\\N{HANGUL SYLLABLE PEUM}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 49345 (\\N{HANGUL SYLLABLE SANG}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 52376 (\\N{HANGUL SYLLABLE CEO}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 45432 (\\N{HANGUL SYLLABLE NO}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 50508 (\\N{HANGUL SYLLABLE AL}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 50630 (\\N{HANGUL SYLLABLE EOBS}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n",
      "/tmp/ipykernel_75100/379102348.py:278: UserWarning: Glyph 51020 (\\N{HANGUL SYLLABLE EUM}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(outfile, dpi=150)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[전체]\n",
      "  ┌ 수정 전(annot A/B/C 전체) ───────────────\n",
      "      기쁨 : 21614\n",
      "      당황 : 190\n",
      "      분노 : 53\n",
      "      불안 : 99\n",
      "      상처 : 82\n",
      "      슬픔 : 83\n",
      "    알수없음 : 2\n",
      "      중립 : 374\n",
      "  └──────────────────────────────────────────\n",
      "  ┌ 수정 후(다수결 최종 레이블) ─────────────\n",
      "      기쁨 : 7371\n",
      "      당황 : 26\n",
      "      분노 : 6\n",
      "      불안 : 8\n",
      "      상처 : 2\n",
      "      슬픔 : 9\n",
      "    알수없음 : 1\n",
      "      중립 : 76\n",
      "  └──────────────────────────────────────────\n",
      "\n",
      "[매칭]\n",
      "  ┌ 수정 전(annot A/B/C 전체) ───────────────\n",
      "      기쁨 : 21614\n",
      "      당황 : 190\n",
      "      분노 : 53\n",
      "      불안 : 99\n",
      "      상처 : 82\n",
      "      슬픔 : 83\n",
      "    알수없음 : 2\n",
      "      중립 : 374\n",
      "  └──────────────────────────────────────────\n",
      "  ┌ 수정 후(다수결 최종 레이블) ─────────────\n",
      "      기쁨 : 7371\n",
      "      당황 : 26\n",
      "      분노 : 6\n",
      "      불안 : 8\n",
      "      상처 : 2\n",
      "      슬픔 : 9\n",
      "    알수없음 : 1\n",
      "      중립 : 76\n",
      "  └──────────────────────────────────────────\n",
      "\n",
      "총 레코드 수: 7499 / 매칭된 레코드 수: 7499\n",
      "완료: 그래프 2종과 CSV가 'figures' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import json\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ========== 1) 경로 설정 ==========\n",
    "# ⚠️ Windows 경로는 r\"...\" 또는 \"/\" 사용\n",
    "JSON_PATH = r\"/workspace/new_data/json/unicode_decoded_happy_data.json\" \n",
    "\n",
    "# (선택) 이미지 폴더 또는 ZIP: 지정하면 '매칭된 이미지' 기준 그래프도 추가 저장\n",
    "IMG_DIR_OR_ZIP = r\"/workspace/new_data/img\"\n",
    "USE_UPLOADER_AS_TIE_BREAK = True   # 동률 시 업로더 라벨을 먼저 고려할지\n",
    "\n",
    "# ========== 2) 폰트/유틸 ==========\n",
    "def ensure_font():\n",
    "    \"\"\"한글 폰트 설정(Windows: 맑은 고딕, macOS: AppleGothic, 기타: DejaVu Sans)\"\"\"\n",
    "    import platform\n",
    "    system = platform.system()\n",
    "    if system == \"Windows\":\n",
    "        plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "    elif system == \"Darwin\":\n",
    "        plt.rcParams['font.family'] = 'AppleGothic'\n",
    "    else:\n",
    "        plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "def to_base_name(path_or_name: str) -> str:\n",
    "    \"\"\"경로/확장자를 제거하고, 소문자로 통일한 베이스 이름 반환.\"\"\"\n",
    "    if path_or_name is None:\n",
    "        return None\n",
    "    name = os.path.basename(str(path_or_name))\n",
    "    if \".\" in name:\n",
    "        name = \".\".join(name.split(\".\")[:-1])  # 마지막 점 기준 확장자 제거\n",
    "    return name.strip().lower()\n",
    "\n",
    "def list_image_basenames_from_dir_or_zip(dir_or_zip: str) -> set:\n",
    "    \"\"\"폴더 또는 zip에서 .jpg/.jpeg 파일 베이스 이름 set 수집.\"\"\"\n",
    "    if not dir_or_zip:\n",
    "        return set()\n",
    "    exts = {\".jpg\", \".jpeg\"}\n",
    "    basenames = set()\n",
    "    p = str(dir_or_zip)\n",
    "    if p.lower().endswith(\".zip\"):\n",
    "        with zipfile.ZipFile(p, \"r\") as zf:\n",
    "            for nm in zf.namelist():\n",
    "                bn = os.path.basename(nm)\n",
    "                ext = os.path.splitext(bn)[1].lower()\n",
    "                if ext in exts:\n",
    "                    basenames.add(to_base_name(bn))\n",
    "    else:\n",
    "        for root, _, files in os.walk(p):\n",
    "            for f in files:\n",
    "                ext = os.path.splitext(f)[1].lower()\n",
    "                if ext in exts:\n",
    "                    basenames.add(to_base_name(f))\n",
    "    return basenames\n",
    "\n",
    "# 영어/한글 라벨 표준화 매핑(원하면 자유롭게 수정하세요)\n",
    "LABEL_MAP = {\n",
    "    \"neutral\": \"중립\", \"happy\": \"기쁨\", \"joy\": \"기쁨\",\n",
    "    \"sad\": \"슬픔\", \"sadness\": \"슬픔\",\n",
    "    \"angry\": \"분노\", \"anger\": \"분노\",\n",
    "    \"surprise\": \"경악\", \"surprised\": \"경악\",\n",
    "    \"fear\": \"공포\", \"disgust\": \"혐오\", \"contempt\": \"경멸\",\n",
    "    \"confused\": \"혼란\", \"bored\": \"지루함\",\n",
    "\n",
    "    # 한국어 원라벨(그대로)\n",
    "    \"중립\": \"중립\", \"기쁨\": \"기쁨\", \"슬픔\": \"슬픔\", \"분노\": \"분노\",\n",
    "    \"경악\": \"경악\", \"공포\": \"공포\", \"혐오\": \"혐오\", \"경멸\": \"경멸\", \"혼란\": \"혼란\", \"지루함\": \"지루함\",\n",
    "}\n",
    "\n",
    "# 동률 우선순위(앞쪽일수록 우선)\n",
    "PRIORITY_ORDER = [\"기쁨\", \"중립\", \"슬픔\", \"분노\", \"경악\", \"공포\", \"혐오\", \"경멸\", \"혼란\", \"지루함\"]\n",
    "\n",
    "def normalize_label(lbl: str) -> str:\n",
    "    \"\"\"라벨 표준화: 소문자/trim → 한국어로 매핑. 매핑 없으면 원문 유지.\"\"\"\n",
    "    if lbl is None:\n",
    "        return None\n",
    "    s = str(lbl).strip()\n",
    "    key = s.lower()\n",
    "    return LABEL_MAP.get(key, s)\n",
    "\n",
    "def parse_faceexp_any(v):\n",
    "    \"\"\"\n",
    "    faceExp 값 파싱: 문자열 | dict | list 모두 지원\n",
    "    - 문자열: 직접 매핑\n",
    "    - dict: {'faceExp': '기쁨'} 또는 {'happy': 0.9, 'sad': 0.1} → faceExp 값 또는 최고 점수 라벨\n",
    "    - list: [{'label': '기쁨', 'score': 0.9}, ...] → 최고 점수 라벨\n",
    "    반환: 표준화된 문자열 라벨 또는 None\n",
    "    \"\"\"\n",
    "    if v is None:\n",
    "        return None\n",
    "\n",
    "    if isinstance(v, str):\n",
    "        return normalize_label(v)\n",
    "\n",
    "    if isinstance(v, dict):\n",
    "        # 명시 키가 있을 때\n",
    "        if 'faceExp' in v:\n",
    "            return normalize_label(v.get('faceExp'))\n",
    "        # 점수 dict일 때\n",
    "        scores = {}\n",
    "        for k, val in v.items():\n",
    "            try:\n",
    "                scores[normalize_label(k)] = float(val)\n",
    "            except (TypeError, ValueError):\n",
    "                pass\n",
    "        if scores:\n",
    "            return max(scores.items(), key=lambda kv: kv[1])[0]\n",
    "        return None\n",
    "\n",
    "    if isinstance(v, list):\n",
    "        scores = {}\n",
    "        for item in v:\n",
    "            if isinstance(item, dict):\n",
    "                label = item.get('label') or item.get('faceExp') or item.get('emotion') or item.get('emo')\n",
    "                score = item.get('score') or item.get('prob') or item.get('confidence')\n",
    "                if label is not None and score is not None:\n",
    "                    try:\n",
    "                        scores[normalize_label(label)] = float(score)\n",
    "                    except (TypeError, ValueError):\n",
    "                        pass\n",
    "        if scores:\n",
    "            return max(scores.items(), key=lambda kv: kv[1])[0]\n",
    "        return None\n",
    "\n",
    "    return None\n",
    "\n",
    "def majority_vote(labels, uploader_top=None, use_uploader=USE_UPLOADER_AS_TIE_BREAK):\n",
    "    \"\"\"\n",
    "    labels: [A, B, C] 표준화된 문자열(또는 None)\n",
    "    uploader_top: 업로더 최상위 라벨(선택)\n",
    "    규칙:\n",
    "      - 2표 이상이면 그 라벨\n",
    "      - 1-1-1 동률이면:\n",
    "          (옵션) uploader_top이 있고 사용 설정이면 → uploader_top\n",
    "          중립 포함 시 → 중립\n",
    "          아니면 PRIORITY_ORDER에서 가장 앞선 라벨\n",
    "    \"\"\"\n",
    "    labels = [l for l in labels if l is not None]\n",
    "    if not labels:\n",
    "        return None\n",
    "    cnt = Counter(labels)\n",
    "    top_lbl, top_n = cnt.most_common(1)[0]\n",
    "    if top_n >= 2:\n",
    "        return top_lbl\n",
    "\n",
    "    uniq = set(labels)\n",
    "\n",
    "    if use_uploader and uploader_top and uploader_top in uniq:\n",
    "        return uploader_top\n",
    "\n",
    "    if \"중립\" in uniq:\n",
    "        return \"중립\"\n",
    "\n",
    "    for p in PRIORITY_ORDER:\n",
    "        if p in uniq:\n",
    "            return p\n",
    "\n",
    "    return labels[0]  # 예외: 매핑 밖 레이블이면 임의 반환\n",
    "\n",
    "# ========== 3) 데이터 로드 ==========\n",
    "ensure_font()\n",
    "\n",
    "with open(JSON_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw = json.load(f)\n",
    "\n",
    "# 레코드 리스트 추출\n",
    "records = []\n",
    "if isinstance(raw, list):\n",
    "    records = raw\n",
    "elif isinstance(raw, dict):\n",
    "    if 'data' in raw and isinstance(raw['data'], list):\n",
    "        records = raw['data']\n",
    "    else:\n",
    "        for v in raw.values():\n",
    "            if isinstance(v, list):\n",
    "                records = v\n",
    "                break\n",
    "if not records:\n",
    "    raise ValueError(\"JSON에서 분석할 레코드를 찾지 못했습니다. 리스트 형태여야 합니다.\")\n",
    "\n",
    "df = pd.DataFrame.from_records(records)\n",
    "\n",
    "# 필수 컬럼 체크\n",
    "for col in ['filename', 'annot_A', 'annot_B', 'annot_C']:\n",
    "    if col not in df.columns:\n",
    "        raise ValueError(f\"JSON에 '{col}' 컬럼이 없습니다.\")\n",
    "\n",
    "has_uploader = 'faceExp_uploader' in df.columns\n",
    "\n",
    "# ========== 4) 파일명/이미지 매칭 ==========\n",
    "df['base_name'] = df['filename'].apply(to_base_name)\n",
    "img_basenames = list_image_basenames_from_dir_or_zip(IMG_DIR_OR_ZIP) if IMG_DIR_OR_ZIP else set()\n",
    "df['has_image'] = df['base_name'].isin(img_basenames) if img_basenames else True  # 이미지 경로 없으면 모두 True\n",
    "\n",
    "# ========== 5) 라벨 파싱 & 다수결 ==========\n",
    "def get_annot_label(row, key):\n",
    "    return normalize_label(parse_faceexp_any(row.get(key)))\n",
    "\n",
    "def get_uploader_top(row):\n",
    "    v = row.get('faceExp_uploader')\n",
    "    return normalize_label(parse_faceexp_any(v))\n",
    "\n",
    "df['A'] = df.apply(lambda r: get_annot_label(r, 'annot_A'), axis=1)\n",
    "df['B'] = df.apply(lambda r: get_annot_label(r, 'annot_B'), axis=1)\n",
    "df['C'] = df.apply(lambda r: get_annot_label(r, 'annot_C'), axis=1)\n",
    "df['uploader_top'] = df.apply(lambda r: get_uploader_top(r) if has_uploader else None, axis=1)\n",
    "\n",
    "df['final_label'] = df.apply(\n",
    "    lambda r: majority_vote([r['A'], r['B'], r['C']], uploader_top=r['uploader_top']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# ========== 6) 분포 집계 ==========\n",
    "def counts_annot_flat(sub_df):\n",
    "    \"\"\"다수결 전: annot A/B/C 전체를 낱개 표본으로 평탄화해 집계\"\"\"\n",
    "    flat = []\n",
    "    vals = sub_df[['A','B','C']].values\n",
    "    for a, b, c in vals:\n",
    "        for v in (a, b, c):\n",
    "            if v is not None:\n",
    "                flat.append(v)\n",
    "    return pd.Series(flat).value_counts().sort_index()\n",
    "\n",
    "def counts_final(sub_df):\n",
    "    return sub_df['final_label'].dropna().value_counts().sort_index()\n",
    "\n",
    "# 전체\n",
    "counts_pre_all = counts_annot_flat(df)            # 수정 전\n",
    "counts_post_all = counts_final(df)                # 수정 후\n",
    "\n",
    "# 매칭만(이미지 존재)\n",
    "matched_df = df[df['has_image']]\n",
    "counts_pre_matched = counts_annot_flat(matched_df)\n",
    "counts_post_matched = counts_final(matched_df)\n",
    "\n",
    "# ========== 7) 시각화(그룹 막대: 수정 전 vs 수정 후) ==========\n",
    "os.makedirs(\"figures\", exist_ok=True)\n",
    "\n",
    "def plot_group_compare(pre_counts, post_counts, title, outfile):\n",
    "    labels_union = sorted(set(pre_counts.index).union(set(post_counts.index)))\n",
    "    comp = pd.DataFrame({\n",
    "        '감정 라벨': labels_union,\n",
    "        '수정 전': [int(pre_counts.get(lbl, 0)) for lbl in labels_union],\n",
    "        '수정 후': [int(post_counts.get(lbl, 0)) for lbl in labels_union],\n",
    "    })\n",
    "    # 보기 좋게 총합 내림차순\n",
    "    comp['총합'] = comp['수정 전'] + comp['수정 후']\n",
    "    comp = comp.sort_values('총합', ascending=False).drop(columns=['총합'])\n",
    "\n",
    "    x = np.arange(len(comp['감정 라벨']))\n",
    "    w = 0.38\n",
    "\n",
    "    plt.figure(figsize=(max(8, len(x)*0.9), 6))\n",
    "    plt.bar(x - w/2, comp['수정 전'], width=w, color='#b0bec5', label='수정 전')\n",
    "    plt.bar(x + w/2, comp['수정 후'], width=w, color='#26a69a', label='수정 후')\n",
    "\n",
    "    plt.xticks(x, comp['감정 라벨'], rotation=25, ha='right')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "\n",
    "    # 값 라벨(옵션)\n",
    "    for xi, v in zip(x - w/2, comp['수정 전']):\n",
    "        if v > 0:\n",
    "            plt.text(xi, v + max(1, v*0.01), str(v), ha='center', va='bottom', fontsize=9, color='#455a64')\n",
    "    for xi, v in zip(x + w/2, comp['수정 후']):\n",
    "        if v > 0:\n",
    "            plt.text(xi, v + max(1, v*0.01), str(v), ha='center', va='bottom', fontsize=9, color='#00695c')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outfile, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "# 저장(3번째 예시 스타일)\n",
    "plot_group_compare(counts_pre_all, counts_post_all,\n",
    "                   \"faceExp 분포 비교 (수정 전 vs 수정 후, 전체)\",\n",
    "                   os.path.join(\"figures\", \"faceExp_distribution_compare_all.png\"))\n",
    "\n",
    "plot_group_compare(counts_pre_matched, counts_post_matched,\n",
    "                   \"faceExp 분포 비교 (수정 전 vs 수정 후, 매칭)\",\n",
    "                   os.path.join(\"figures\", \"faceExp_distribution_compare_matched.png\"))\n",
    "\n",
    "# ========== 8) 텍스트 요약 출력 ==========\n",
    "def print_summary_block(title, pre_counts, post_counts):\n",
    "    print(f\"[{title}]\")\n",
    "    print(\"  ┌ 수정 전(annot A/B/C 전체) ───────────────\")\n",
    "    if pre_counts.empty: print(\"    (데이터 없음)\")\n",
    "    else:\n",
    "        for lbl, val in pre_counts.items():\n",
    "            print(f\"    {lbl:>4s} : {val}\")\n",
    "    print(\"  └──────────────────────────────────────────\")\n",
    "    print(\"  ┌ 수정 후(다수결 최종 레이블) ─────────────\")\n",
    "    if post_counts.empty: print(\"    (데이터 없음)\")\n",
    "    else:\n",
    "        for lbl, val in post_counts.items():\n",
    "            print(f\"    {lbl:>4s} : {val}\")\n",
    "    print(\"  └──────────────────────────────────────────\\n\")\n",
    "\n",
    "print_summary_block(\"전체\", counts_pre_all, counts_post_all)\n",
    "print_summary_block(\"매칭\", counts_pre_matched, counts_post_matched)\n",
    "print(f\"총 레코드 수: {len(df)} / 매칭된 레코드 수: {int(df['has_image'].sum())}\")\n",
    "\n",
    "# ========== 9) 결과 CSV 저장 ==========\n",
    "out_csv = os.path.join(\"figures\", \"final_labels.csv\")\n",
    "df_out = df[['filename','A','B','C','uploader_top','final_label','has_image']]\n",
    "df_out.to_csv(out_csv, index=False, encoding='utf-8-sig')\n",
    "print(f\"완료: 그래프 2종과 CSV가 'figures' 폴더에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5555f9e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbe6e5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 레코드 수: 7499\n",
      "매핑 존재 수: 180\n",
      "실제 교체(변경) 수: 78 → 저장: unicode_decoded_happy_data_changed.json\n",
      "비변경 수: 7421 → 저장: unicode_decoded_happy_data_unchanged.json\n",
      "전체 업데이트본 저장: unicode_decoded_happy_data_updated.json\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ========== 1) 경로 ==========\n",
    "JSON_PATH = r\"/workspace/new_data/json/unicode_decoded_happy_data.json\"\n",
    "EXCEL_PATH = r\"/workspace/new_data/label/json_img_matching_happy.xlsx\"  # .xlsx/.xls/.csv 모두 지원\n",
    "\n",
    "EXCEL_SHEET_NAME = 0\n",
    "EXCEL_FILENAME_COL = \"gudt\"\n",
    "EXCEL_JUDGE_COL = \"judge\"\n",
    "\n",
    "# 출력 파일명은 원본 JSON 이름을 기준으로 생성\n",
    "SPLIT_CHANGED_SUFFIX   = \"_changed\"    # 바뀐 78건\n",
    "SPLIT_UNCHANGED_SUFFIX = \"_unchanged\"  # 나머지 7421건\n",
    "UPDATED_JSON_SUFFIX    = \"_updated\"    # (전체 업데이트본이 필요할 때)\n",
    "\n",
    "# ========== 2) 헬퍼 ==========\n",
    "def to_base_name(path_or_name: str) -> str:\n",
    "    \"\"\"경로/확장자 제거 + 소문자 통일한 베이스 이름.\"\"\"\n",
    "    if path_or_name is None:\n",
    "        return None\n",
    "    name = os.path.basename(str(path_or_name)).strip()\n",
    "    if \".\" in name:\n",
    "        name = \".\".join(name.split(\".\")[:-1])\n",
    "    return name.lower()\n",
    "\n",
    "def normalize_judge(lbl: str) -> str:\n",
    "    \"\"\"judge 라벨을 '기쁨' 또는 '중립'으로 정규화.\"\"\"\n",
    "    if lbl is None or (isinstance(lbl, float) and pd.isna(lbl)):\n",
    "        return None\n",
    "    s = str(lbl).strip().lower()\n",
    "    mapping = {\n",
    "        \"기쁨\": \"기쁨\", \"행복\": \"기쁨\", \"joy\": \"기쁨\", \"happy\": \"기쁨\",\n",
    "        \"중립\": \"중립\", \"neutral\": \"중립\"\n",
    "    }\n",
    "    return mapping.get(s, s)\n",
    "\n",
    "def faceexp_top_label(value):\n",
    "    \"\"\"\n",
    "    faceExp_uploader의 최상위 라벨만 추출(문자열/딕셔너리/리스트 모두 대응).\n",
    "    - 문자열: 그대로\n",
    "    - dict: 최고 점수 키\n",
    "    - list[dict]: 최고 점수 label\n",
    "    \"\"\"\n",
    "    if value is None:\n",
    "        return None\n",
    "    if isinstance(value, str):\n",
    "        return value.strip()\n",
    "    if isinstance(value, dict):\n",
    "        try:\n",
    "            return max(value.items(), key=lambda kv: float(kv[1]))[0]\n",
    "        except Exception:\n",
    "            return None\n",
    "    if isinstance(value, list):\n",
    "        scores = {}\n",
    "        for item in value:\n",
    "            if isinstance(item, dict):\n",
    "                label = item.get('label') or item.get('faceExp') or item.get('emotion') or item.get('emo')\n",
    "                score = item.get('score') or item.get('prob') or item.get('confidence')\n",
    "                if label is not None and score is not None:\n",
    "                    try:\n",
    "                        scores[str(label).strip()] = float(score)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "        if scores:\n",
    "            return max(scores.items(), key=lambda kv: kv[1])[0]\n",
    "    return None\n",
    "\n",
    "def load_table(path: str, sheet_name=0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    .xlsx/.xls/.csv 자동 판별하여 로드.\n",
    "    - .xlsx/.xlsm: openpyxl 필요 (pip install openpyxl)\n",
    "    - .xls: xlrd 필요 (pip install xlrd)\n",
    "    - .csv: 엔진 불필요\n",
    "    \"\"\"\n",
    "    ext = Path(path).suffix.lower()\n",
    "    if ext in [\".xlsx\", \".xlsm\"]:\n",
    "        try:\n",
    "            return pd.read_excel(path, sheet_name=sheet_name, engine=\"openpyxl\")\n",
    "        except ImportError:\n",
    "            raise ImportError(\"openpyxl가 필요합니다. 설치 후 실행하거나, 엑셀을 CSV로 저장해 주세요.\")\n",
    "    elif ext == \".xls\":\n",
    "        try:\n",
    "            return pd.read_excel(path, sheet_name=sheet_name, engine=\"xlrd\")\n",
    "        except ImportError:\n",
    "            raise ImportError(\"xlrd가 필요합니다. 설치 후 실행하거나, 엑셀을 CSV로 저장해 주세요.\")\n",
    "    elif ext in [\".csv\", \".tsv\"]:\n",
    "        sep = \",\" if ext == \".csv\" else \"\\t\"\n",
    "        return pd.read_csv(path, sep=sep, encoding=\"utf-8\")\n",
    "    else:\n",
    "        raise ValueError(f\"지원하지 않는 파일 형식: {ext}\")\n",
    "\n",
    "# ========== 3) 데이터 로드 ==========\n",
    "# JSON 로드\n",
    "with open(JSON_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw = json.load(f)\n",
    "\n",
    "# 레코드 리스트 추출 (list 또는 dict 래핑 모두 대응)\n",
    "records = []\n",
    "if isinstance(raw, list):\n",
    "    records = raw\n",
    "elif isinstance(raw, dict):\n",
    "    if 'data' in raw and isinstance(raw['data'], list):\n",
    "        records = raw['data']\n",
    "    else:\n",
    "        for v in raw.values():\n",
    "            if isinstance(v, list):\n",
    "                records = v\n",
    "                break\n",
    "if not records:\n",
    "    raise ValueError(\"JSON에서 분석할 레코드를 찾지 못했습니다. 리스트 형태여야 합니다.\")\n",
    "\n",
    "df = pd.DataFrame.from_records(records)\n",
    "if 'filename' not in df.columns:\n",
    "    raise ValueError(\"JSON에 'filename' 컬럼이 없습니다.\")\n",
    "\n",
    "# 기존 top label (비교 기준)\n",
    "before_top = df['faceExp_uploader'].apply(faceexp_top_label) if 'faceExp_uploader' in df.columns else pd.Series([None]*len(df))\n",
    "\n",
    "# JSON 파일명 베이스 이름\n",
    "df['base_name_json'] = df['filename'].apply(to_base_name)\n",
    "\n",
    "# 엑셀/CSV 로드\n",
    "xlsx = load_table(EXCEL_PATH, sheet_name=EXCEL_SHEET_NAME)\n",
    "for col in [EXCEL_FILENAME_COL, EXCEL_JUDGE_COL]:\n",
    "    if col not in xlsx.columns:\n",
    "        raise ValueError(f\"엑셀/CSV에 '{col}' 컬럼이 없습니다. 실제 컬럼: {list(xlsx.columns)}\")\n",
    "\n",
    "# 엑셀 파일명/라벨 정규화\n",
    "xlsx['base_name_excel'] = xlsx[EXCEL_FILENAME_COL].astype(str).apply(to_base_name)\n",
    "xlsx['judge_norm'] = xlsx[EXCEL_JUDGE_COL].apply(normalize_judge)\n",
    "xlsx_valid = xlsx.dropna(subset=['base_name_excel', 'judge_norm']).copy()\n",
    "xlsx_valid = xlsx_valid[xlsx_valid['judge_norm'].isin(['기쁨', '중립'])]\n",
    "\n",
    "# 같은 파일명이 엑셀에 여러 번 있을 때 → 다수결로 결정(동수면 중립 우선)\n",
    "vote_map = {}\n",
    "for basename, grp in xlsx_valid.groupby('base_name_excel'):\n",
    "    counts = grp['judge_norm'].value_counts()\n",
    "    if len(counts) == 0:\n",
    "        continue\n",
    "    if len(counts) == 1:\n",
    "        final = counts.index[0]\n",
    "    else:\n",
    "        most = counts.max()\n",
    "        winners = counts[counts == most].index.tolist()\n",
    "        final = '중립' if '중립' in winners else winners[0]\n",
    "    vote_map[basename] = final\n",
    "\n",
    "# ========== 4) 업데이트 & 변경 여부 산출 ==========\n",
    "df['mapped_judge'] = df['base_name_json'].map(vote_map)\n",
    "\n",
    "# 이 줄을 True로 바꾸면 \"매핑만 있으면 변경으로 간주(=180건)\"가 됩니다.\n",
    "USE_STRICT_CHANGE_CRITERIA = True\n",
    "\n",
    "if USE_STRICT_CHANGE_CRITERIA:\n",
    "    # 이전 코드와 동일: 최상위 라벨이 다를 때만 '실제 교체'\n",
    "    changed_mask = df['mapped_judge'].notna() & (before_top.fillna(\"__NA__\") != df['mapped_judge'])\n",
    "else:\n",
    "    # 매핑된 모든 건을 '변경'으로 간주\n",
    "    changed_mask = df['mapped_judge'].notna()\n",
    "\n",
    "# 업데이트된 값(매핑이 있으면 교체)\n",
    "def replace_uploader(old_val, mapped):\n",
    "    return mapped if mapped is not None else old_val\n",
    "\n",
    "df['faceExp_uploader_updated'] = [\n",
    "    replace_uploader(o, m) for o, m in zip(df.get('faceExp_uploader', pd.Series([None]*len(df))), df['mapped_judge'])\n",
    "]\n",
    "\n",
    "# ========== 5) 분리 저장 ==========\n",
    "# 원본 구조를 유지할 필요가 있으면, 여기서 dict 래핑을 복원할 수 있으나\n",
    "# 요구사항에 따라 '리스트 JSON'으로 저장합니다.\n",
    "\n",
    "# 업데이트된 전체 레코드(리스트)\n",
    "updated_records = []\n",
    "for i, rec in enumerate(records):\n",
    "    rec2 = dict(rec)\n",
    "    rec2['faceExp_uploader'] = df.loc[i, 'faceExp_uploader_updated']\n",
    "    updated_records.append(rec2)\n",
    "\n",
    "# 분리: 변경/비변경\n",
    "changed_indices = df.index[changed_mask].tolist()\n",
    "unchanged_indices = df.index[~changed_mask].tolist()\n",
    "\n",
    "changed_records   = [updated_records[i] for i in changed_indices]\n",
    "unchanged_records = [updated_records[i] for i in unchanged_indices]\n",
    "\n",
    "# 파일 경로\n",
    "json_path = Path(JSON_PATH)\n",
    "out_changed   = json_path.with_name(json_path.stem + SPLIT_CHANGED_SUFFIX   + json_path.suffix)\n",
    "out_unchanged = json_path.with_name(json_path.stem + SPLIT_UNCHANGED_SUFFIX + json_path.suffix)\n",
    "out_updated   = json_path.with_name(json_path.stem + UPDATED_JSON_SUFFIX    + json_path.suffix)  # 참고: 전체 업데이트본\n",
    "\n",
    "# 저장\n",
    "with open(out_changed, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(changed_records, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(out_unchanged, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(unchanged_records, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# (선택) 전체 업데이트본도 저장하고 싶으면 아래 주석 해제\n",
    "with open(out_updated, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(updated_records, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# (부가) 변경된 파일명 목록 저장\n",
    "changed_filenames = [records[i].get('filename') for i in changed_indices]\n",
    "with open(json_path.with_name(json_path.stem + \"_changed_filenames.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(changed_filenames, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# 검증 출력\n",
    "print(f\"총 레코드 수: {len(df)}\")\n",
    "print(f\"매핑 존재 수: {int(df['mapped_judge'].notna().sum())}\")\n",
    "print(f\"실제 교체(변경) 수: {len(changed_records)} → 저장: {out_changed.name}\")\n",
    "print(f\"비변경 수: {len(unchanged_records)} → 저장: {out_unchanged.name}\")\n",
    "print(f\"전체 업데이트본 저장: {out_updated.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e811c9d4",
   "metadata": {},
   "source": [
    "3710필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b732c5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "완료! 3710개 이미지의 중앙값 박스를 ./bbox_agg_median_per_image.csv에 저장했습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "import statistics\n",
    "\n",
    "# ===== 설정 =====\n",
    "INPUT_JSON = \"/workspace/new_data/split_half/happy_half.json\"  # ← 수천 개 이미지가 들어있는 단일 JSON 파일\n",
    "OUTPUT_CSV  = \"./bbox_agg_median_per_image.csv\"\n",
    "\n",
    "def normalize_item_to_annots(item, fallback_image=None):\n",
    "    \"\"\"\n",
    "    한 '이미지 단위' 객체에서 annot_*의 boxes를 추출하여 통일된 형태로 반환.\n",
    "    반환: (image_name, list of boxes dicts [{minX,...}, ...])\n",
    "    \"\"\"\n",
    "    image_name = item.get(\"image\", fallback_image)\n",
    "    boxes_list = []\n",
    "\n",
    "    def maybe_push(annot_val):\n",
    "        if not isinstance(annot_val, dict):\n",
    "            return\n",
    "        boxes = annot_val.get(\"boxes\")\n",
    "        if not isinstance(boxes, dict):\n",
    "            return\n",
    "        try:\n",
    "            minX = float(boxes[\"minX\"]); minY = float(boxes[\"minY\"])\n",
    "            maxX = float(boxes[\"maxX\"]); maxY = float(boxes[\"maxY\"])\n",
    "        except (KeyError, ValueError, TypeError):\n",
    "            return\n",
    "        boxes_list.append({\"minX\": minX, \"minY\": minY, \"maxX\": maxX, \"maxY\": maxY})\n",
    "\n",
    "    # 케이스 1) {\"annotations\": {annot_A:{boxes:...}, annot_B:{...}, ...}}\n",
    "    if \"annotations\" in item and isinstance(item[\"annotations\"], dict):\n",
    "        for _, annot_val in item[\"annotations\"].items():\n",
    "            maybe_push(annot_val)\n",
    "    else:\n",
    "        # 케이스 2) 루트에 바로 annot_A/B/C가 있는 경우\n",
    "        # 또는 item 자체가 단일 annot 구조(바로 boxes 포함)인 경우까지 커버\n",
    "        found_any = False\n",
    "        for key, val in item.items():\n",
    "            if isinstance(val, dict) and \"boxes\" in val:\n",
    "                maybe_push(val)\n",
    "                found_any = True\n",
    "        if not found_any and \"boxes\" in item:\n",
    "            # item 자체가 하나의 annot일 때\n",
    "            maybe_push(item)\n",
    "\n",
    "    return image_name, boxes_list\n",
    "\n",
    "def process_large_json(input_json):\n",
    "    \"\"\"\n",
    "    대용량 단일 JSON(리스트 또는 딕셔너리) 전체를 읽어\n",
    "    이미지별로 A/B/C의 min/max 중앙값을 계산하고 center/width/height까지 계산해 행 목록 반환.\n",
    "    \"\"\"\n",
    "    with open(input_json, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    # 최상위가 리스트인 경우: 각 원소가 이미지 단위라고 가정\n",
    "    if isinstance(data, list):\n",
    "        for idx, item in enumerate(data):\n",
    "            if not isinstance(item, dict):\n",
    "                continue\n",
    "            image_name, boxes_list = normalize_item_to_annots(item, fallback_image=f\"img_{idx}\")\n",
    "            # A/B/C 등에서 모인 박스가 없으면 스킵\n",
    "            if not boxes_list:\n",
    "                continue\n",
    "\n",
    "            # 좌표별 리스트 만들기\n",
    "            minXs = [b[\"minX\"] for b in boxes_list]\n",
    "            minYs = [b[\"minY\"] for b in boxes_list]\n",
    "            maxXs = [b[\"maxX\"] for b in boxes_list]\n",
    "            maxYs = [b[\"maxY\"] for b in boxes_list]\n",
    "\n",
    "            agg_minX = statistics.median(minXs)\n",
    "            agg_minY = statistics.median(minYs)\n",
    "            agg_maxX = statistics.median(maxXs)\n",
    "            agg_maxY = statistics.median(maxYs)\n",
    "\n",
    "            centerX = (agg_minX + agg_maxX) / 2.0\n",
    "            centerY = (agg_minY + agg_maxY) / 2.0\n",
    "            width   = agg_maxX - agg_minX\n",
    "            height  = agg_maxY - agg_minY\n",
    "\n",
    "            rows.append({\n",
    "                \"image\": image_name,\n",
    "                \"agg_minX\": agg_minX, \"agg_minY\": agg_minY,\n",
    "                \"agg_maxX\": agg_maxX, \"agg_maxY\": agg_maxY,\n",
    "                \"centerX\": centerX, \"centerY\": centerY,\n",
    "                \"width\": width, \"height\": height,\n",
    "            })\n",
    "\n",
    "    # 최상위가 딕셔너리인 경우:\n",
    "    # - 형태 A) {\"images\": [...]} 같은 컬렉션 키 아래 리스트\n",
    "    # - 형태 B) 루트에 이미지 단위 딕셔너리들이 key별로 들어 있는 경우(덜 일반적)\n",
    "    elif isinstance(data, dict):\n",
    "        # 형태 A 우선 시도\n",
    "        candidate_keys = [\"images\", \"data\", \"items\", \"records\", \"annotations_list\"]\n",
    "        img_list = None\n",
    "        for k in candidate_keys:\n",
    "            if k in data and isinstance(data[k], list):\n",
    "                img_list = data[k]\n",
    "                break\n",
    "\n",
    "        if img_list is not None:\n",
    "            for idx, item in enumerate(img_list):\n",
    "                if not isinstance(item, dict):\n",
    "                    continue\n",
    "                image_name, boxes_list = normalize_item_to_annots(item, fallback_image=f\"img_{idx}\")\n",
    "                if not boxes_list:\n",
    "                    continue\n",
    "\n",
    "                minXs = [b[\"minX\"] for b in boxes_list]\n",
    "                minYs = [b[\"minY\"] for b in boxes_list]\n",
    "                maxXs = [b[\"maxX\"] for b in boxes_list]\n",
    "                maxYs = [b[\"maxY\"] for b in boxes_list]\n",
    "\n",
    "                agg_minX = statistics.median(minXs)\n",
    "                agg_minY = statistics.median(minYs)\n",
    "                agg_maxX = statistics.median(maxXs)\n",
    "                agg_maxY = statistics.median(maxYs)\n",
    "\n",
    "                centerX = (agg_minX + agg_maxX) / 2.0\n",
    "                centerY = (agg_minY + agg_maxY) / 2.0\n",
    "                width   = agg_maxX - agg_minX\n",
    "                height  = agg_maxY - agg_minY\n",
    "\n",
    "                rows.append({\n",
    "                    \"image\": image_name,\n",
    "                    \"agg_minX\": agg_minX, \"agg_minY\": agg_minY,\n",
    "                    \"agg_maxX\": agg_maxX, \"agg_maxY\": agg_maxY,\n",
    "                    \"centerX\": centerX, \"centerY\": centerY,\n",
    "                    \"width\": width, \"height\": height,\n",
    "                })\n",
    "        else:\n",
    "            # 형태 B: 루트의 각 key가 이미지 단위 객체라고 가정\n",
    "            for key, item in data.items():\n",
    "                if not isinstance(item, dict):\n",
    "                    continue\n",
    "                image_name, boxes_list = normalize_item_to_annots(item, fallback_image=str(key))\n",
    "                if not boxes_list:\n",
    "                    continue\n",
    "\n",
    "                minXs = [b[\"minX\"] for b in boxes_list]\n",
    "                minYs = [b[\"minY\"] for b in boxes_list]\n",
    "                maxXs = [b[\"maxX\"] for b in boxes_list]\n",
    "                maxYs = [b[\"maxY\"] for b in boxes_list]\n",
    "\n",
    "                agg_minX = statistics.median(minXs)\n",
    "                agg_minY = statistics.median(minYs)\n",
    "                agg_maxX = statistics.median(maxXs)\n",
    "                agg_maxY = statistics.median(maxYs)\n",
    "\n",
    "                centerX = (agg_minX + agg_maxX) / 2.0\n",
    "                centerY = (agg_minY + agg_maxY) / 2.0\n",
    "                width   = agg_maxX - agg_minX\n",
    "                height  = agg_maxY - agg_minY\n",
    "\n",
    "                rows.append({\n",
    "                    \"image\": image_name,\n",
    "                    \"agg_minX\": agg_minX, \"agg_minY\": agg_minY,\n",
    "                    \"agg_maxX\": agg_maxX, \"agg_maxY\": agg_maxY,\n",
    "                    \"centerX\": centerX, \"centerY\": centerY,\n",
    "                    \"width\": width, \"height\": height,\n",
    "                })\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"지원하지 않는 최상위 JSON 구조입니다. (dict 또는 list 여야 합니다)\")\n",
    "\n",
    "    return rows\n",
    "\n",
    "def main():\n",
    "    rows = process_large_json(INPUT_JSON)\n",
    "    if not rows:\n",
    "        print(\"집계할 데이터가 없습니다. 입력 JSON 구조와 annot A/B/C 존재 여부를 확인하세요.\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(os.path.dirname(OUTPUT_CSV) or \".\", exist_ok=True)\n",
    "    fieldnames = [\n",
    "        \"image\",\n",
    "        \"agg_minX\", \"agg_minY\", \"agg_maxX\", \"agg_maxY\",\n",
    "        \"centerX\", \"centerY\", \"width\", \"height\",\n",
    "    ]\n",
    "    with open(OUTPUT_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        w.writeheader()\n",
    "        w.writerows(rows)\n",
    "\n",
    "    print(f\"완료! {len(rows)}개 이미지의 중앙값 박스를 {OUTPUT_CSV}에 저장했습니다.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11205d30",
   "metadata": {},
   "source": [
    "json자동 중간값 필터기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7562588",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tomas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
